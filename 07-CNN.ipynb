{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fresh-promise",
   "metadata": {},
   "source": [
    "# 합성곱 신경망(CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-motor",
   "metadata": {},
   "source": [
    "## 01 합성곱/풀링 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-cover",
   "metadata": {},
   "source": [
    "### 4차원 배열"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-manner",
   "metadata": {},
   "source": [
    "CNN에서 계층 사이를 흐르는 데이터는 4차원이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "emotional-necklace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 높이 28, 너비 28, 채널 1개인 데이터 10개를 무작위로 생성\n",
    "x = np.random.rand(10, 1, 28, 28)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bright-height",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10개 중 첫 번째 데이터에 접근\n",
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "retired-evening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째 채널의 공간 데이터에 접근\n",
    "x[0, 0].shape  # 또는 x[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-andorra",
   "metadata": {},
   "source": [
    "### for문 대신 im2col로 데이터 전개하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-nicaragua",
   "metadata": {},
   "source": [
    "* im2col : 입력 데이터를 필터링(가중치 계산)하기 좋게 전개하는(펼치는) 함수, image to column, 이미지에서 행렬로\n",
    "\n",
    "* 카페(Cafe)나 체이너(Chainer) 등의 딥러닝 프레임워크에서 합성곱 계층 구현할 때 사용\n",
    "\n",
    "* 필터 적용 영역이 겹치게 되면 im2col이 메모리를 더 많이 소비하는 단점이 있지만, 행렬 계산으로 만들면 선형 대수 라이브러리를 활용해 효율을 높일 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-sullivan",
   "metadata": {},
   "source": [
    "### im2col 이용하여 합성곱 계층 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alone-african",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n",
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "# im2col(input_data, filter_h, filter_w, stride=1, pad=0)\n",
    "\n",
    "import sys, os\n",
    "os.chdir(\"C:/Users/Soyeon/Desktop/Study/DL-Study/밑시딥/deep-learning-from-scratch/ch07/\")\n",
    "sys.path.append(os.pardir)\n",
    "from common.util import im2col\n",
    "\n",
    "x1 = np.random.rand(1, 3, 7, 7) # (데이터의 수, 채널 수, 높이, 너비)\n",
    "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
    "print(col1.shape)\n",
    "\n",
    "x2 = np.random.rand(10, 3, 7, 7) # 데이터 10개\n",
    "col2 = im2col(x2, 5, 5, stride=1, pad=0)\n",
    "print(col2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cognitive-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)\n",
    "        \n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T # 필터 전개\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2) # 축 순서 변경 (N,H,W,C) -> (N,C,H,W)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-huntington",
   "metadata": {},
   "source": [
    "* 합성곱 계층의 역전파 구현은 col2im 을 사용하면 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-annotation",
   "metadata": {},
   "source": [
    "### 풀링 계층 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "compliant-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        # 전개\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "        \n",
    "        # 행 방향 최댓값\n",
    "        out = np.max(col, axis=1)\n",
    "        \n",
    "        # reshape\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-buyer",
   "metadata": {},
   "source": [
    "## 02 CNN 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-lingerie",
   "metadata": {},
   "source": [
    "### SimpleConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aboriginal-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"단순한 합성곱 신경망\n",
    "    \n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 입력 크기（MNIST의 경우엔 784）\n",
    "    hidden_size_list : 각 은닉층의 뉴런 수를 담은 리스트（e.g. [100, 100, 100]）\n",
    "    output_size : 출력 크기（MNIST의 경우엔 10）\n",
    "    activation : 활성화 함수 - 'relu' 혹은 'sigmoid'\n",
    "    weight_init_std : 가중치의 표준편차 지정（e.g. 0.01）\n",
    "        'relu'나 'he'로 지정하면 'He 초깃값'으로 설정\n",
    "        'sigmoid'나 'xavier'로 지정하면 'Xavier 초깃값'으로 설정\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "        \n",
    "        \n",
    "# ====================================== 여기까지가 초기화 =============================================\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"손실 함수를 구한다.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다(오차역전파법).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-stranger",
   "metadata": {},
   "source": [
    "### 학습 알고리즘 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-applicant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.300128147929024\n",
      "=== epoch:1, train acc:0.24, test acc:0.24 ===\n",
      "train loss:2.2982954570120286\n",
      "train loss:2.2924145060397194\n",
      "train loss:2.2863589475256627\n",
      "train loss:2.275980630474982\n",
      "train loss:2.2592918867088145\n",
      "train loss:2.2583229245448275\n",
      "train loss:2.219414120649185\n",
      "train loss:2.2231167441026285\n",
      "train loss:2.1783174934848946\n",
      "train loss:2.1624609101390164\n",
      "train loss:2.132356204184751\n",
      "train loss:2.0805731294428966\n",
      "train loss:2.0512358185958703\n",
      "train loss:1.9858004483001575\n",
      "train loss:1.9006868056124135\n",
      "train loss:1.8583023861284713\n",
      "train loss:1.8251104137889638\n",
      "train loss:1.7319297149537975\n",
      "train loss:1.646967824506188\n",
      "train loss:1.5805233054075978\n",
      "train loss:1.5027700042338168\n",
      "train loss:1.416229941914942\n",
      "train loss:1.2326947084617912\n",
      "train loss:1.2494080007716408\n",
      "train loss:1.2319665922050274\n",
      "train loss:1.130676173491968\n",
      "train loss:1.097684282661787\n",
      "train loss:1.0845037698935185\n",
      "train loss:0.9017328196605426\n",
      "train loss:0.9855261417091823\n",
      "train loss:0.9508069116447517\n",
      "train loss:0.8466976842839142\n",
      "train loss:0.832358773048131\n",
      "train loss:0.8141016398281661\n",
      "train loss:0.8601693157670256\n",
      "train loss:0.7141362921042078\n",
      "train loss:0.6151644809875403\n",
      "train loss:0.6879035587020755\n",
      "train loss:0.6544821908424797\n",
      "train loss:0.7324861076610598\n",
      "train loss:0.5145525961608662\n",
      "train loss:0.6191063279871917\n",
      "train loss:0.5159793296307371\n",
      "train loss:0.616732397822911\n",
      "train loss:0.5690880849122038\n",
      "train loss:0.5664657226441907\n",
      "train loss:0.5275954768521236\n",
      "train loss:0.39543980858585526\n",
      "train loss:0.42908820157740896\n",
      "train loss:0.5707310972306133\n",
      "train loss:0.48994514566476405\n",
      "train loss:0.5416099078272704\n",
      "train loss:0.5622273767289163\n",
      "train loss:0.4094370983343954\n",
      "train loss:0.5395197610130305\n",
      "train loss:0.7794135833696485\n",
      "train loss:0.5836315288722951\n",
      "train loss:0.4570823814916875\n",
      "train loss:0.37705593761433326\n",
      "train loss:0.43076538872964215\n",
      "train loss:0.5132934194532421\n",
      "train loss:0.3845244880270471\n",
      "train loss:0.40878799290511253\n",
      "train loss:0.6166561021267873\n",
      "train loss:0.4481365397127724\n",
      "train loss:0.6020471426495508\n",
      "train loss:0.7065779141868614\n",
      "train loss:0.41165005511337915\n",
      "train loss:0.5625110324465055\n",
      "train loss:0.514761852558803\n",
      "train loss:0.43920371626208016\n",
      "train loss:0.4759397754314876\n",
      "train loss:0.4347540698887481\n",
      "train loss:0.5217040763085117\n",
      "train loss:0.4225678129749347\n",
      "train loss:0.370269788185505\n",
      "train loss:0.4021577805594583\n",
      "train loss:0.5677631026966177\n",
      "train loss:0.4008124617267277\n",
      "train loss:0.5747350977725958\n",
      "train loss:0.5569795764798808\n",
      "train loss:0.29479613309067143\n",
      "train loss:0.39306196805257343\n",
      "train loss:0.30695185749706594\n",
      "train loss:0.38130666310370415\n",
      "train loss:0.39626501901276734\n",
      "train loss:0.3288306504566598\n",
      "train loss:0.4091792098745255\n",
      "train loss:0.4631928687585718\n",
      "train loss:0.4765814659934757\n",
      "train loss:0.30159395961966556\n",
      "train loss:0.5248045209842415\n",
      "train loss:0.293514524152933\n",
      "train loss:0.3041387418425216\n",
      "train loss:0.33565344718363\n",
      "train loss:0.6749097022367585\n",
      "train loss:0.47318168502156893\n",
      "train loss:0.3870138093338518\n",
      "train loss:0.47648445459394023\n",
      "train loss:0.44813211206515285\n",
      "train loss:0.2984848712843785\n",
      "train loss:0.3080693269008616\n",
      "train loss:0.5233842720559686\n",
      "train loss:0.5561815693816393\n",
      "train loss:0.3166949271890638\n",
      "train loss:0.23873206926238288\n",
      "train loss:0.36810329089375193\n",
      "train loss:0.3982852225040898\n",
      "train loss:0.44270876311728935\n",
      "train loss:0.46935824138842297\n",
      "train loss:0.4596451491097418\n",
      "train loss:0.2845326565457384\n",
      "train loss:0.4831138673285442\n",
      "train loss:0.5204338037973383\n",
      "train loss:0.45040627845943987\n",
      "train loss:0.5694448113475774\n",
      "train loss:0.4142781205614381\n",
      "train loss:0.2596719628795359\n",
      "train loss:0.3273496977957075\n",
      "train loss:0.4186357753363275\n",
      "train loss:0.3434336900999649\n",
      "train loss:0.4035178927006029\n",
      "train loss:0.28627747964908945\n",
      "train loss:0.3024521814727326\n",
      "train loss:0.36003588340368897\n",
      "train loss:0.47408702754520865\n",
      "train loss:0.2801704474599509\n",
      "train loss:0.4765693878800146\n",
      "train loss:0.473746133805222\n",
      "train loss:0.2675911398788999\n",
      "train loss:0.34267282944183575\n",
      "train loss:0.591729761681579\n",
      "train loss:0.4514734370827041\n",
      "train loss:0.2929823431190483\n",
      "train loss:0.20279893851816724\n",
      "train loss:0.2149623463939775\n",
      "train loss:0.348951248172842\n",
      "train loss:0.3155000698405749\n",
      "train loss:0.43416074746921346\n",
      "train loss:0.3165608954300953\n",
      "train loss:0.495106289854068\n",
      "train loss:0.4096013066942597\n",
      "train loss:0.3814678835476629\n",
      "train loss:0.2546075038818246\n",
      "train loss:0.26968318172083733\n",
      "train loss:0.287759201626152\n",
      "train loss:0.23009462800287347\n",
      "train loss:0.38306060672598796\n",
      "train loss:0.47185358429710605\n",
      "train loss:0.3772583375874538\n",
      "train loss:0.38528254352749974\n",
      "train loss:0.3805742004692389\n",
      "train loss:0.33867007390511644\n",
      "train loss:0.368258082766729\n",
      "train loss:0.2965742740706742\n",
      "train loss:0.27734567627817835\n",
      "train loss:0.3072375428726286\n",
      "train loss:0.2989941060002457\n",
      "train loss:0.297580453166993\n",
      "train loss:0.29046703439971244\n",
      "train loss:0.3311073765937105\n",
      "train loss:0.3183893755605345\n",
      "train loss:0.29103064571633724\n",
      "train loss:0.3402451845435619\n",
      "train loss:0.2953724062900478\n",
      "train loss:0.2819466143831293\n",
      "train loss:0.3076574778253613\n",
      "train loss:0.19474715376994628\n",
      "train loss:0.36211625354089266\n",
      "train loss:0.1800926636972504\n",
      "train loss:0.4755981313144915\n",
      "train loss:0.2128563774972512\n",
      "train loss:0.2336650595451918\n",
      "train loss:0.4238410729246212\n",
      "train loss:0.4127967974537045\n",
      "train loss:0.251965994452402\n",
      "train loss:0.22460232240658193\n",
      "train loss:0.3238975756423419\n",
      "train loss:0.3736658739943512\n",
      "train loss:0.3840628037903811\n",
      "train loss:0.2726987910577195\n",
      "train loss:0.2857524414052041\n",
      "train loss:0.2763986590319884\n",
      "train loss:0.37535882191861475\n",
      "train loss:0.23390277436416063\n",
      "train loss:0.21063084961958148\n",
      "train loss:0.4520319572934362\n",
      "train loss:0.3353543971685972\n",
      "train loss:0.16728848958689796\n",
      "train loss:0.27421335543563896\n",
      "train loss:0.29646549360710506\n",
      "train loss:0.4444975716826521\n",
      "train loss:0.4225193363901031\n",
      "train loss:0.34992011677384804\n",
      "train loss:0.35649299892843594\n",
      "train loss:0.3370301626307356\n",
      "train loss:0.28149060858862135\n",
      "train loss:0.4148542183323297\n",
      "train loss:0.31139339000504246\n",
      "train loss:0.360904471470733\n",
      "train loss:0.3820211832016001\n",
      "train loss:0.2858614086491047\n",
      "train loss:0.3436964055930706\n",
      "train loss:0.3501255533203937\n",
      "train loss:0.23652575934334463\n",
      "train loss:0.32532725838047805\n",
      "train loss:0.1417144870250694\n",
      "train loss:0.3229016336591995\n",
      "train loss:0.2812749439916264\n",
      "train loss:0.37564148587978397\n",
      "train loss:0.23311442534707105\n",
      "train loss:0.34283006149572137\n",
      "train loss:0.2228327899507685\n",
      "train loss:0.19582752256279523\n",
      "train loss:0.3690695361894231\n",
      "train loss:0.15580211629130258\n",
      "train loss:0.23859342415127785\n",
      "train loss:0.3390718595322377\n",
      "train loss:0.25382704200889916\n",
      "train loss:0.2893573179976667\n",
      "train loss:0.29823046362690914\n",
      "train loss:0.29353925445140566\n",
      "train loss:0.20487621966258726\n",
      "train loss:0.28706526153165257\n",
      "train loss:0.25088418175930177\n",
      "train loss:0.21891036339995726\n",
      "train loss:0.21380894070939263\n",
      "train loss:0.2401900833688204\n",
      "train loss:0.32068990752023135\n",
      "train loss:0.27403583227154615\n",
      "train loss:0.2913709611539066\n",
      "train loss:0.24473052551144467\n",
      "train loss:0.21496641961694204\n",
      "train loss:0.29001452213022344\n",
      "train loss:0.3518487939517786\n",
      "train loss:0.21651439321024019\n",
      "train loss:0.490092825545441\n",
      "train loss:0.417695992072301\n",
      "train loss:0.26978393673451617\n",
      "train loss:0.1653908509640723\n",
      "train loss:0.32244133330066627\n",
      "train loss:0.2456541056058271\n",
      "train loss:0.4238196287348255\n",
      "train loss:0.30709387877729183\n",
      "train loss:0.2877785102868581\n",
      "train loss:0.15213554042968458\n",
      "train loss:0.38780751872056\n",
      "train loss:0.28956646151078436\n",
      "train loss:0.4229321250933515\n",
      "train loss:0.18655026799885677\n",
      "train loss:0.2438752283895899\n",
      "train loss:0.21280379343599903\n",
      "train loss:0.19651483839350806\n",
      "train loss:0.19306219069603292\n",
      "train loss:0.18120222781757322\n",
      "train loss:0.19672351277933253\n",
      "train loss:0.31913542572694936\n",
      "train loss:0.2860625903083625\n",
      "train loss:0.18901695598120227\n",
      "train loss:0.22614928537807114\n",
      "train loss:0.321374857359449\n",
      "train loss:0.40525071757427705\n",
      "train loss:0.2686882770720071\n",
      "train loss:0.27643999186424895\n",
      "train loss:0.15528266665850107\n",
      "train loss:0.18549252137248973\n",
      "train loss:0.20187512638097327\n",
      "train loss:0.302097344018379\n",
      "train loss:0.1595427460156491\n",
      "train loss:0.23184423732278397\n",
      "train loss:0.20238528108897733\n",
      "train loss:0.16563196055734047\n",
      "train loss:0.156061364674415\n",
      "train loss:0.3358580888063746\n",
      "train loss:0.16945688047162694\n",
      "train loss:0.19427600594467787\n",
      "train loss:0.3472010686088823\n",
      "train loss:0.24613681526039105\n",
      "train loss:0.281409700305305\n",
      "train loss:0.33579889388685125\n",
      "train loss:0.22479742233405836\n",
      "train loss:0.14462004197251438\n",
      "train loss:0.2116495320778031\n",
      "train loss:0.1775948426998838\n",
      "train loss:0.3364116183055512\n",
      "train loss:0.2036941569650514\n",
      "train loss:0.23868095239622972\n",
      "train loss:0.2810447956004597\n",
      "train loss:0.12551970578947105\n",
      "train loss:0.18537074395748174\n",
      "train loss:0.1438703887040493\n",
      "train loss:0.09855432041881049\n",
      "train loss:0.21950662553125577\n",
      "train loss:0.2241342495652395\n",
      "train loss:0.19736932634704737\n",
      "train loss:0.2655662951972832\n",
      "train loss:0.23943900816291136\n",
      "train loss:0.22659672526223865\n",
      "train loss:0.2635207280846892\n",
      "train loss:0.171583386779695\n",
      "train loss:0.19122464024723582\n",
      "train loss:0.2654241489093397\n",
      "train loss:0.2591435521836391\n",
      "train loss:0.18937682816168222\n",
      "train loss:0.19867325632769128\n",
      "train loss:0.29171097537405655\n",
      "train loss:0.2762649303276964\n",
      "train loss:0.16477237337585537\n",
      "train loss:0.27782281784819135\n",
      "train loss:0.2625382673212348\n",
      "train loss:0.39909326825928354\n",
      "train loss:0.2531679740197284\n",
      "train loss:0.19016180554854986\n",
      "train loss:0.1302632366550255\n",
      "train loss:0.2521760691726016\n",
      "train loss:0.17630011522455175\n",
      "train loss:0.18935340832041464\n",
      "train loss:0.2231134971357548\n",
      "train loss:0.26404218130565416\n",
      "train loss:0.10037527605137832\n",
      "train loss:0.2059733795506192\n",
      "train loss:0.11565116825483222\n",
      "train loss:0.1682556232266208\n",
      "train loss:0.19704599929546174\n",
      "train loss:0.200126958097245\n",
      "train loss:0.24245935068679236\n",
      "train loss:0.19682236052874308\n",
      "train loss:0.21829395426866363\n",
      "train loss:0.20642477405696316\n",
      "train loss:0.13422335935380153\n",
      "train loss:0.24468654806271262\n",
      "train loss:0.17380152453199055\n",
      "train loss:0.14388709171732258\n",
      "train loss:0.32864910455822866\n",
      "train loss:0.21436620462504588\n",
      "train loss:0.3287291928144755\n",
      "train loss:0.2681648290884384\n",
      "train loss:0.1864074183595611\n",
      "train loss:0.2852534190034291\n",
      "train loss:0.17561083478259396\n",
      "train loss:0.15421972370937592\n",
      "train loss:0.24416211803250898\n",
      "train loss:0.2174103131358626\n",
      "train loss:0.22864271623643012\n",
      "train loss:0.3144426847671519\n",
      "train loss:0.2061616493347346\n",
      "train loss:0.18045775670860198\n",
      "train loss:0.1611224763821154\n",
      "train loss:0.22110772088919856\n",
      "train loss:0.1899018026458651\n",
      "train loss:0.4993745392123408\n",
      "train loss:0.15208845109267885\n",
      "train loss:0.3242031504058943\n",
      "train loss:0.16720038551226235\n",
      "train loss:0.0802801806918974\n",
      "train loss:0.1967841194937766\n",
      "train loss:0.12508531707753556\n",
      "train loss:0.27461636885022256\n",
      "train loss:0.2262256404424905\n",
      "train loss:0.2751254454215275\n",
      "train loss:0.17818710349346767\n",
      "train loss:0.09993822816734813\n",
      "train loss:0.3095916559353194\n",
      "train loss:0.1110032689466584\n",
      "train loss:0.1369789871649329\n",
      "train loss:0.21380979178161014\n",
      "train loss:0.2526701969858013\n",
      "train loss:0.22351720354530635\n",
      "train loss:0.19392418393036695\n",
      "train loss:0.14384964679306003\n",
      "train loss:0.2252729507380635\n",
      "train loss:0.08569577786898437\n",
      "train loss:0.26629989315958036\n",
      "train loss:0.2529374204590969\n",
      "train loss:0.19725776349769986\n",
      "train loss:0.1621090529206026\n",
      "train loss:0.2325510463086785\n",
      "train loss:0.30516380053610975\n",
      "train loss:0.13860985481679824\n",
      "train loss:0.21059496725655114\n",
      "train loss:0.20512395959560706\n",
      "train loss:0.24481415096575812\n",
      "train loss:0.11898637285991245\n",
      "train loss:0.15716951625310735\n",
      "train loss:0.1413564732601599\n",
      "train loss:0.08257813068068925\n",
      "train loss:0.20632327010299534\n",
      "train loss:0.1840960888565871\n",
      "train loss:0.32330119038445915\n",
      "train loss:0.173650704562042\n",
      "train loss:0.24605339291733017\n",
      "train loss:0.07974276464817376\n",
      "train loss:0.14755562525732555\n",
      "train loss:0.10668238233511845\n",
      "train loss:0.16902616274013593\n",
      "train loss:0.2569313105386607\n",
      "train loss:0.143758785373831\n",
      "train loss:0.21000773974180528\n",
      "train loss:0.186011883058267\n",
      "train loss:0.21650031067119638\n",
      "train loss:0.15737204606067295\n",
      "train loss:0.25484407848191926\n",
      "train loss:0.08784968376096595\n",
      "train loss:0.1751690200424016\n",
      "train loss:0.09641452805408685\n",
      "train loss:0.13566576293790356\n",
      "train loss:0.10898588655221803\n",
      "train loss:0.16199313175004423\n",
      "train loss:0.20763481307198578\n",
      "train loss:0.17499585609251705\n",
      "train loss:0.2967924829019539\n",
      "train loss:0.0892206136182691\n",
      "train loss:0.0779737315551611\n",
      "train loss:0.15086183861827582\n",
      "train loss:0.12250550042033904\n",
      "train loss:0.14468201368780817\n",
      "train loss:0.13335697334310914\n",
      "train loss:0.062108590288945796\n",
      "train loss:0.19310743671803973\n",
      "train loss:0.21626869854418035\n",
      "train loss:0.20308700713031183\n",
      "train loss:0.11788910081253472\n",
      "train loss:0.11557995426338977\n",
      "train loss:0.35635977617709136\n",
      "train loss:0.22108556056209758\n",
      "train loss:0.20487399714508278\n",
      "train loss:0.10965153540147543\n",
      "train loss:0.14250217019692643\n",
      "train loss:0.196260281294038\n",
      "train loss:0.12175886289733012\n",
      "train loss:0.20848481971212574\n",
      "train loss:0.14031274010600717\n",
      "train loss:0.20779860867122588\n",
      "train loss:0.17897072033497885\n",
      "train loss:0.11957344066029994\n",
      "train loss:0.1993631000443364\n",
      "train loss:0.18672853515283155\n",
      "train loss:0.14353819192250067\n",
      "train loss:0.10135329445395871\n",
      "train loss:0.32289417179031177\n",
      "train loss:0.15400457435856546\n",
      "train loss:0.3025193228258251\n",
      "train loss:0.1538031487429235\n",
      "train loss:0.19118584702352692\n",
      "train loss:0.08692366899790818\n",
      "train loss:0.229315706448003\n",
      "train loss:0.16177255024163562\n",
      "train loss:0.11812548989654671\n",
      "train loss:0.2628068483828922\n",
      "train loss:0.1418391900822766\n",
      "train loss:0.22112408739093398\n",
      "train loss:0.12288265472194414\n",
      "train loss:0.1340165908203814\n",
      "train loss:0.20485508088464377\n",
      "train loss:0.18242412279051926\n",
      "train loss:0.2560460963365834\n",
      "train loss:0.1362719044211843\n",
      "train loss:0.25899979529541667\n",
      "train loss:0.16052483102245113\n",
      "train loss:0.10686060529015207\n",
      "train loss:0.23494493604353905\n",
      "train loss:0.18020953214104946\n",
      "train loss:0.16624466498455542\n",
      "train loss:0.29165393520451366\n",
      "train loss:0.2502384747010406\n",
      "train loss:0.2666491610491579\n",
      "train loss:0.2196232224634112\n",
      "train loss:0.14525249407346771\n",
      "train loss:0.1897172130242661\n",
      "train loss:0.1904704428694291\n",
      "train loss:0.1180182775460488\n",
      "train loss:0.133073420264923\n",
      "train loss:0.16157886882498992\n",
      "train loss:0.159774197718364\n",
      "train loss:0.2520290552817205\n",
      "train loss:0.14510121185521715\n",
      "train loss:0.2709847447966456\n",
      "train loss:0.10996354168229133\n",
      "train loss:0.2161545345316786\n",
      "train loss:0.08232200329340006\n",
      "train loss:0.15164197324030135\n",
      "train loss:0.19899171468442442\n",
      "train loss:0.09074806382196089\n",
      "train loss:0.10844240590039106\n",
      "train loss:0.1537479167184461\n",
      "train loss:0.19991692448143322\n",
      "train loss:0.16483511880094678\n",
      "train loss:0.1374651593989714\n",
      "train loss:0.20762042682352708\n",
      "train loss:0.17905297877187057\n",
      "train loss:0.223737324403351\n",
      "train loss:0.40992443151392577\n",
      "train loss:0.11889685491439525\n",
      "train loss:0.14237445640859472\n",
      "train loss:0.16892709225222002\n",
      "train loss:0.12753950442992823\n",
      "train loss:0.14330467953671464\n",
      "train loss:0.21353072731585399\n",
      "train loss:0.19125124976787689\n",
      "train loss:0.19015058493347667\n",
      "train loss:0.20755764536347435\n",
      "train loss:0.07537201478446263\n",
      "train loss:0.06867181654436237\n",
      "train loss:0.24050671244072547\n",
      "train loss:0.09743808180975329\n",
      "train loss:0.23727358181627664\n",
      "train loss:0.18951719937202668\n",
      "train loss:0.12865720525890773\n",
      "train loss:0.15175926166100076\n",
      "train loss:0.15797236449769544\n",
      "train loss:0.1532499942370303\n",
      "train loss:0.1379818070056604\n",
      "train loss:0.08562041262371531\n",
      "train loss:0.09675373361341802\n",
      "train loss:0.2923202178669359\n",
      "train loss:0.20271672854646383\n",
      "train loss:0.25332022203276033\n",
      "train loss:0.19815063835319957\n",
      "train loss:0.18383316256927512\n",
      "train loss:0.3000602149609607\n",
      "train loss:0.1463613933785168\n",
      "train loss:0.08396588464534258\n",
      "train loss:0.263862190329152\n",
      "train loss:0.09828924681293445\n",
      "train loss:0.15252082861570201\n",
      "train loss:0.20843624664874802\n",
      "train loss:0.17896304336239066\n",
      "train loss:0.1910513320578927\n",
      "train loss:0.18090006743444703\n",
      "train loss:0.2014693033968933\n",
      "train loss:0.12236809569200012\n",
      "train loss:0.2012012417215499\n",
      "train loss:0.16521244018338765\n",
      "train loss:0.19174863515393617\n",
      "train loss:0.18071306055960104\n",
      "train loss:0.13441839865703054\n",
      "train loss:0.1794042486016413\n",
      "train loss:0.1518648272901629\n",
      "train loss:0.19541813724329046\n",
      "train loss:0.1331157446656102\n",
      "train loss:0.13105926783855049\n",
      "train loss:0.16074312668256646\n",
      "train loss:0.27372172802871025\n",
      "train loss:0.16312658393968646\n",
      "train loss:0.12821565843085106\n",
      "train loss:0.22167163503539694\n",
      "train loss:0.17616706243935543\n",
      "train loss:0.2500468689876244\n",
      "train loss:0.09352543924677187\n",
      "train loss:0.11360038848456211\n",
      "train loss:0.10653898653247504\n",
      "train loss:0.12486453795676271\n",
      "train loss:0.1295350954138975\n",
      "train loss:0.09022511176085218\n",
      "train loss:0.10305492619151108\n",
      "train loss:0.22968580829879973\n",
      "train loss:0.16540201774362945\n",
      "train loss:0.16838291397252103\n",
      "train loss:0.14482019836181045\n",
      "train loss:0.09874372089792567\n",
      "train loss:0.07872270859029516\n",
      "train loss:0.13153517463147119\n",
      "train loss:0.24196359140885665\n",
      "train loss:0.20247147239733607\n",
      "train loss:0.07190023361013287\n",
      "train loss:0.06705222797517733\n",
      "train loss:0.2014909578291993\n",
      "train loss:0.17046228843992245\n",
      "train loss:0.18060603705163394\n",
      "train loss:0.17532145313799152\n",
      "train loss:0.10005022707953422\n",
      "train loss:0.11326598574012683\n",
      "train loss:0.10649196913284319\n",
      "train loss:0.2045098915964076\n",
      "train loss:0.19211164214213863\n",
      "train loss:0.15591697386373218\n",
      "train loss:0.09056055212454392\n",
      "train loss:0.19800158245422772\n",
      "train loss:0.23743946026279514\n",
      "train loss:0.2052512502395789\n",
      "train loss:0.2380333912350229\n",
      "train loss:0.1290562073235332\n",
      "train loss:0.10770591089969683\n",
      "train loss:0.09019300071978611\n",
      "train loss:0.1598150610348094\n",
      "train loss:0.03795837502025826\n",
      "train loss:0.10577941712528764\n",
      "train loss:0.10815508363535324\n",
      "train loss:0.14643795860853143\n",
      "train loss:0.20412543171647501\n",
      "train loss:0.10833412486418106\n",
      "train loss:0.12688039775648977\n",
      "train loss:0.1459085556684211\n",
      "train loss:0.26230950907446465\n",
      "train loss:0.08472058965903649\n",
      "train loss:0.10702424541362614\n",
      "train loss:0.09488537007276615\n",
      "train loss:0.1007384397386763\n",
      "train loss:0.09419296696915135\n",
      "train loss:0.1594447320688024\n",
      "=== epoch:2, train acc:0.955, test acc:0.958 ===\n",
      "train loss:0.13808362882605135\n",
      "train loss:0.1125199390302087\n",
      "train loss:0.15920355171574754\n",
      "train loss:0.1676898799244393\n",
      "train loss:0.07090102506760979\n",
      "train loss:0.09598513007393457\n",
      "train loss:0.10150329108847095\n",
      "train loss:0.07459746722256393\n",
      "train loss:0.14380308666576305\n",
      "train loss:0.0624203362263799\n",
      "train loss:0.17110589286589387\n",
      "train loss:0.24497928094113555\n",
      "train loss:0.20423204670412418\n",
      "train loss:0.07160560541457649\n",
      "train loss:0.10215055541257595\n",
      "train loss:0.16132527656434298\n",
      "train loss:0.19022298143286023\n",
      "train loss:0.16738014881215652\n",
      "train loss:0.16863799785269706\n",
      "train loss:0.1562665290860921\n",
      "train loss:0.12997774303709347\n",
      "train loss:0.15273623159438132\n",
      "train loss:0.11463540336063544\n",
      "train loss:0.11511634230579298\n",
      "train loss:0.13683050119552267\n",
      "train loss:0.1930403971463544\n",
      "train loss:0.13474564619629567\n",
      "train loss:0.19232470883546365\n",
      "train loss:0.07082467438005828\n",
      "train loss:0.1358178481664643\n",
      "train loss:0.17616820816927045\n",
      "train loss:0.11867822068584191\n",
      "train loss:0.08427034550334855\n",
      "train loss:0.22816910103430327\n",
      "train loss:0.24763803001981066\n",
      "train loss:0.13209726513661166\n",
      "train loss:0.09798348873212229\n",
      "train loss:0.1361368125428568\n",
      "train loss:0.1346548813839023\n",
      "train loss:0.11976700878703742\n",
      "train loss:0.07187411019519957\n",
      "train loss:0.07665636595734018\n",
      "train loss:0.10253775874552808\n",
      "train loss:0.20338144265282052\n",
      "train loss:0.10385822219870956\n",
      "train loss:0.17762586929613464\n",
      "train loss:0.06942881399236656\n",
      "train loss:0.14224702363484074\n",
      "train loss:0.13996168254944963\n",
      "train loss:0.07895818183090778\n",
      "train loss:0.10731735127088214\n",
      "train loss:0.09575046711175979\n",
      "train loss:0.04841535631865156\n",
      "train loss:0.15086573197623643\n",
      "train loss:0.09063271932273477\n",
      "train loss:0.07130611578655859\n",
      "train loss:0.07431846910984433\n",
      "train loss:0.1857471357981407\n",
      "train loss:0.10138973171023796\n",
      "train loss:0.05933359087905033\n",
      "train loss:0.072724521614424\n",
      "train loss:0.12496990306039259\n",
      "train loss:0.16730411111506122\n",
      "train loss:0.10615670206148563\n",
      "train loss:0.21557859767778315\n",
      "train loss:0.09871024129787663\n",
      "train loss:0.12805942966987435\n",
      "train loss:0.08026526283596759\n",
      "train loss:0.10563631232203323\n",
      "train loss:0.18248391407920994\n",
      "train loss:0.09014265238783883\n",
      "train loss:0.10824996447708939\n",
      "train loss:0.05776578655902874\n",
      "train loss:0.13292650943644774\n",
      "train loss:0.150544529666682\n",
      "train loss:0.10484960539629441\n",
      "train loss:0.11372136810540584\n",
      "train loss:0.06944199250565214\n",
      "train loss:0.1025975628441399\n",
      "train loss:0.054796250919750225\n",
      "train loss:0.08194728160375117\n",
      "train loss:0.07172409390459267\n",
      "train loss:0.09290535429237304\n",
      "train loss:0.09218605837590127\n",
      "train loss:0.12581550661501925\n",
      "train loss:0.14880277412986748\n",
      "train loss:0.030525769717312686\n",
      "train loss:0.06758544914945977\n",
      "train loss:0.22362326826331494\n",
      "train loss:0.19129961157379852\n",
      "train loss:0.09330457771542124\n",
      "train loss:0.12620457310538455\n",
      "train loss:0.1169967075956585\n",
      "train loss:0.17419521623310222\n",
      "train loss:0.09740590030138627\n",
      "train loss:0.06574963129715511\n",
      "train loss:0.09340788667023657\n",
      "train loss:0.07874516774213258\n",
      "train loss:0.17382372519733758\n",
      "train loss:0.09371582816953192\n",
      "train loss:0.18955387045476232\n",
      "train loss:0.06338536881692042\n",
      "train loss:0.05949816331291727\n",
      "train loss:0.13427282252301656\n",
      "train loss:0.08462677050538998\n",
      "train loss:0.1023799254506629\n",
      "train loss:0.17772544810228086\n",
      "train loss:0.2426443697368271\n",
      "train loss:0.17225522982769217\n",
      "train loss:0.03999796184841196\n",
      "train loss:0.12216951072189002\n",
      "train loss:0.19816419401109708\n",
      "train loss:0.1015598769919817\n",
      "train loss:0.14195315488458307\n",
      "train loss:0.11584381817119807\n",
      "train loss:0.04045500231336109\n",
      "train loss:0.1153788861085147\n",
      "train loss:0.10139009779726069\n",
      "train loss:0.08030028890119054\n",
      "train loss:0.13815059273305919\n",
      "train loss:0.17139152590053355\n",
      "train loss:0.19668795117664228\n",
      "train loss:0.18914337251228852\n",
      "train loss:0.0880758877038974\n",
      "train loss:0.0826138694727797\n",
      "train loss:0.03680917212365092\n",
      "train loss:0.09777821146365476\n",
      "train loss:0.07881069459186225\n",
      "train loss:0.16244469098843436\n",
      "train loss:0.12069537560300797\n",
      "train loss:0.0947128907257769\n",
      "train loss:0.0986624565735113\n",
      "train loss:0.1733799630509672\n",
      "train loss:0.06768794308103132\n",
      "train loss:0.07753739751345073\n",
      "train loss:0.28264415767596107\n",
      "train loss:0.08980061825274144\n",
      "train loss:0.07059278426756653\n",
      "train loss:0.08623032192190777\n",
      "train loss:0.12529230611979394\n",
      "train loss:0.19061106555019142\n",
      "train loss:0.16826895906677394\n",
      "train loss:0.10230272180131607\n",
      "train loss:0.08420439124043905\n",
      "train loss:0.1305849054507809\n",
      "train loss:0.03526977741802061\n",
      "train loss:0.10723069844896604\n",
      "train loss:0.06138238980185066\n",
      "train loss:0.15061384121935986\n",
      "train loss:0.06807609160232439\n",
      "train loss:0.10230576348199787\n",
      "train loss:0.14133728104591892\n",
      "train loss:0.06843175064255838\n",
      "train loss:0.05096109252358079\n",
      "train loss:0.10350192674223818\n",
      "train loss:0.16684466084224361\n",
      "train loss:0.051658946891788966\n",
      "train loss:0.12743509457870072\n",
      "train loss:0.03700877621503362\n",
      "train loss:0.1791929524127097\n",
      "train loss:0.08503356944704688\n",
      "train loss:0.10272967091191389\n",
      "train loss:0.12423966685370184\n",
      "train loss:0.08052630540008376\n",
      "train loss:0.07271873350112756\n",
      "train loss:0.0645333054408191\n",
      "train loss:0.061979905581087034\n",
      "train loss:0.10904339715368333\n",
      "train loss:0.09766862070543207\n",
      "train loss:0.12509616915359387\n",
      "train loss:0.091669660465959\n",
      "train loss:0.0800503761337747\n",
      "train loss:0.07966296190828882\n",
      "train loss:0.10831464258750452\n",
      "train loss:0.06870551019177999\n",
      "train loss:0.09915777217332904\n",
      "train loss:0.12210399132629032\n",
      "train loss:0.07661657449539472\n",
      "train loss:0.06803557012054448\n",
      "train loss:0.08857563274851143\n",
      "train loss:0.1410838681294855\n",
      "train loss:0.08879875608083988\n",
      "train loss:0.0660992498160762\n",
      "train loss:0.08110832995935865\n",
      "train loss:0.1172010011960506\n",
      "train loss:0.14557971122464328\n",
      "train loss:0.0700977696544304\n",
      "train loss:0.09781559455873466\n",
      "train loss:0.13560429748904526\n",
      "train loss:0.10463011307379495\n",
      "train loss:0.08910536863771922\n",
      "train loss:0.05456761526433766\n",
      "train loss:0.055539762405389805\n",
      "train loss:0.051636902005896455\n",
      "train loss:0.07076368303974331\n",
      "train loss:0.030478305134697608\n",
      "train loss:0.12624897906915214\n",
      "train loss:0.09359538752883305\n",
      "train loss:0.08297198940411771\n",
      "train loss:0.09445932563173141\n",
      "train loss:0.05167875056173577\n",
      "train loss:0.06509257414920853\n",
      "train loss:0.1254059081771607\n",
      "train loss:0.07825737622177983\n",
      "train loss:0.10787670082905641\n",
      "train loss:0.06468510526667175\n",
      "train loss:0.07769175438382289\n",
      "train loss:0.11251875321549706\n",
      "train loss:0.06897060516972164\n",
      "train loss:0.048885133456653324\n",
      "train loss:0.1318907683428203\n",
      "train loss:0.1392279077154078\n",
      "train loss:0.033969316376530424\n",
      "train loss:0.08579796375349608\n",
      "train loss:0.1678324975954128\n",
      "train loss:0.1401103718318336\n",
      "train loss:0.05203454811069287\n",
      "train loss:0.11207296593774246\n",
      "train loss:0.10077480620512132\n",
      "train loss:0.16179688182816257\n",
      "train loss:0.13415228638230978\n",
      "train loss:0.1301539594636382\n",
      "train loss:0.06727072325873308\n",
      "train loss:0.05516189244499145\n",
      "train loss:0.08508466455596868\n",
      "train loss:0.03596587986406004\n",
      "train loss:0.05095211841238828\n",
      "train loss:0.09910583648441744\n",
      "train loss:0.12571652444268783\n",
      "train loss:0.07496832836140244\n",
      "train loss:0.08629655052098585\n",
      "train loss:0.09484839212468682\n",
      "train loss:0.12718648725281348\n",
      "train loss:0.24828813224504434\n",
      "train loss:0.13258355085877105\n",
      "train loss:0.03821912090401101\n",
      "train loss:0.18619626449439622\n",
      "train loss:0.1286290626271169\n",
      "train loss:0.15070409254697836\n",
      "train loss:0.14727143872890205\n",
      "train loss:0.23940979160264939\n",
      "train loss:0.07795963296037313\n",
      "train loss:0.12736725967355672\n",
      "train loss:0.09663487590937989\n",
      "train loss:0.07027380397470483\n",
      "train loss:0.047264437679430935\n",
      "train loss:0.053039813560348696\n",
      "train loss:0.06933857403564711\n",
      "train loss:0.11722812215014355\n",
      "train loss:0.11506522431616212\n",
      "train loss:0.08098084492737621\n",
      "train loss:0.12487852535879401\n",
      "train loss:0.09951189593141291\n",
      "train loss:0.09241485425583715\n",
      "train loss:0.12319211454771395\n",
      "train loss:0.06999683530551341\n",
      "train loss:0.13498334225051598\n",
      "train loss:0.09922983445407914\n",
      "train loss:0.11307103711238245\n",
      "train loss:0.06479524456972399\n",
      "train loss:0.09328104596314465\n",
      "train loss:0.1557296227058134\n",
      "train loss:0.04163627950589227\n",
      "train loss:0.1779663658509884\n",
      "train loss:0.07350934620859649\n",
      "train loss:0.08103744025235567\n",
      "train loss:0.060231473332614104\n",
      "train loss:0.1616566789452363\n",
      "train loss:0.11362036831350762\n",
      "train loss:0.1689517846805028\n",
      "train loss:0.040528355130459257\n",
      "train loss:0.08523969781311633\n",
      "train loss:0.04736428973460145\n",
      "train loss:0.10200724612630602\n",
      "train loss:0.045919137069204155\n",
      "train loss:0.09435366630403128\n",
      "train loss:0.03962795406981877\n",
      "train loss:0.041399392936500454\n",
      "train loss:0.09647929900533019\n",
      "train loss:0.0950803522583061\n",
      "train loss:0.07381666067982594\n",
      "train loss:0.06839440109950622\n",
      "train loss:0.1494085969152698\n",
      "train loss:0.026675119396255286\n",
      "train loss:0.05514588681206306\n",
      "train loss:0.12937986767540557\n",
      "train loss:0.10440671528943125\n",
      "train loss:0.14166466334883093\n",
      "train loss:0.15724152545111614\n",
      "train loss:0.0503777872090809\n",
      "train loss:0.07027191567092428\n",
      "train loss:0.08574454163872343\n",
      "train loss:0.08853023083595624\n",
      "train loss:0.26607100725807087\n",
      "train loss:0.11373915809692736\n",
      "train loss:0.07565918213095152\n",
      "train loss:0.06859272669003276\n",
      "train loss:0.15456950857316282\n",
      "train loss:0.08990096291844867\n",
      "train loss:0.05389406133213345\n",
      "train loss:0.22306283466658036\n",
      "train loss:0.04672428184078241\n",
      "train loss:0.10139477807433166\n",
      "train loss:0.12376163753927134\n",
      "train loss:0.03171160412663825\n",
      "train loss:0.0789140460447725\n",
      "train loss:0.1489920441064006\n",
      "train loss:0.10409474484752707\n",
      "train loss:0.11116300987219388\n",
      "train loss:0.09418888163479139\n",
      "train loss:0.04585618742414091\n",
      "train loss:0.14538213874158776\n",
      "train loss:0.14225126537670024\n",
      "train loss:0.07711976991054366\n",
      "train loss:0.13766269992230115\n",
      "train loss:0.09481744071005872\n",
      "train loss:0.07847779436621219\n",
      "train loss:0.06368296403776418\n",
      "train loss:0.05264156281219537\n",
      "train loss:0.11487027192534006\n",
      "train loss:0.12432356983116455\n",
      "train loss:0.08817384767026132\n",
      "train loss:0.08533396096681449\n",
      "train loss:0.0786112633333813\n",
      "train loss:0.0783782418448212\n",
      "train loss:0.05299391379734037\n",
      "train loss:0.09004925255157105\n",
      "train loss:0.04387663904572342\n",
      "train loss:0.0952600626316552\n",
      "train loss:0.11646849824870299\n",
      "train loss:0.06607126169660767\n",
      "train loss:0.07303071573244342\n",
      "train loss:0.1310786352377466\n",
      "train loss:0.06925702209068063\n",
      "train loss:0.035682415591671894\n",
      "train loss:0.1321853309108552\n",
      "train loss:0.08548877185482466\n",
      "train loss:0.037615899477659066\n",
      "train loss:0.12904353061204155\n",
      "train loss:0.11584967602879011\n",
      "train loss:0.1553820914777825\n",
      "train loss:0.12514347555396066\n",
      "train loss:0.11868747291015311\n",
      "train loss:0.13459453125579748\n",
      "train loss:0.030023524966562975\n",
      "train loss:0.07362690693916518\n",
      "train loss:0.028591297036619858\n",
      "train loss:0.0324307343140581\n",
      "train loss:0.15411492309117264\n",
      "train loss:0.12733625980707142\n",
      "train loss:0.053003800066802234\n",
      "train loss:0.11026296360527493\n",
      "train loss:0.08871574111617879\n",
      "train loss:0.03153173957174173\n",
      "train loss:0.0750995882608836\n",
      "train loss:0.06702446558149967\n",
      "train loss:0.0551868872261671\n",
      "train loss:0.09756667353297895\n",
      "train loss:0.10640316507449325\n",
      "train loss:0.0855731978391099\n",
      "train loss:0.07372738893694619\n",
      "train loss:0.14172144762834243\n",
      "train loss:0.03155535092805657\n",
      "train loss:0.09206861759509245\n",
      "train loss:0.16630930506029318\n",
      "train loss:0.04118935468383047\n",
      "train loss:0.15081689147337762\n",
      "train loss:0.04489495829223663\n",
      "train loss:0.05588973972657165\n",
      "train loss:0.07031729879312572\n",
      "train loss:0.06217340959616003\n",
      "train loss:0.0537199972814935\n",
      "train loss:0.07287881780954239\n",
      "train loss:0.08258010890730573\n",
      "train loss:0.14631962985759867\n",
      "train loss:0.049278341160238145\n",
      "train loss:0.06483590510308596\n",
      "train loss:0.037922286513945413\n",
      "train loss:0.20216934508341516\n",
      "train loss:0.05866878892824424\n",
      "train loss:0.0684661267201445\n",
      "train loss:0.04248356941569085\n",
      "train loss:0.13374251378265115\n",
      "train loss:0.08886158700916832\n",
      "train loss:0.09129457799717279\n",
      "train loss:0.1723547976982995\n",
      "train loss:0.10796492639305745\n",
      "train loss:0.1482351459173946\n",
      "train loss:0.054351766172534795\n",
      "train loss:0.08569650570254166\n",
      "train loss:0.06943180492286236\n",
      "train loss:0.06571738007785005\n",
      "train loss:0.09305882149441363\n",
      "train loss:0.03620063959494133\n",
      "train loss:0.12407960385233778\n",
      "train loss:0.12323424476143002\n",
      "train loss:0.035147773262223334\n",
      "train loss:0.10268643484804083\n",
      "train loss:0.11112698047448456\n",
      "train loss:0.072812828640481\n",
      "train loss:0.1307034404171933\n",
      "train loss:0.06541189280990811\n",
      "train loss:0.17638257994565013\n",
      "train loss:0.07163911537471934\n",
      "train loss:0.20158525130382415\n",
      "train loss:0.05273029220922789\n",
      "train loss:0.06981072122452503\n",
      "train loss:0.06642465813172646\n",
      "train loss:0.10134902369490913\n",
      "train loss:0.03325995986199725\n",
      "train loss:0.04888207762436458\n",
      "train loss:0.05946887653085496\n",
      "train loss:0.1073291327768312\n",
      "train loss:0.13376977042718882\n",
      "train loss:0.06993825240807769\n",
      "train loss:0.09177401596317893\n",
      "train loss:0.02362731243767976\n",
      "train loss:0.07168034178171788\n",
      "train loss:0.09490980587047793\n",
      "train loss:0.05064392176326927\n",
      "train loss:0.051047501310125594\n",
      "train loss:0.04459945132732004\n",
      "train loss:0.08680304164553236\n",
      "train loss:0.05834170827964885\n",
      "train loss:0.05900577051825149\n",
      "train loss:0.05749886811762989\n",
      "train loss:0.09864902990501458\n",
      "train loss:0.11035959427405435\n",
      "train loss:0.053644024463522184\n",
      "train loss:0.08920881000652095\n",
      "train loss:0.11657051641613933\n",
      "train loss:0.04797178793294787\n",
      "train loss:0.023877217868159075\n",
      "train loss:0.10578333746000482\n",
      "train loss:0.06075343962276031\n",
      "train loss:0.07296862136036028\n",
      "train loss:0.04014263180176189\n",
      "train loss:0.06428756660354369\n",
      "train loss:0.10983006821948668\n",
      "train loss:0.04185022094004604\n",
      "train loss:0.0450417121827249\n",
      "train loss:0.09642659369495567\n",
      "train loss:0.08655541834114867\n",
      "train loss:0.054347667665357646\n",
      "train loss:0.09608542815959283\n",
      "train loss:0.1767319123059715\n",
      "train loss:0.17189531129392258\n",
      "train loss:0.09060532668233373\n",
      "train loss:0.08919843888442143\n",
      "train loss:0.12961797796903135\n",
      "train loss:0.08355787518948965\n",
      "train loss:0.062337862749163406\n",
      "train loss:0.22549344108709785\n",
      "train loss:0.14335356892705245\n",
      "train loss:0.1181061463532264\n",
      "train loss:0.07609663944803846\n",
      "train loss:0.0860923886041445\n",
      "train loss:0.07146357230844655\n",
      "train loss:0.06786490297851039\n",
      "train loss:0.20456706695966959\n",
      "train loss:0.05264237199203718\n",
      "train loss:0.0319272204481156\n",
      "train loss:0.06863067705805659\n",
      "train loss:0.13284053507017815\n",
      "train loss:0.05395763600549475\n",
      "train loss:0.021976338629731963\n",
      "train loss:0.09487946538440337\n",
      "train loss:0.0574771119838161\n",
      "train loss:0.09548710392311499\n",
      "train loss:0.062315384804730395\n",
      "train loss:0.10034449454906748\n",
      "train loss:0.08281695209125252\n",
      "train loss:0.05268934963511945\n",
      "train loss:0.17042518788498362\n",
      "train loss:0.0657013947056868\n",
      "train loss:0.0517180210573958\n",
      "train loss:0.10071727293541732\n",
      "train loss:0.04499252456681898\n",
      "train loss:0.0664032868859356\n",
      "train loss:0.060901207754847\n",
      "train loss:0.04331397761487238\n",
      "train loss:0.061089276131329334\n",
      "train loss:0.03337547423095143\n",
      "train loss:0.08738691335303794\n",
      "train loss:0.0937698205429459\n",
      "train loss:0.10171892008705828\n",
      "train loss:0.10588020953884651\n",
      "train loss:0.11597880420026657\n",
      "train loss:0.07491046872750115\n",
      "train loss:0.162260348768822\n",
      "train loss:0.04510379893331175\n",
      "train loss:0.04510895281429897\n",
      "train loss:0.10251044974754951\n",
      "train loss:0.06489015888813224\n",
      "train loss:0.09567064395254384\n",
      "train loss:0.12019965953366574\n",
      "train loss:0.12173599652634133\n",
      "train loss:0.03661528837388535\n",
      "train loss:0.06810098443692633\n",
      "train loss:0.10107186493065332\n",
      "train loss:0.058968315504808036\n",
      "train loss:0.04454256851933678\n",
      "train loss:0.03104404317596217\n",
      "train loss:0.15067749305102646\n",
      "train loss:0.060024632376324334\n",
      "train loss:0.07438712779712611\n",
      "train loss:0.03507392602156199\n",
      "train loss:0.09065857488871147\n",
      "train loss:0.05087754641091911\n",
      "train loss:0.07754621719273846\n",
      "train loss:0.12313628137726891\n",
      "train loss:0.05481188214564395\n",
      "train loss:0.11388429684734401\n",
      "train loss:0.12920821432152216\n",
      "train loss:0.07491338545617547\n",
      "train loss:0.03263363105602515\n",
      "train loss:0.03429908207006243\n",
      "train loss:0.04333595497700477\n",
      "train loss:0.07728100420551043\n",
      "train loss:0.07614869882975098\n",
      "train loss:0.07598029293516773\n",
      "train loss:0.07224588911704913\n",
      "train loss:0.03627122562074084\n",
      "train loss:0.03348543507760934\n",
      "train loss:0.19993204023346306\n",
      "train loss:0.03888038873128439\n",
      "train loss:0.024979163436464984\n",
      "train loss:0.03731040719450874\n",
      "train loss:0.06736767012160975\n",
      "train loss:0.05360923183588675\n",
      "train loss:0.06315537653877755\n",
      "train loss:0.08349837468364261\n",
      "train loss:0.10077919335227929\n",
      "train loss:0.09219507055930459\n",
      "train loss:0.0623596783093514\n",
      "train loss:0.07977873315504068\n",
      "train loss:0.04604230140589602\n",
      "train loss:0.08324747843595853\n",
      "train loss:0.16010987865279955\n",
      "train loss:0.0837255230345874\n",
      "train loss:0.11509992244795823\n",
      "train loss:0.0926574960393005\n",
      "train loss:0.07489100592712958\n",
      "train loss:0.05499593878856481\n",
      "train loss:0.06431245194326751\n",
      "train loss:0.03252334260992982\n",
      "train loss:0.030608591199599654\n",
      "train loss:0.042817190026771715\n",
      "train loss:0.10790930176312537\n",
      "train loss:0.15176696382899965\n",
      "train loss:0.10336684703967192\n",
      "train loss:0.0358098518301708\n",
      "train loss:0.15968330331799943\n",
      "train loss:0.11889762319358495\n",
      "train loss:0.04273025193063974\n",
      "train loss:0.05970793771468908\n",
      "train loss:0.04696267492568332\n",
      "train loss:0.05999284244350133\n",
      "train loss:0.12623575138706675\n",
      "train loss:0.05918012214234521\n",
      "train loss:0.09845407689733265\n",
      "train loss:0.04094157572895469\n",
      "train loss:0.04733327566642053\n",
      "train loss:0.047264161351841805\n",
      "train loss:0.036993880080147805\n",
      "train loss:0.08949758167817919\n",
      "train loss:0.09851587227870943\n",
      "train loss:0.12067027705818095\n",
      "train loss:0.06395949694667341\n",
      "train loss:0.059912697125089134\n",
      "train loss:0.030342752521269452\n",
      "train loss:0.03639643799694774\n",
      "train loss:0.029529446592100616\n",
      "train loss:0.042616436860288556\n",
      "train loss:0.03777527089173302\n",
      "train loss:0.09801434479643303\n",
      "train loss:0.09841491155764015\n",
      "train loss:0.0648121851159248\n",
      "train loss:0.032500620347827\n",
      "train loss:0.041888639554869114\n",
      "train loss:0.07782603103645797\n",
      "train loss:0.0485288407390126\n",
      "train loss:0.13292336411576205\n",
      "train loss:0.06349998603012433\n",
      "train loss:0.05509009048180061\n",
      "train loss:0.093645033676269\n",
      "train loss:0.04875904699135341\n",
      "train loss:0.09219532045910213\n",
      "train loss:0.05051562804410832\n",
      "train loss:0.06845897951676581\n",
      "train loss:0.09193910443865141\n",
      "train loss:0.055838122298755566\n",
      "train loss:0.10464249529434387\n",
      "train loss:0.13963812090633923\n",
      "train loss:0.06913188142768681\n",
      "train loss:0.03955321995847695\n",
      "train loss:0.0827792418100553\n",
      "train loss:0.07700115760280327\n",
      "train loss:0.06453691833405627\n",
      "train loss:0.07405892976095775\n",
      "=== epoch:3, train acc:0.97, test acc:0.969 ===\n",
      "train loss:0.035552641317829\n",
      "train loss:0.13438578711257318\n",
      "train loss:0.041929829674630874\n",
      "train loss:0.06006942170684636\n",
      "train loss:0.05946252832186899\n",
      "train loss:0.0677135507127551\n",
      "train loss:0.04412306016019424\n",
      "train loss:0.10873946198637743\n",
      "train loss:0.2304833912934005\n",
      "train loss:0.07806775578110714\n",
      "train loss:0.05978000781762491\n",
      "train loss:0.09667826615876088\n",
      "train loss:0.09016524849405684\n",
      "train loss:0.05506742213187635\n",
      "train loss:0.041445184015852864\n",
      "train loss:0.01757169337642244\n",
      "train loss:0.08676388041477776\n",
      "train loss:0.017898233723125923\n",
      "train loss:0.13576426262766947\n",
      "train loss:0.09445490279093\n",
      "train loss:0.10423984963167147\n",
      "train loss:0.07839493056542574\n",
      "train loss:0.08006958110637827\n",
      "train loss:0.12202934063499002\n",
      "train loss:0.08111401069174985\n",
      "train loss:0.02120176031978341\n",
      "train loss:0.04288117840800196\n",
      "train loss:0.05524443711023098\n",
      "train loss:0.08262428259723242\n",
      "train loss:0.09446797593299311\n",
      "train loss:0.04520123261114788\n",
      "train loss:0.08846480214025138\n",
      "train loss:0.12928519036334907\n",
      "train loss:0.03155979887627028\n",
      "train loss:0.027573759047940762\n",
      "train loss:0.10095377108170536\n",
      "train loss:0.11912634957613308\n",
      "train loss:0.04592191938472116\n",
      "train loss:0.11001827136343571\n",
      "train loss:0.0350902446424933\n",
      "train loss:0.09463260913398054\n",
      "train loss:0.06614818981442488\n",
      "train loss:0.0811261642771904\n",
      "train loss:0.038262154432881654\n",
      "train loss:0.038681981037881924\n",
      "train loss:0.04213058665787069\n",
      "train loss:0.04055986663690069\n",
      "train loss:0.07353801353046663\n",
      "train loss:0.07332819504250945\n",
      "train loss:0.09993807017529983\n",
      "train loss:0.07367712720433447\n",
      "train loss:0.053071001523950515\n",
      "train loss:0.08240996451286177\n",
      "train loss:0.024360802121325725\n",
      "train loss:0.045636805465965005\n",
      "train loss:0.05073723678622244\n",
      "train loss:0.04282729438751462\n",
      "train loss:0.09524041673308162\n",
      "train loss:0.026085934775910778\n",
      "train loss:0.0672202539012295\n",
      "train loss:0.06688554271828574\n",
      "train loss:0.12889482531675386\n",
      "train loss:0.04192294222380813\n",
      "train loss:0.02795633729586422\n",
      "train loss:0.06977194610640612\n",
      "train loss:0.09073482473955918\n",
      "train loss:0.014315222777545638\n",
      "train loss:0.054735305589121624\n",
      "train loss:0.0958868112052581\n",
      "train loss:0.02783963278737015\n",
      "train loss:0.03778019608774351\n",
      "train loss:0.057548311872144736\n",
      "train loss:0.08003937279547603\n",
      "train loss:0.08090471594420935\n",
      "train loss:0.020405857624394633\n",
      "train loss:0.047197760404612155\n",
      "train loss:0.13726660626060241\n",
      "train loss:0.02738703741302735\n",
      "train loss:0.0329560589072822\n",
      "train loss:0.07554647494526234\n",
      "train loss:0.07534742564857119\n",
      "train loss:0.043637288156440066\n",
      "train loss:0.021524683848904574\n",
      "train loss:0.032822055847999666\n",
      "train loss:0.04739326021352844\n",
      "train loss:0.05561938282628402\n",
      "train loss:0.08847130315599097\n",
      "train loss:0.037017914428033954\n",
      "train loss:0.03798897870986881\n",
      "train loss:0.11973393639749734\n",
      "train loss:0.09244002569560048\n",
      "train loss:0.05425302114342311\n",
      "train loss:0.039029015479191825\n",
      "train loss:0.09310425899905357\n",
      "train loss:0.04856408924504239\n",
      "train loss:0.09622692093667125\n",
      "train loss:0.13530708475440872\n",
      "train loss:0.018054485961947354\n",
      "train loss:0.04889030340712385\n",
      "train loss:0.13089863252379816\n",
      "train loss:0.03004812588724754\n",
      "train loss:0.03944856930062208\n",
      "train loss:0.02193995675619833\n",
      "train loss:0.025910300242311588\n",
      "train loss:0.043703482556485734\n",
      "train loss:0.04353909298797576\n",
      "train loss:0.0904711374815175\n",
      "train loss:0.0780200244397348\n",
      "train loss:0.11029503784653326\n",
      "train loss:0.10361125501456384\n",
      "train loss:0.04673901367243279\n",
      "train loss:0.04685309346331706\n",
      "train loss:0.05015351798091603\n",
      "train loss:0.10508342744028078\n",
      "train loss:0.09686325343763232\n",
      "train loss:0.030277783104790693\n",
      "train loss:0.05476996154947547\n",
      "train loss:0.0379713679522356\n",
      "train loss:0.03920288936873754\n",
      "train loss:0.027397559566604536\n",
      "train loss:0.08766335712229896\n",
      "train loss:0.11640784222071553\n",
      "train loss:0.12173971089469456\n",
      "train loss:0.12854065201050446\n",
      "train loss:0.09719508447258894\n",
      "train loss:0.05866658973533514\n",
      "train loss:0.03712022261273336\n",
      "train loss:0.025915410644553483\n",
      "train loss:0.06973219063260598\n",
      "train loss:0.05090881601045313\n",
      "train loss:0.06156100682634588\n",
      "train loss:0.009625866839899576\n",
      "train loss:0.10702952928275225\n",
      "train loss:0.057958986859697775\n",
      "train loss:0.11652630871605967\n",
      "train loss:0.04210781008055717\n",
      "train loss:0.024698454411271182\n",
      "train loss:0.10073807923859057\n",
      "train loss:0.016853098296107337\n",
      "train loss:0.023061530088824972\n",
      "train loss:0.04532677252954492\n",
      "train loss:0.039465439673512605\n",
      "train loss:0.030900654506265324\n",
      "train loss:0.020024932690656624\n",
      "train loss:0.040532265711462866\n",
      "train loss:0.0676682061586089\n",
      "train loss:0.0597206500642677\n",
      "train loss:0.08372478422671792\n",
      "train loss:0.01807807892940335\n",
      "train loss:0.07177256021593344\n",
      "train loss:0.11127086619054438\n",
      "train loss:0.031907480664127616\n",
      "train loss:0.09233020708593585\n",
      "train loss:0.06777210390387278\n",
      "train loss:0.08194063873967158\n",
      "train loss:0.08597172331003859\n",
      "train loss:0.1909819117172143\n",
      "train loss:0.05335801945477718\n",
      "train loss:0.06264760562596589\n",
      "train loss:0.034682876920684814\n",
      "train loss:0.042695234125353185\n",
      "train loss:0.14141706044245483\n",
      "train loss:0.08006306512406913\n",
      "train loss:0.024165836618807737\n",
      "train loss:0.05199208602939488\n",
      "train loss:0.03554305513673062\n",
      "train loss:0.25256218177230977\n",
      "train loss:0.0592501733450273\n",
      "train loss:0.03884172872653353\n",
      "train loss:0.04052688827299761\n",
      "train loss:0.04547127938858953\n",
      "train loss:0.06862448531654368\n",
      "train loss:0.07280611059861082\n",
      "train loss:0.07523830637196496\n",
      "train loss:0.09282707886882696\n",
      "train loss:0.027403481311343826\n",
      "train loss:0.05645952380909936\n",
      "train loss:0.1072691036769323\n",
      "train loss:0.10567028234227234\n",
      "train loss:0.04189272229571256\n",
      "train loss:0.027024283681183207\n",
      "train loss:0.019570180668755\n",
      "train loss:0.036327300975640846\n",
      "train loss:0.031109857721702744\n",
      "train loss:0.06188636006800876\n",
      "train loss:0.0656557212929644\n",
      "train loss:0.12459755533413544\n",
      "train loss:0.06743435766233097\n",
      "train loss:0.05258849387927964\n",
      "train loss:0.0522595905716115\n",
      "train loss:0.07321827481529507\n",
      "train loss:0.031605369369830154\n",
      "train loss:0.03276590907068062\n",
      "train loss:0.017235022585077683\n",
      "train loss:0.06134744586214962\n",
      "train loss:0.027424984855646678\n",
      "train loss:0.07523523951953837\n",
      "train loss:0.0784591993147499\n",
      "train loss:0.01843015248227606\n",
      "train loss:0.02906916489293124\n",
      "train loss:0.05147380815261835\n",
      "train loss:0.08267458121406919\n",
      "train loss:0.06099410471764023\n",
      "train loss:0.04727414028028603\n",
      "train loss:0.027480477089907324\n",
      "train loss:0.038399861797661826\n",
      "train loss:0.036671052189859485\n",
      "train loss:0.03526915688989985\n",
      "train loss:0.09502623178035924\n",
      "train loss:0.0522480966064616\n",
      "train loss:0.029794342997559772\n",
      "train loss:0.07900810885409261\n",
      "train loss:0.04433207758805573\n",
      "train loss:0.11740880103920168\n",
      "train loss:0.02687554148333376\n",
      "train loss:0.040560915852882296\n",
      "train loss:0.13999232660974648\n",
      "train loss:0.10651330302414072\n",
      "train loss:0.033835542133762796\n",
      "train loss:0.07736788398843021\n",
      "train loss:0.05429680833989848\n",
      "train loss:0.04754650248413928\n",
      "train loss:0.05267326301285427\n",
      "train loss:0.06824307024277018\n",
      "train loss:0.093838236324301\n",
      "train loss:0.05257510189117711\n",
      "train loss:0.11029042198818502\n",
      "train loss:0.022152175137333297\n",
      "train loss:0.08065842635172013\n",
      "train loss:0.07368029239420083\n",
      "train loss:0.012270741783498806\n",
      "train loss:0.0465886403428033\n",
      "train loss:0.05244962100717709\n",
      "train loss:0.05933464140223615\n",
      "train loss:0.07724490111441312\n",
      "train loss:0.04240108815967468\n",
      "train loss:0.05288440781935177\n",
      "train loss:0.04060900120563318\n",
      "train loss:0.031319631888605974\n",
      "train loss:0.04980558989517621\n",
      "train loss:0.11475187279086758\n",
      "train loss:0.08548749831514556\n",
      "train loss:0.0353443846503972\n",
      "train loss:0.11251421681743282\n",
      "train loss:0.04638827367775153\n",
      "train loss:0.042411624163138956\n",
      "train loss:0.05964090975241104\n",
      "train loss:0.05710640730620067\n",
      "train loss:0.07119337891589286\n",
      "train loss:0.04958894423234706\n",
      "train loss:0.05389974395547251\n",
      "train loss:0.04118536611609985\n",
      "train loss:0.05490423146520205\n",
      "train loss:0.01739868674090936\n",
      "train loss:0.03980105858512946\n",
      "train loss:0.0908633091593625\n",
      "train loss:0.09923146453957124\n",
      "train loss:0.025294829795098468\n",
      "train loss:0.08712697124751659\n",
      "train loss:0.016162176589803283\n",
      "train loss:0.02296976340509433\n",
      "train loss:0.018602375200475273\n",
      "train loss:0.03550470981125778\n",
      "train loss:0.1060428139019132\n",
      "train loss:0.08499094114686699\n",
      "train loss:0.039785867994337996\n",
      "train loss:0.04131153047825313\n",
      "train loss:0.09073454438086387\n",
      "train loss:0.062417223623894624\n",
      "train loss:0.21477016899576373\n",
      "train loss:0.03532276645263209\n",
      "train loss:0.1478704926737826\n",
      "train loss:0.0379522506967344\n",
      "train loss:0.0691356169147215\n",
      "train loss:0.06565735825384166\n",
      "train loss:0.07529032932859903\n",
      "train loss:0.04367235109433163\n",
      "train loss:0.0684121305907576\n",
      "train loss:0.02763248949127163\n",
      "train loss:0.12361728596484284\n",
      "train loss:0.013013009572811606\n",
      "train loss:0.049885241705529444\n",
      "train loss:0.028026303130842166\n",
      "train loss:0.02962683596245245\n",
      "train loss:0.11059352690359382\n",
      "train loss:0.0717058135365012\n",
      "train loss:0.08447512239697072\n",
      "train loss:0.025219541883491167\n",
      "train loss:0.03709636467909766\n",
      "train loss:0.028525243624567858\n",
      "train loss:0.07494988120338669\n",
      "train loss:0.15730117535799246\n",
      "train loss:0.027026926918635855\n",
      "train loss:0.04349977772552444\n",
      "train loss:0.05049174660910431\n",
      "train loss:0.02378379891022226\n",
      "train loss:0.020463781855010257\n",
      "train loss:0.05515744434471323\n",
      "train loss:0.08172290040900586\n",
      "train loss:0.09349387068971636\n",
      "train loss:0.03373306150247577\n",
      "train loss:0.01824869855449691\n",
      "train loss:0.09734342821079199\n",
      "train loss:0.07103992447150496\n",
      "train loss:0.03405411808016276\n",
      "train loss:0.0759885521172653\n",
      "train loss:0.05941194243460383\n",
      "train loss:0.02256437325719396\n",
      "train loss:0.03996648962302772\n",
      "train loss:0.023260099960184997\n",
      "train loss:0.01966702239211553\n",
      "train loss:0.06088876292163907\n",
      "train loss:0.14650678273741977\n",
      "train loss:0.08425550311365808\n",
      "train loss:0.05184867210097173\n",
      "train loss:0.01826168106691633\n",
      "train loss:0.07302086785088646\n",
      "train loss:0.03870233580042635\n",
      "train loss:0.035117548348971434\n",
      "train loss:0.03897193279297757\n",
      "train loss:0.05607857109751488\n",
      "train loss:0.1050011819189252\n",
      "train loss:0.01643083111594955\n",
      "train loss:0.0455927945800427\n",
      "train loss:0.015759539469962038\n",
      "train loss:0.025247783426894602\n",
      "train loss:0.025212488260481267\n",
      "train loss:0.03564342352058035\n",
      "train loss:0.0931312994621055\n",
      "train loss:0.05794839875686961\n",
      "train loss:0.014004918558765275\n",
      "train loss:0.016048179683003472\n",
      "train loss:0.03264123348498288\n",
      "train loss:0.041785054842807784\n",
      "train loss:0.059878282485639873\n",
      "train loss:0.06491571347900049\n",
      "train loss:0.015611868530374502\n",
      "train loss:0.05701691675255764\n",
      "train loss:0.0386004997030947\n",
      "train loss:0.09077605878652567\n",
      "train loss:0.08302349669100056\n",
      "train loss:0.018044949055429072\n",
      "train loss:0.09184769622727297\n",
      "train loss:0.10440775564735569\n",
      "train loss:0.02992136485032065\n",
      "train loss:0.12234209357508245\n",
      "train loss:0.044951530248966136\n",
      "train loss:0.03646468956370872\n",
      "train loss:0.08873715470058871\n",
      "train loss:0.09001712387229473\n",
      "train loss:0.026323267004073968\n",
      "train loss:0.06024212947888296\n",
      "train loss:0.09773615095365122\n",
      "train loss:0.114626178379394\n",
      "train loss:0.029787288117376333\n",
      "train loss:0.06364331927370172\n",
      "train loss:0.044717506000232235\n",
      "train loss:0.09429057617475424\n",
      "train loss:0.05657811224140569\n",
      "train loss:0.030423418684006998\n",
      "train loss:0.06884316755520004\n",
      "train loss:0.05643017139375476\n",
      "train loss:0.07809221197376184\n",
      "train loss:0.08209539419801437\n",
      "train loss:0.035185342663164774\n",
      "train loss:0.0381016003311406\n",
      "train loss:0.030936546332702618\n",
      "train loss:0.04049934853536169\n",
      "train loss:0.03504424776311053\n",
      "train loss:0.08171328946709236\n",
      "train loss:0.09080253587401829\n",
      "train loss:0.07035459290592277\n",
      "train loss:0.05716228629271522\n",
      "train loss:0.014003115523428939\n",
      "train loss:0.049143989615300185\n",
      "train loss:0.12782179022605356\n",
      "train loss:0.053558711338679926\n",
      "train loss:0.059801630532048164\n",
      "train loss:0.04255319606856326\n",
      "train loss:0.08250006174810796\n",
      "train loss:0.04495088757574273\n",
      "train loss:0.055533727566941915\n",
      "train loss:0.045781929836171846\n",
      "train loss:0.04712366174957529\n",
      "train loss:0.022677003585697224\n",
      "train loss:0.02890380635888963\n",
      "train loss:0.02519838595059654\n",
      "train loss:0.017387304559008398\n",
      "train loss:0.02914817548284331\n",
      "train loss:0.03232467686741476\n",
      "train loss:0.04030447615833435\n",
      "train loss:0.012511299357296175\n",
      "train loss:0.033993932192069504\n",
      "train loss:0.0868530875000144\n",
      "train loss:0.03333790670426978\n",
      "train loss:0.03671350135723958\n",
      "train loss:0.03101016464366224\n",
      "train loss:0.08364403242130602\n",
      "train loss:0.03260138694526436\n",
      "train loss:0.10240120159885097\n",
      "train loss:0.054452016482843375\n",
      "train loss:0.025156311080950334\n",
      "train loss:0.030827751593778038\n",
      "train loss:0.09482602232290097\n",
      "train loss:0.032541621086293125\n",
      "train loss:0.074513197216035\n",
      "train loss:0.04803213370039671\n",
      "train loss:0.07239985913543884\n",
      "train loss:0.013633532809555688\n",
      "train loss:0.025353879415152786\n",
      "train loss:0.026442086650919773\n",
      "train loss:0.1583820853548832\n",
      "train loss:0.1023562830356959\n",
      "train loss:0.011457372036875217\n",
      "train loss:0.030394529026322156\n",
      "train loss:0.04760376306991463\n",
      "train loss:0.09684626810696743\n",
      "train loss:0.05659820956289182\n",
      "train loss:0.0244592218456932\n",
      "train loss:0.037981942776211995\n",
      "train loss:0.09840798382027292\n",
      "train loss:0.07378581730772263\n",
      "train loss:0.10129769819216293\n",
      "train loss:0.03135332266612403\n",
      "train loss:0.014480904443175907\n",
      "train loss:0.11477619914233189\n",
      "train loss:0.021607648579899937\n",
      "train loss:0.09430049385248265\n",
      "train loss:0.02062978877436426\n",
      "train loss:0.03652149491794742\n",
      "train loss:0.03330249403060055\n",
      "train loss:0.07232683184166505\n",
      "train loss:0.03338809446431183\n",
      "train loss:0.04974374908091313\n",
      "train loss:0.03750523659866055\n",
      "train loss:0.047833097804849324\n",
      "train loss:0.018112384773103517\n",
      "train loss:0.04818012411208018\n",
      "train loss:0.017026383315660195\n",
      "train loss:0.07087610718033081\n",
      "train loss:0.03244280509857839\n",
      "train loss:0.053854009793792505\n",
      "train loss:0.019375377774599863\n",
      "train loss:0.1033245072316644\n",
      "train loss:0.02686714441524949\n",
      "train loss:0.025867969918040568\n",
      "train loss:0.043391847684542476\n",
      "train loss:0.06255392768181958\n",
      "train loss:0.0497677929050568\n",
      "train loss:0.011925719027263016\n",
      "train loss:0.09165634433091753\n",
      "train loss:0.08465072274860036\n",
      "train loss:0.027601385250647256\n",
      "train loss:0.01903980784681049\n",
      "train loss:0.05848754217910513\n",
      "train loss:0.0419859181496282\n",
      "train loss:0.06915200746971809\n",
      "train loss:0.052444558975175436\n",
      "train loss:0.032765812907962516\n",
      "train loss:0.028188231047505768\n",
      "train loss:0.04132026795253647\n",
      "train loss:0.017135072497054194\n",
      "train loss:0.018460530384866038\n",
      "train loss:0.14493495651989366\n",
      "train loss:0.0269836799895999\n",
      "train loss:0.02712990809217424\n",
      "train loss:0.026325676425134885\n",
      "train loss:0.03888959035227315\n",
      "train loss:0.03176124821816783\n",
      "train loss:0.024113065715283762\n",
      "train loss:0.06809486099737368\n",
      "train loss:0.08094357219187337\n",
      "train loss:0.04473369034271755\n",
      "train loss:0.022278266006425584\n",
      "train loss:0.018816004744008193\n",
      "train loss:0.014815748713594857\n",
      "train loss:0.034261512879679316\n",
      "train loss:0.026471700886757956\n",
      "train loss:0.05156788250188277\n",
      "train loss:0.04626353733599146\n",
      "train loss:0.19529232019282486\n",
      "train loss:0.052507308736569\n",
      "train loss:0.02847377097103352\n",
      "train loss:0.04215602320437676\n",
      "train loss:0.08191762976153852\n",
      "train loss:0.09244700915487208\n",
      "train loss:0.07115716056241533\n",
      "train loss:0.03712890135267768\n",
      "train loss:0.11701465852590352\n",
      "train loss:0.046819645264066574\n",
      "train loss:0.06115738835632104\n",
      "train loss:0.03923136622097484\n",
      "train loss:0.051656325390741706\n",
      "train loss:0.0074702999104622235\n",
      "train loss:0.06220262710375191\n",
      "train loss:0.02449854096228559\n",
      "train loss:0.1489497988531993\n",
      "train loss:0.04149895837103181\n",
      "train loss:0.07555600895618447\n",
      "train loss:0.05869301018956767\n",
      "train loss:0.026901478380686655\n",
      "train loss:0.05932986667584987\n",
      "train loss:0.03294154951117633\n",
      "train loss:0.02472581500991038\n",
      "train loss:0.010685716684509168\n",
      "train loss:0.011599542141179465\n",
      "train loss:0.055488013804591715\n",
      "train loss:0.028706462067110347\n",
      "train loss:0.04003351011956706\n",
      "train loss:0.05506208395523703\n",
      "train loss:0.02248503745840867\n",
      "train loss:0.016306031806764446\n",
      "train loss:0.009739243221772484\n",
      "train loss:0.024814199263159423\n",
      "train loss:0.0488935017102393\n",
      "train loss:0.07617984953453487\n",
      "train loss:0.023476378524272846\n",
      "train loss:0.10271319050078795\n",
      "train loss:0.020590902260391297\n",
      "train loss:0.07729898948865313\n",
      "train loss:0.04164367903714124\n",
      "train loss:0.06109396345784299\n",
      "train loss:0.07409083250928888\n",
      "train loss:0.014506186481729612\n",
      "train loss:0.028713458578978404\n",
      "train loss:0.05383020043851623\n",
      "train loss:0.0687570925200004\n",
      "train loss:0.057392291793401495\n",
      "train loss:0.01726225400728804\n",
      "train loss:0.05619463848110546\n",
      "train loss:0.026832477798799367\n",
      "train loss:0.05818781518929914\n",
      "train loss:0.049568225235066474\n",
      "train loss:0.018023051655956468\n",
      "train loss:0.06221094236164612\n",
      "train loss:0.07338291577236113\n",
      "train loss:0.02451581163875671\n",
      "train loss:0.07758817733547377\n",
      "train loss:0.01525849850143322\n",
      "train loss:0.023957905573556558\n",
      "train loss:0.03515163860463711\n",
      "train loss:0.025476773740361017\n",
      "train loss:0.007932943430888848\n",
      "train loss:0.0784029662601888\n",
      "train loss:0.18569359001514738\n",
      "train loss:0.07193277125915101\n",
      "train loss:0.0395359837910047\n",
      "train loss:0.011908017672897776\n",
      "train loss:0.1363885289084104\n",
      "train loss:0.03234711250748752\n",
      "train loss:0.06777788815666573\n",
      "train loss:0.018711050196484134\n",
      "train loss:0.04611263975424977\n",
      "train loss:0.02177618719523504\n",
      "train loss:0.01778250113187185\n",
      "train loss:0.0264754483279357\n",
      "train loss:0.042391203023043375\n",
      "train loss:0.039335768991676276\n",
      "train loss:0.01842710953720694\n",
      "train loss:0.08838590206976255\n",
      "train loss:0.08825546752808226\n",
      "train loss:0.06575646602759284\n",
      "train loss:0.03880196529563132\n",
      "train loss:0.04807428523689932\n",
      "train loss:0.044586571755306864\n",
      "train loss:0.010836239015480002\n",
      "train loss:0.05987305665555584\n",
      "train loss:0.06944818262166655\n",
      "train loss:0.1553922011558686\n",
      "train loss:0.04863449545496167\n",
      "train loss:0.03782490276613315\n",
      "train loss:0.020195582862066953\n",
      "train loss:0.028731245874067897\n",
      "train loss:0.01893888185738263\n",
      "train loss:0.025302276772423683\n",
      "train loss:0.03578071161053977\n",
      "train loss:0.0261296103168635\n",
      "train loss:0.01863348483948388\n",
      "train loss:0.07552277503947769\n",
      "train loss:0.04899016521958264\n",
      "train loss:0.0380549382008758\n",
      "train loss:0.03439420640832909\n",
      "train loss:0.011270561814820706\n",
      "train loss:0.042001260337345636\n",
      "train loss:0.08908396903912545\n",
      "train loss:0.020577394724723027\n",
      "train loss:0.07629076144980125\n",
      "train loss:0.03831833147319031\n",
      "train loss:0.020530629850918792\n",
      "train loss:0.0344908008260216\n",
      "train loss:0.046592058408928175\n",
      "train loss:0.070872224853375\n",
      "train loss:0.02544199654903282\n",
      "train loss:0.018896228123176418\n",
      "train loss:0.011307807337384415\n",
      "train loss:0.048176337411659186\n",
      "train loss:0.03492100319428262\n",
      "train loss:0.01721204102174891\n",
      "train loss:0.11646002410753452\n",
      "train loss:0.0724021397184647\n",
      "=== epoch:4, train acc:0.982, test acc:0.977 ===\n",
      "train loss:0.07243645214731753\n",
      "train loss:0.014580791399719137\n",
      "train loss:0.025127458502644272\n",
      "train loss:0.03287405450442825\n",
      "train loss:0.07958268572828116\n",
      "train loss:0.026352380641309042\n",
      "train loss:0.04611295261660514\n",
      "train loss:0.02121896804103607\n",
      "train loss:0.06930852364326898\n",
      "train loss:0.07442579970651747\n",
      "train loss:0.031103569811619283\n",
      "train loss:0.09551185132142322\n",
      "train loss:0.039729173520451584\n",
      "train loss:0.05582504624887001\n",
      "train loss:0.0381766714294776\n",
      "train loss:0.024252355828959907\n",
      "train loss:0.02384550732656178\n",
      "train loss:0.03417468949488928\n",
      "train loss:0.025326367302410308\n",
      "train loss:0.026393031453642954\n",
      "train loss:0.023501917422517768\n",
      "train loss:0.025661880216912274\n",
      "train loss:0.0741377125153548\n",
      "train loss:0.03397427350757442\n",
      "train loss:0.11506420657945306\n",
      "train loss:0.028028085270622706\n",
      "train loss:0.040442715257034835\n",
      "train loss:0.06857427531737495\n",
      "train loss:0.03985928077137008\n",
      "train loss:0.08023520937354733\n",
      "train loss:0.007372312366429941\n",
      "train loss:0.011113890654111527\n",
      "train loss:0.06110614161096474\n",
      "train loss:0.01258289917268519\n",
      "train loss:0.04093541725313243\n",
      "train loss:0.031790094887589444\n",
      "train loss:0.014638164835990182\n",
      "train loss:0.03720380492103087\n",
      "train loss:0.060914592906867994\n",
      "train loss:0.027392435824790604\n",
      "train loss:0.07685224526993281\n",
      "train loss:0.032974535924098214\n",
      "train loss:0.03704764319379468\n",
      "train loss:0.015542148871655878\n",
      "train loss:0.01842431950064623\n",
      "train loss:0.026368768531966697\n",
      "train loss:0.14218718806688654\n",
      "train loss:0.016741804092718984\n",
      "train loss:0.01996446929007058\n",
      "train loss:0.01896743858275559\n",
      "train loss:0.029024069500982765\n",
      "train loss:0.017035210300219598\n",
      "train loss:0.06300570209660002\n",
      "train loss:0.06708147504673187\n",
      "train loss:0.06505631405374475\n",
      "train loss:0.05306140849031689\n",
      "train loss:0.02415468423288104\n",
      "train loss:0.01813816604309122\n",
      "train loss:0.027080597426350054\n",
      "train loss:0.03930098258368623\n",
      "train loss:0.08600799014612871\n",
      "train loss:0.014911800709527766\n",
      "train loss:0.12343190521230879\n",
      "train loss:0.025736206420862325\n",
      "train loss:0.02722734333593928\n",
      "train loss:0.03340131256200159\n",
      "train loss:0.013387707093096057\n",
      "train loss:0.03051611535454899\n",
      "train loss:0.009021804907210973\n",
      "train loss:0.058933467690075146\n",
      "train loss:0.02876519266531704\n",
      "train loss:0.027731603863896906\n",
      "train loss:0.06948462694554756\n",
      "train loss:0.03625762127474099\n",
      "train loss:0.048235917894507215\n",
      "train loss:0.06964482101728144\n",
      "train loss:0.05329142557863599\n",
      "train loss:0.02585883150495706\n",
      "train loss:0.07742817959269326\n",
      "train loss:0.029708022712320484\n",
      "train loss:0.04190994442008125\n",
      "train loss:0.07016051026489567\n",
      "train loss:0.017772104825133445\n",
      "train loss:0.054383481460441085\n",
      "train loss:0.04001272542892351\n",
      "train loss:0.05148431413577893\n",
      "train loss:0.049354164730106405\n",
      "train loss:0.03801894579200735\n",
      "train loss:0.02856325544322764\n",
      "train loss:0.023593214288462554\n",
      "train loss:0.062068647827583284\n",
      "train loss:0.034248072943327774\n",
      "train loss:0.04049340872532404\n",
      "train loss:0.025405902309499587\n",
      "train loss:0.07257605298845907\n",
      "train loss:0.03236512827063177\n",
      "train loss:0.10725680064756705\n",
      "train loss:0.07793388393627841\n",
      "train loss:0.014970833600071475\n",
      "train loss:0.022798729052607346\n",
      "train loss:0.02721387058660036\n",
      "train loss:0.015125323814243037\n",
      "train loss:0.028805642552364046\n",
      "train loss:0.020843019167425668\n",
      "train loss:0.06612182015975758\n",
      "train loss:0.04083806310624105\n",
      "train loss:0.053921376956281\n",
      "train loss:0.07872416843097917\n",
      "train loss:0.14202350494778473\n",
      "train loss:0.04201689073779146\n",
      "train loss:0.024250912156032478\n",
      "train loss:0.03256414835515982\n",
      "train loss:0.05265894352707579\n",
      "train loss:0.04462894292987769\n",
      "train loss:0.01673527764175275\n",
      "train loss:0.049850063000744044\n",
      "train loss:0.010042314696463132\n",
      "train loss:0.03299118761541303\n",
      "train loss:0.0943569655178528\n",
      "train loss:0.013253265807290202\n",
      "train loss:0.015559983694510055\n",
      "train loss:0.13294581552906645\n",
      "train loss:0.07231105925558595\n",
      "train loss:0.09926166480512504\n",
      "train loss:0.020431453401020146\n",
      "train loss:0.05925032066986681\n",
      "train loss:0.026443142214858315\n",
      "train loss:0.08145050358331331\n",
      "train loss:0.052108810672038375\n",
      "train loss:0.05965804412988463\n",
      "train loss:0.03567711001815428\n",
      "train loss:0.14268168007101945\n",
      "train loss:0.058982662876183076\n",
      "train loss:0.0413478075912446\n",
      "train loss:0.029081023799664277\n",
      "train loss:0.1363983369180593\n",
      "train loss:0.013810638247372062\n",
      "train loss:0.03882504743636579\n",
      "train loss:0.02155809706658419\n",
      "train loss:0.13286994847830783\n",
      "train loss:0.08792328617183535\n",
      "train loss:0.01843513512130766\n",
      "train loss:0.07846805457224285\n",
      "train loss:0.06965377796079256\n",
      "train loss:0.0556646251429159\n",
      "train loss:0.11436588216677399\n",
      "train loss:0.07776726122430025\n",
      "train loss:0.04394509443856243\n",
      "train loss:0.037297552970603214\n",
      "train loss:0.0398421995973509\n",
      "train loss:0.022137497575476135\n",
      "train loss:0.06371680920157023\n",
      "train loss:0.02191410112959199\n",
      "train loss:0.02988341844536517\n",
      "train loss:0.07859408801094828\n",
      "train loss:0.016360098052112793\n",
      "train loss:0.03554313106340665\n",
      "train loss:0.031805550335179074\n",
      "train loss:0.05720726479546245\n",
      "train loss:0.04239411404676744\n",
      "train loss:0.06606014510997447\n",
      "train loss:0.03678505677743959\n",
      "train loss:0.029504240153806906\n",
      "train loss:0.03951468240381291\n",
      "train loss:0.049266181863614034\n",
      "train loss:0.022784353340220425\n",
      "train loss:0.016218515138703708\n",
      "train loss:0.025696576957415566\n",
      "train loss:0.024584186670139\n",
      "train loss:0.02476809267522508\n",
      "train loss:0.022676121426291718\n",
      "train loss:0.019843537441932634\n",
      "train loss:0.021946712572284574\n",
      "train loss:0.033527636622225604\n",
      "train loss:0.04619619103101355\n",
      "train loss:0.04692509050994567\n",
      "train loss:0.004636575736718142\n",
      "train loss:0.04557905738930277\n",
      "train loss:0.018202190016320365\n",
      "train loss:0.0825888867516908\n",
      "train loss:0.10656846366926807\n",
      "train loss:0.05496143690290761\n",
      "train loss:0.040217139694297355\n",
      "train loss:0.015849762434381565\n",
      "train loss:0.08215150630876165\n",
      "train loss:0.021011255797856534\n",
      "train loss:0.021767143742337024\n",
      "train loss:0.041358787672337846\n",
      "train loss:0.04449390937405443\n",
      "train loss:0.03558311238786989\n",
      "train loss:0.03982089025615228\n",
      "train loss:0.05169673749997019\n",
      "train loss:0.06966138522819086\n",
      "train loss:0.050174994850055776\n",
      "train loss:0.028310875025224592\n",
      "train loss:0.018391640347355152\n",
      "train loss:0.012161904341027206\n",
      "train loss:0.05535032222691158\n",
      "train loss:0.035063997496374774\n",
      "train loss:0.05391835620831189\n",
      "train loss:0.020519138024255243\n",
      "train loss:0.03874619094668114\n",
      "train loss:0.1090572373794967\n",
      "train loss:0.0416856669135586\n",
      "train loss:0.03096952548203769\n",
      "train loss:0.02467443638583056\n",
      "train loss:0.04043765750670066\n",
      "train loss:0.03374288101158139\n",
      "train loss:0.07662764854234068\n",
      "train loss:0.08134864860953933\n",
      "train loss:0.05148280022378987\n",
      "train loss:0.09271280986422141\n",
      "train loss:0.027213066865497675\n",
      "train loss:0.06975478238146318\n",
      "train loss:0.11022958812944716\n",
      "train loss:0.046294917358190225\n",
      "train loss:0.05366822673148574\n",
      "train loss:0.033268157757292666\n",
      "train loss:0.07098251600076377\n",
      "train loss:0.020312327523108104\n",
      "train loss:0.00539964069657842\n",
      "train loss:0.1440673079410637\n",
      "train loss:0.04146471404878784\n",
      "train loss:0.03513453199389063\n",
      "train loss:0.0678940592118592\n",
      "train loss:0.03066827626650959\n",
      "train loss:0.047770664354714915\n",
      "train loss:0.027054889639854078\n",
      "train loss:0.036090266723167855\n",
      "train loss:0.052589257710545435\n",
      "train loss:0.021630815363500585\n",
      "train loss:0.01708813802293311\n",
      "train loss:0.01129420031468159\n",
      "train loss:0.04761216842346666\n",
      "train loss:0.11887921936503781\n",
      "train loss:0.03170664988796114\n",
      "train loss:0.025291690475970862\n",
      "train loss:0.08266487361438682\n",
      "train loss:0.03283466745828334\n",
      "train loss:0.03301925805451159\n",
      "train loss:0.026847771858738673\n",
      "train loss:0.02711966334707767\n",
      "train loss:0.04969153098998733\n",
      "train loss:0.018046573369256854\n",
      "train loss:0.033135091856609705\n",
      "train loss:0.01448157972792786\n",
      "train loss:0.006131405471205709\n",
      "train loss:0.026417538640681\n",
      "train loss:0.02727805163008825\n",
      "train loss:0.05548047697788947\n",
      "train loss:0.03924058928353503\n",
      "train loss:0.019994885708771063\n",
      "train loss:0.022049705232849628\n",
      "train loss:0.08401264219943118\n",
      "train loss:0.011903422090728328\n",
      "train loss:0.03366060257050818\n",
      "train loss:0.11914156518309746\n",
      "train loss:0.020414309980489168\n",
      "train loss:0.0403311242324564\n",
      "train loss:0.02799723845470476\n",
      "train loss:0.030735396753438983\n",
      "train loss:0.01805607297633813\n",
      "train loss:0.026564962444999122\n",
      "train loss:0.02570131963102311\n",
      "train loss:0.030327959783314595\n",
      "train loss:0.028220617042116494\n",
      "train loss:0.047815619744592495\n",
      "train loss:0.02038176685726914\n",
      "train loss:0.025222543729893077\n",
      "train loss:0.013699679089908066\n",
      "train loss:0.02091781866317031\n",
      "train loss:0.03546297673875618\n",
      "train loss:0.019204857239463465\n",
      "train loss:0.05572714554854326\n",
      "train loss:0.005546560018252201\n",
      "train loss:0.011846622542417523\n",
      "train loss:0.0332370297132876\n",
      "train loss:0.018626172950042885\n",
      "train loss:0.1342655392778289\n",
      "train loss:0.03503680010963031\n",
      "train loss:0.08305557180190411\n",
      "train loss:0.007276904652130879\n",
      "train loss:0.018088535555735082\n",
      "train loss:0.02281134491692832\n",
      "train loss:0.051859244823013524\n",
      "train loss:0.034158867986056676\n",
      "train loss:0.04571100693850652\n",
      "train loss:0.010641510596303172\n",
      "train loss:0.09257429738542763\n",
      "train loss:0.013864582560607755\n",
      "train loss:0.017624484246655362\n",
      "train loss:0.03840099782643895\n",
      "train loss:0.02316330825864541\n",
      "train loss:0.04255223398973063\n",
      "train loss:0.019516619388901767\n",
      "train loss:0.048384885322274085\n",
      "train loss:0.1263646529700779\n",
      "train loss:0.07353521545271739\n",
      "train loss:0.11836601242896966\n",
      "train loss:0.054177050638324745\n",
      "train loss:0.0047662916508900005\n",
      "train loss:0.02736745574132251\n",
      "train loss:0.06025892386665593\n",
      "train loss:0.021343801839255064\n",
      "train loss:0.06102487421739572\n",
      "train loss:0.013963225172952367\n",
      "train loss:0.07089825120047663\n",
      "train loss:0.14699727214740457\n",
      "train loss:0.026310473639127127\n",
      "train loss:0.05132388396080308\n",
      "train loss:0.10550292595777896\n",
      "train loss:0.017064960583118995\n",
      "train loss:0.007867607973115094\n",
      "train loss:0.026034476946147193\n",
      "train loss:0.017221443513379328\n",
      "train loss:0.014839066510120447\n",
      "train loss:0.07289811167641624\n",
      "train loss:0.06388245799232847\n",
      "train loss:0.03534209729665229\n",
      "train loss:0.03019470313948863\n",
      "train loss:0.020922031625683887\n",
      "train loss:0.023792298236877917\n",
      "train loss:0.030484690276157203\n",
      "train loss:0.032643647789999064\n",
      "train loss:0.06802144709059893\n",
      "train loss:0.02421212687932416\n",
      "train loss:0.06880421453132238\n",
      "train loss:0.03365477768639899\n",
      "train loss:0.0600604940324947\n",
      "train loss:0.04641771912520477\n",
      "train loss:0.022499296429232252\n",
      "train loss:0.04310323689793144\n",
      "train loss:0.007835275396952812\n",
      "train loss:0.027348949598036243\n",
      "train loss:0.0743716514765664\n",
      "train loss:0.053798371596906376\n",
      "train loss:0.04394161905953662\n",
      "train loss:0.10207862835756241\n",
      "train loss:0.021912812827862064\n",
      "train loss:0.04601891206402863\n",
      "train loss:0.026012343585954483\n",
      "train loss:0.0107041929130179\n",
      "train loss:0.006141400030538362\n",
      "train loss:0.014379598700181184\n",
      "train loss:0.07129588588070498\n",
      "train loss:0.06358307859670631\n",
      "train loss:0.015918028440202375\n",
      "train loss:0.019933606607747713\n",
      "train loss:0.013378096511692514\n",
      "train loss:0.03712519714648432\n",
      "train loss:0.022477613056692717\n",
      "train loss:0.006593462124433716\n",
      "train loss:0.031111512193772017\n",
      "train loss:0.07687298556442666\n",
      "train loss:0.02901752836605021\n",
      "train loss:0.06519167860161862\n",
      "train loss:0.03234750606489691\n",
      "train loss:0.022126758183569763\n",
      "train loss:0.026202154909464065\n",
      "train loss:0.036125731141713885\n",
      "train loss:0.02175507429969796\n",
      "train loss:0.01230692402418162\n",
      "train loss:0.022906825814048827\n",
      "train loss:0.02933262235020942\n",
      "train loss:0.08163353233639802\n",
      "train loss:0.033935431571804654\n",
      "train loss:0.020409405364546596\n",
      "train loss:0.041555159342384816\n",
      "train loss:0.06409418471150673\n",
      "train loss:0.007891098886490432\n",
      "train loss:0.09756313990412034\n",
      "train loss:0.03418455447569284\n",
      "train loss:0.013985818975404882\n",
      "train loss:0.1394058766075685\n",
      "train loss:0.06687123993349958\n",
      "train loss:0.04839292301393096\n",
      "train loss:0.038594943707036956\n",
      "train loss:0.06916371340370323\n",
      "train loss:0.018166995208317282\n",
      "train loss:0.03187375964561047\n",
      "train loss:0.008959441131955343\n",
      "train loss:0.00837719231984929\n",
      "train loss:0.029826816167456322\n",
      "train loss:0.185052117610938\n",
      "train loss:0.026661644508865358\n",
      "train loss:0.07407274250520036\n",
      "train loss:0.04145564625142522\n",
      "train loss:0.012567999793135422\n",
      "train loss:0.018994677101966565\n",
      "train loss:0.04584893328761769\n",
      "train loss:0.05942276905021717\n",
      "train loss:0.018208230315898792\n",
      "train loss:0.02259936874999397\n",
      "train loss:0.016778714366548795\n",
      "train loss:0.02047655618069235\n",
      "train loss:0.020636418912796793\n",
      "train loss:0.009613207988169501\n",
      "train loss:0.027662451710188964\n",
      "train loss:0.07664665394768498\n",
      "train loss:0.05117759621274913\n",
      "train loss:0.016106526650487424\n",
      "train loss:0.034905761570853684\n",
      "train loss:0.019538679073728644\n",
      "train loss:0.04645804568244937\n",
      "train loss:0.10165790214734866\n",
      "train loss:0.01672843805071909\n",
      "train loss:0.00823319924737649\n",
      "train loss:0.017176292198476294\n",
      "train loss:0.04315191684182092\n",
      "train loss:0.06469663165990096\n",
      "train loss:0.022849221889098558\n",
      "train loss:0.009831906365390686\n",
      "train loss:0.037840752317613024\n",
      "train loss:0.05230413896855437\n",
      "train loss:0.007036545766198319\n",
      "train loss:0.06397016888889391\n",
      "train loss:0.16228240344034975\n",
      "train loss:0.024579175612974048\n",
      "train loss:0.005978934127483837\n",
      "train loss:0.018794111321921395\n",
      "train loss:0.02767877214242634\n",
      "train loss:0.02699360481098074\n",
      "train loss:0.03412893938990466\n",
      "train loss:0.018495095582506744\n",
      "train loss:0.0216685108921635\n",
      "train loss:0.012200329556124991\n",
      "train loss:0.022199510660852118\n",
      "train loss:0.04131641738487312\n",
      "train loss:0.016961889249861167\n",
      "train loss:0.018504574078772068\n",
      "train loss:0.023507499665532658\n",
      "train loss:0.02710260108243554\n",
      "train loss:0.030805161868299985\n",
      "train loss:0.011877364161557673\n",
      "train loss:0.03553004805874938\n",
      "train loss:0.015570254810326842\n",
      "train loss:0.006556153492389421\n",
      "train loss:0.01773584812378779\n",
      "train loss:0.02488809690966522\n",
      "train loss:0.0311145934706046\n",
      "train loss:0.007159051439072374\n",
      "train loss:0.07591534504830617\n",
      "train loss:0.07957607856361906\n",
      "train loss:0.030186400676073206\n",
      "train loss:0.011144441240920077\n",
      "train loss:0.04283546118964338\n",
      "train loss:0.08963918258393201\n",
      "train loss:0.020647847241764054\n",
      "train loss:0.015237135213667765\n",
      "train loss:0.05253330113189258\n",
      "train loss:0.012885082705996894\n",
      "train loss:0.00634253662998078\n",
      "train loss:0.013766812722581416\n",
      "train loss:0.019328045802143333\n",
      "train loss:0.016087029620567607\n",
      "train loss:0.04765567681612395\n",
      "train loss:0.021879839134497762\n",
      "train loss:0.030350590144727428\n",
      "train loss:0.07509673257271121\n",
      "train loss:0.031707779224054405\n",
      "train loss:0.01750873774435112\n",
      "train loss:0.012520771270683673\n",
      "train loss:0.02437885710734422\n",
      "train loss:0.02010077382339469\n",
      "train loss:0.03328724344352752\n",
      "train loss:0.015128252558120194\n",
      "train loss:0.016380790642241894\n",
      "train loss:0.019806330021006843\n",
      "train loss:0.012081720404362893\n",
      "train loss:0.02563823349388536\n",
      "train loss:0.01783332508982363\n",
      "train loss:0.030010581727347278\n",
      "train loss:0.024913164482894993\n",
      "train loss:0.018557350166159833\n",
      "train loss:0.02428131760813352\n",
      "train loss:0.005081382916152851\n",
      "train loss:0.06056151323339662\n",
      "train loss:0.018576113892998874\n",
      "train loss:0.02714082427113124\n",
      "train loss:0.07593013243422644\n",
      "train loss:0.006926630532483146\n",
      "train loss:0.04860978889931434\n",
      "train loss:0.009018550422821535\n",
      "train loss:0.033166662465539655\n",
      "train loss:0.044921464133370816\n",
      "train loss:0.01801479922455394\n",
      "train loss:0.043081236371864166\n",
      "train loss:0.040426387824658586\n",
      "train loss:0.02680281824762514\n",
      "train loss:0.010825049928274759\n",
      "train loss:0.07471939617620516\n",
      "train loss:0.033075000609706307\n",
      "train loss:0.06288089129123965\n",
      "train loss:0.017654156373338475\n",
      "train loss:0.03232851741423407\n",
      "train loss:0.02525788233458565\n",
      "train loss:0.027075267088183377\n",
      "train loss:0.02380918005831868\n",
      "train loss:0.035616408779647356\n",
      "train loss:0.02117268055691658\n",
      "train loss:0.05827266164446475\n",
      "train loss:0.040542921846444625\n",
      "train loss:0.012783191587265836\n",
      "train loss:0.039300859942155\n",
      "train loss:0.011623932713172982\n",
      "train loss:0.03953358935011373\n",
      "train loss:0.01145692189137905\n",
      "train loss:0.009369160146714461\n",
      "train loss:0.009676966367933333\n",
      "train loss:0.018020712679822075\n",
      "train loss:0.017191643875031762\n",
      "train loss:0.07290033418032033\n",
      "train loss:0.019497620467788183\n",
      "train loss:0.021410875802940658\n",
      "train loss:0.029428787219448575\n",
      "train loss:0.02894114827887702\n",
      "train loss:0.016142528736802962\n",
      "train loss:0.023067990565443123\n",
      "train loss:0.009837874319991884\n",
      "train loss:0.02200430443725319\n",
      "train loss:0.023682700000463658\n",
      "train loss:0.02710560254722212\n",
      "train loss:0.05389302503106832\n",
      "train loss:0.005705254225234002\n",
      "train loss:0.03671783196766551\n",
      "train loss:0.014069087008017839\n",
      "train loss:0.009642307053108451\n",
      "train loss:0.01871592106737238\n",
      "train loss:0.008461912949904997\n",
      "train loss:0.05063830372882339\n",
      "train loss:0.01855012348607633\n",
      "train loss:0.042399788633464344\n",
      "train loss:0.012221699648903309\n",
      "train loss:0.045527114246846134\n",
      "train loss:0.09129507426196141\n",
      "train loss:0.041959416780071174\n",
      "train loss:0.09747773246933168\n",
      "train loss:0.05857490356008042\n",
      "train loss:0.03604702212726289\n",
      "train loss:0.0034662701401028135\n",
      "train loss:0.011478621237199095\n",
      "train loss:0.014470832588414717\n",
      "train loss:0.009802361312435207\n",
      "train loss:0.07922014878730393\n",
      "train loss:0.035252297029412655\n",
      "train loss:0.05195983362707232\n",
      "train loss:0.037864095779421854\n",
      "train loss:0.08870890977986759\n",
      "train loss:0.15353113522297798\n",
      "train loss:0.07954817029689328\n",
      "train loss:0.011270394095361038\n",
      "train loss:0.006251850241714878\n",
      "train loss:0.033743433801841013\n",
      "train loss:0.05395756188870264\n",
      "train loss:0.03276344015982291\n",
      "train loss:0.023803634785930287\n",
      "train loss:0.03919989684543778\n",
      "train loss:0.03198871164481946\n",
      "train loss:0.027683051077491836\n",
      "train loss:0.07463570859112434\n",
      "train loss:0.010638746493757196\n",
      "train loss:0.016862746730409876\n",
      "train loss:0.0655496343002662\n",
      "train loss:0.021184914581247064\n",
      "train loss:0.09921082860405935\n",
      "train loss:0.023932967280337142\n",
      "train loss:0.00516939338668426\n",
      "train loss:0.03489690552089219\n",
      "train loss:0.03948010797752782\n",
      "train loss:0.025898388330399855\n",
      "train loss:0.019147729680790867\n",
      "train loss:0.07528137126190049\n",
      "train loss:0.0180565697213264\n",
      "train loss:0.017224628527197732\n",
      "train loss:0.034105621602451744\n",
      "train loss:0.011663696454000928\n",
      "train loss:0.03320694522568585\n",
      "train loss:0.008421357577879806\n",
      "train loss:0.015078923440996738\n",
      "train loss:0.0150780486179615\n",
      "train loss:0.03703631796696239\n",
      "train loss:0.00468031423752715\n",
      "train loss:0.044055355666464256\n",
      "train loss:0.028921210687538744\n",
      "train loss:0.025038732590788794\n",
      "train loss:0.019683982537371567\n",
      "train loss:0.12261695910611253\n",
      "train loss:0.00929232381154346\n",
      "train loss:0.012964420624465704\n",
      "train loss:0.09442346849510672\n",
      "train loss:0.03251319550038782\n",
      "train loss:0.09300695948079918\n",
      "train loss:0.07121048607464384\n",
      "train loss:0.07671068216399712\n",
      "train loss:0.020428892133456302\n",
      "train loss:0.04984746283677545\n",
      "train loss:0.007319256287539243\n",
      "train loss:0.06979858701480997\n",
      "train loss:0.010901834669028478\n",
      "train loss:0.07536598626001142\n",
      "=== epoch:5, train acc:0.986, test acc:0.985 ===\n",
      "train loss:0.04857998678012816\n",
      "train loss:0.016401020928643813\n",
      "train loss:0.02433576277861214\n",
      "train loss:0.03173199128457204\n",
      "train loss:0.09031091331388062\n",
      "train loss:0.02167897289245099\n",
      "train loss:0.01516941175081753\n",
      "train loss:0.033729766856773424\n",
      "train loss:0.03165175024667926\n",
      "train loss:0.04812090792713985\n",
      "train loss:0.0074619024620090745\n",
      "train loss:0.03391343932648049\n",
      "train loss:0.11438080050966176\n",
      "train loss:0.08020027027931569\n",
      "train loss:0.020727558089058563\n",
      "train loss:0.01651844072991138\n",
      "train loss:0.014215504182739256\n",
      "train loss:0.0783343324744457\n",
      "train loss:0.014210792236647505\n",
      "train loss:0.015152861589486944\n",
      "train loss:0.019944222340751716\n",
      "train loss:0.0736346344122277\n",
      "train loss:0.030048404538573603\n",
      "train loss:0.05737073440915868\n",
      "train loss:0.079573610785376\n",
      "train loss:0.027098480495617118\n",
      "train loss:0.0387179975172809\n",
      "train loss:0.01522314056414075\n",
      "train loss:0.021603025836215782\n",
      "train loss:0.03573652158275838\n",
      "train loss:0.038033090585427004\n",
      "train loss:0.10362351994562462\n",
      "train loss:0.04771055825599977\n",
      "train loss:0.048453817560519606\n",
      "train loss:0.009416898125989791\n",
      "train loss:0.03932174484370252\n",
      "train loss:0.01976595213703277\n",
      "train loss:0.09699731491203495\n",
      "train loss:0.04906146462865525\n",
      "train loss:0.030207110881965246\n",
      "train loss:0.014680547386809309\n",
      "train loss:0.021849984289880074\n",
      "train loss:0.03546221266532122\n",
      "train loss:0.0054816993043066186\n",
      "train loss:0.018628868363425626\n",
      "train loss:0.004858206555188915\n",
      "train loss:0.03796606126479892\n",
      "train loss:0.039943788214143405\n",
      "train loss:0.007457669201423117\n",
      "train loss:0.010488422555758587\n",
      "train loss:0.05327999131196503\n",
      "train loss:0.014139825204175407\n",
      "train loss:0.0053805604890949385\n",
      "train loss:0.0047054988183446314\n",
      "train loss:0.04020976424671349\n",
      "train loss:0.013717028241427431\n",
      "train loss:0.008347991800822085\n",
      "train loss:0.028507918710821985\n",
      "train loss:0.006654306981398476\n",
      "train loss:0.013266414643386563\n",
      "train loss:0.020093806070031625\n",
      "train loss:0.007708082000753058\n",
      "train loss:0.03645055222462181\n",
      "train loss:0.019436491034404996\n",
      "train loss:0.005930262054067626\n",
      "train loss:0.008994882758897182\n",
      "train loss:0.06254473888645831\n",
      "train loss:0.023807685714615116\n",
      "train loss:0.012311563850603092\n",
      "train loss:0.012151900222247703\n",
      "train loss:0.013142160493004828\n",
      "train loss:0.04894331951686718\n",
      "train loss:0.029347980906738805\n",
      "train loss:0.0519532549718617\n",
      "train loss:0.02529414608735296\n",
      "train loss:0.03601570037596367\n",
      "train loss:0.01940031224426105\n",
      "train loss:0.014330939231118152\n",
      "train loss:0.02488030725939496\n",
      "train loss:0.043155037542790736\n",
      "train loss:0.16542737734370377\n",
      "train loss:0.034804010552592045\n",
      "train loss:0.02019485978174354\n",
      "train loss:0.009518994381456565\n",
      "train loss:0.07350042121708572\n",
      "train loss:0.11272782528935191\n",
      "train loss:0.043731219332564075\n",
      "train loss:0.08939072657338501\n",
      "train loss:0.03810346865278054\n",
      "train loss:0.006503248341691992\n",
      "train loss:0.033910469157520676\n",
      "train loss:0.025139203352076943\n",
      "train loss:0.05119056956301139\n",
      "train loss:0.04000137457604176\n",
      "train loss:0.08066732327042876\n",
      "train loss:0.023544276647743674\n",
      "train loss:0.06393514828693819\n",
      "train loss:0.0699138283963977\n",
      "train loss:0.07043419656360582\n",
      "train loss:0.03201500265441276\n",
      "train loss:0.08130914551458109\n",
      "train loss:0.02388890326772484\n",
      "train loss:0.07194701100004658\n",
      "train loss:0.020994043350843566\n",
      "train loss:0.05751081754213048\n",
      "train loss:0.008523479685224192\n",
      "train loss:0.04086046772677749\n",
      "train loss:0.018705329073548962\n",
      "train loss:0.017781112988842447\n",
      "train loss:0.0588528912692405\n",
      "train loss:0.031128320971352444\n",
      "train loss:0.020862327307161133\n",
      "train loss:0.02716966279402298\n",
      "train loss:0.027129051660204833\n",
      "train loss:0.06605663523832005\n",
      "train loss:0.05104379618468991\n",
      "train loss:0.10472588184095821\n",
      "train loss:0.016166215666967555\n",
      "train loss:0.03640312591362161\n",
      "train loss:0.09254248920232025\n",
      "train loss:0.0237977822100779\n",
      "train loss:0.019939246569043292\n",
      "train loss:0.096715991172316\n",
      "train loss:0.03371962381084138\n",
      "train loss:0.06055471073940571\n",
      "train loss:0.006918329750757939\n",
      "train loss:0.010698337277971415\n",
      "train loss:0.013870632642559505\n",
      "train loss:0.005673686456820778\n",
      "train loss:0.039880690032081195\n",
      "train loss:0.03975044182478518\n",
      "train loss:0.031503603723943265\n",
      "train loss:0.039550293603496836\n",
      "train loss:0.034688030278473385\n",
      "train loss:0.04996560252737014\n",
      "train loss:0.04065940600990766\n",
      "train loss:0.02127881219347161\n",
      "train loss:0.015383968420054281\n",
      "train loss:0.01664519461257323\n",
      "train loss:0.023821546959683387\n",
      "train loss:0.009983776765290083\n",
      "train loss:0.015450605342165151\n",
      "train loss:0.03197233290949209\n",
      "train loss:0.0058208485100298265\n",
      "train loss:0.05611063659426864\n",
      "train loss:0.03930726230682571\n",
      "train loss:0.036447181304829226\n",
      "train loss:0.007295235368587612\n",
      "train loss:0.004338973831071796\n",
      "train loss:0.039370547940519446\n",
      "train loss:0.02810393172252074\n",
      "train loss:0.020893357150303094\n",
      "train loss:0.007398223142264111\n",
      "train loss:0.004032721257094859\n",
      "train loss:0.013362031117041658\n",
      "train loss:0.03522394251699493\n",
      "train loss:0.026726241904661916\n",
      "train loss:0.015520188898148166\n",
      "train loss:0.0281575780532053\n",
      "train loss:0.02971676791889768\n",
      "train loss:0.020746920344994545\n",
      "train loss:0.08433467442996116\n",
      "train loss:0.006639369008828045\n",
      "train loss:0.0216451473398236\n",
      "train loss:0.022864781701999175\n",
      "train loss:0.014402584631116697\n",
      "train loss:0.007838525873641701\n",
      "train loss:0.009378416967159527\n",
      "train loss:0.018531819034355204\n",
      "train loss:0.016721114773833715\n",
      "train loss:0.013107886721985224\n",
      "train loss:0.09640914205845436\n",
      "train loss:0.009172470375880561\n",
      "train loss:0.03900710436718535\n",
      "train loss:0.006629765047728341\n",
      "train loss:0.06554574617528519\n",
      "train loss:0.024219166590313788\n",
      "train loss:0.05902871691098099\n",
      "train loss:0.03276294443419734\n",
      "train loss:0.01394177064136193\n",
      "train loss:0.03762610388864411\n",
      "train loss:0.012614715455609353\n",
      "train loss:0.008375600065831242\n",
      "train loss:0.02245661745112591\n",
      "train loss:0.01816510216397086\n",
      "train loss:0.06835141877083366\n",
      "train loss:0.011828815561869337\n",
      "train loss:0.022019404709338858\n",
      "train loss:0.030328413424831713\n",
      "train loss:0.017745572012496408\n",
      "train loss:0.025636595604416237\n",
      "train loss:0.03937987607384095\n",
      "train loss:0.04458686409094364\n",
      "train loss:0.04488387467444218\n",
      "train loss:0.05000414887059493\n",
      "train loss:0.025583208152770213\n",
      "train loss:0.009133573827349443\n",
      "train loss:0.030283710443657755\n",
      "train loss:0.050524473221142625\n",
      "train loss:0.03944524362708134\n",
      "train loss:0.011131624688933583\n",
      "train loss:0.03391225824085557\n",
      "train loss:0.05368724180829523\n",
      "train loss:0.050432837825674925\n",
      "train loss:0.020135749658470915\n",
      "train loss:0.010281725218916937\n",
      "train loss:0.029585119211412304\n",
      "train loss:0.05069188679341342\n",
      "train loss:0.08745074672716636\n",
      "train loss:0.0131828508823516\n",
      "train loss:0.024773300354511703\n",
      "train loss:0.14519344190941308\n",
      "train loss:0.014152618749803818\n",
      "train loss:0.04913039621740769\n",
      "train loss:0.07076918818214248\n",
      "train loss:0.01336133787669062\n",
      "train loss:0.053909641633100865\n",
      "train loss:0.024668125249860066\n",
      "train loss:0.053266988448783706\n",
      "train loss:0.02405678534975944\n",
      "train loss:0.022985782992067095\n",
      "train loss:0.04229668209210706\n",
      "train loss:0.016267858082625805\n",
      "train loss:0.07021629766249866\n",
      "train loss:0.011546571023424672\n",
      "train loss:0.05096913912385445\n",
      "train loss:0.009676616081667956\n",
      "train loss:0.007825961344301934\n",
      "train loss:0.029303227811536204\n",
      "train loss:0.025088468326870474\n",
      "train loss:0.006220146536177141\n",
      "train loss:0.02428957993303622\n",
      "train loss:0.00829562081080105\n",
      "train loss:0.02080934165697315\n",
      "train loss:0.01810708275468196\n",
      "train loss:0.01976377648394965\n",
      "train loss:0.0053413684712534035\n",
      "train loss:0.015467910618016372\n",
      "train loss:0.04692928919584251\n",
      "train loss:0.047007105892424024\n",
      "train loss:0.01715429870618088\n",
      "train loss:0.01578661413958111\n",
      "train loss:0.07317268994638387\n",
      "train loss:0.010863240931748654\n",
      "train loss:0.037948619484714646\n",
      "train loss:0.010013133330262292\n",
      "train loss:0.01074023553900201\n",
      "train loss:0.07509586326473346\n",
      "train loss:0.011959098495168638\n",
      "train loss:0.00943870560199711\n",
      "train loss:0.0054428351703647146\n",
      "train loss:0.009842310196666716\n",
      "train loss:0.015859412580701046\n",
      "train loss:0.025205354218011667\n",
      "train loss:0.012956756640201222\n",
      "train loss:0.06336067803292664\n",
      "train loss:0.030392260080300045\n",
      "train loss:0.02745593608735239\n",
      "train loss:0.037419177760573026\n",
      "train loss:0.004599149907493116\n",
      "train loss:0.006810257613976143\n",
      "train loss:0.062315773214202765\n",
      "train loss:0.01007631787737062\n",
      "train loss:0.007836827711451042\n",
      "train loss:0.015998369849979377\n",
      "train loss:0.05770895067571092\n",
      "train loss:0.021082618610525246\n",
      "train loss:0.016446546784306917\n",
      "train loss:0.016724353859214655\n",
      "train loss:0.01989300911824038\n",
      "train loss:0.027217258386121154\n",
      "train loss:0.010241025168297637\n",
      "train loss:0.08972295146641697\n",
      "train loss:0.0036933284221874535\n",
      "train loss:0.06000431445505614\n",
      "train loss:0.03198530489789222\n",
      "train loss:0.011942617952690917\n",
      "train loss:0.012984179667964406\n",
      "train loss:0.055303709691527876\n",
      "train loss:0.03732425194179557\n",
      "train loss:0.026414781419656978\n",
      "train loss:0.04320611263737459\n",
      "train loss:0.08606067867994788\n",
      "train loss:0.009312688860252018\n",
      "train loss:0.0125381065727014\n",
      "train loss:0.05058159961549286\n",
      "train loss:0.02316379912586251\n",
      "train loss:0.04336647546346421\n",
      "train loss:0.0060924510951061335\n",
      "train loss:0.016904272797079848\n",
      "train loss:0.04010460537711208\n",
      "train loss:0.06118774316711978\n",
      "train loss:0.021338411406080778\n",
      "train loss:0.05125107988505492\n",
      "train loss:0.010114336238327477\n",
      "train loss:0.013515756711197466\n",
      "train loss:0.012954103425578282\n",
      "train loss:0.04832867650765283\n",
      "train loss:0.024191032377084195\n",
      "train loss:0.013281237945978758\n",
      "train loss:0.052696600017503516\n",
      "train loss:0.025492820567151228\n",
      "train loss:0.025964224041039263\n",
      "train loss:0.021908175908699604\n",
      "train loss:0.032643013200958054\n",
      "train loss:0.007248430993068033\n",
      "train loss:0.01565073999644276\n",
      "train loss:0.014090412105867844\n",
      "train loss:0.009050911936833932\n",
      "train loss:0.07787552152974228\n",
      "train loss:0.02161065391665779\n",
      "train loss:0.02227385061988935\n",
      "train loss:0.013755380012951991\n",
      "train loss:0.023179302551756376\n",
      "train loss:0.03857903268840978\n",
      "train loss:0.02235323788543214\n",
      "train loss:0.01389333099968282\n",
      "train loss:0.018808201765825983\n",
      "train loss:0.007195528579153905\n",
      "train loss:0.035892519165824054\n",
      "train loss:0.015151435423254674\n",
      "train loss:0.06276915200449278\n",
      "train loss:0.01256813408782332\n",
      "train loss:0.03486202964118105\n",
      "train loss:0.054656298668985685\n",
      "train loss:0.043042249932826085\n",
      "train loss:0.0251070537900986\n",
      "train loss:0.004942427773667934\n",
      "train loss:0.012248291223750958\n",
      "train loss:0.03668538791678708\n",
      "train loss:0.0573706435077821\n",
      "train loss:0.049350927056268645\n",
      "train loss:0.1058150161755549\n",
      "train loss:0.027337108950472276\n",
      "train loss:0.04631938521178124\n",
      "train loss:0.18805026905611125\n",
      "train loss:0.015192429073842226\n",
      "train loss:0.007732044909353987\n",
      "train loss:0.018018964724920858\n",
      "train loss:0.0379649448312908\n",
      "train loss:0.020573873706168266\n",
      "train loss:0.015360500030178527\n",
      "train loss:0.02349946842108705\n",
      "train loss:0.014645414891941213\n",
      "train loss:0.008188244378121337\n",
      "train loss:0.04431578835711871\n",
      "train loss:0.012634868668938141\n",
      "train loss:0.01746855830199245\n",
      "train loss:0.0625514113967557\n",
      "train loss:0.008673329373562735\n",
      "train loss:0.013092577846014464\n",
      "train loss:0.024083549687342463\n",
      "train loss:0.02127720925230729\n",
      "train loss:0.011296191549187014\n",
      "train loss:0.04917819580263678\n",
      "train loss:0.014346876898345405\n",
      "train loss:0.003247697214995249\n",
      "train loss:0.04049913630503839\n",
      "train loss:0.050359430204732464\n",
      "train loss:0.05026011676514618\n",
      "train loss:0.022199318777002822\n",
      "train loss:0.0515544385824868\n",
      "train loss:0.030829312984066357\n",
      "train loss:0.011362517918411884\n",
      "train loss:0.07128196860900088\n",
      "train loss:0.02850169301768451\n",
      "train loss:0.017596983580344328\n",
      "train loss:0.008373134747046419\n",
      "train loss:0.03772608579108192\n",
      "train loss:0.012101752124882532\n",
      "train loss:0.015934464367617064\n",
      "train loss:0.05153484541952096\n",
      "train loss:0.03309101349647043\n",
      "train loss:0.03831460654220316\n",
      "train loss:0.06092039006287635\n",
      "train loss:0.06493760879318257\n",
      "train loss:0.05106322834257015\n",
      "train loss:0.021090342171639784\n",
      "train loss:0.00731745541289237\n",
      "train loss:0.02831588144814801\n",
      "train loss:0.034373391438568254\n",
      "train loss:0.07374526116192566\n",
      "train loss:0.017795813178215162\n",
      "train loss:0.02267477374925309\n",
      "train loss:0.028001976109428835\n",
      "train loss:0.11664909346214293\n",
      "train loss:0.021684481749381\n",
      "train loss:0.023256827123945705\n",
      "train loss:0.006944918962557743\n",
      "train loss:0.021192128407423367\n",
      "train loss:0.02369585849193831\n",
      "train loss:0.0166137183017902\n",
      "train loss:0.009958665146350415\n",
      "train loss:0.027343504459718157\n",
      "train loss:0.033750465798859854\n",
      "train loss:0.045006156088647914\n",
      "train loss:0.04257638966327873\n",
      "train loss:0.020999179195342374\n",
      "train loss:0.007143992030337004\n",
      "train loss:0.022625004810963318\n",
      "train loss:0.008958939917585552\n",
      "train loss:0.003648461813817925\n",
      "train loss:0.013664309344486028\n",
      "train loss:0.027209031419410456\n",
      "train loss:0.004810845352046155\n",
      "train loss:0.0388117781975275\n",
      "train loss:0.008856545130351954\n",
      "train loss:0.0338990926538453\n",
      "train loss:0.014184437537513504\n",
      "train loss:0.044435555835374514\n",
      "train loss:0.00844247584202768\n",
      "train loss:0.02475309031347098\n",
      "train loss:0.025247415807648985\n",
      "train loss:0.027971162218966783\n",
      "train loss:0.0048336183721646945\n",
      "train loss:0.02544332393237964\n",
      "train loss:0.026156253713107147\n",
      "train loss:0.04634959944955585\n",
      "train loss:0.02793911183266322\n",
      "train loss:0.043062309540002064\n",
      "train loss:0.04584168161540078\n",
      "train loss:0.0614001320715212\n",
      "train loss:0.06610081543159337\n",
      "train loss:0.014871736448106292\n",
      "train loss:0.033654749873760444\n",
      "train loss:0.035102780758952984\n",
      "train loss:0.03415722493437573\n",
      "train loss:0.17034881912110694\n",
      "train loss:0.007789188961114619\n",
      "train loss:0.03316721445143953\n",
      "train loss:0.052468478665355145\n",
      "train loss:0.015277522077179721\n",
      "train loss:0.00437754135336174\n",
      "train loss:0.011725212763338964\n",
      "train loss:0.04220859056946495\n",
      "train loss:0.030073635489155537\n",
      "train loss:0.01309947363493449\n",
      "train loss:0.028254888933213877\n",
      "train loss:0.029917379051038213\n",
      "train loss:0.02319189790985984\n",
      "train loss:0.016112907082777104\n",
      "train loss:0.009676012112457616\n",
      "train loss:0.04813757943470114\n",
      "train loss:0.005071584320528595\n",
      "train loss:0.005542660425675314\n",
      "train loss:0.05467578058128736\n",
      "train loss:0.02115464587987782\n",
      "train loss:0.019285196582879725\n",
      "train loss:0.017872870686259746\n",
      "train loss:0.057743203835153585\n",
      "train loss:0.007227466619085778\n",
      "train loss:0.007514875608308042\n",
      "train loss:0.023662530142651676\n",
      "train loss:0.012128588513867958\n",
      "train loss:0.014364613493040843\n",
      "train loss:0.017209777808393972\n",
      "train loss:0.07193754738511944\n",
      "train loss:0.06333157914607436\n",
      "train loss:0.05919952964304421\n",
      "train loss:0.013127480545269686\n",
      "train loss:0.018603077289135274\n",
      "train loss:0.035206718949553094\n",
      "train loss:0.0171256366861993\n",
      "train loss:0.004576756984591812\n",
      "train loss:0.03732906901163859\n",
      "train loss:0.005937610883100523\n",
      "train loss:0.04601601268234836\n",
      "train loss:0.022060956425286445\n",
      "train loss:0.01640758701400505\n",
      "train loss:0.01660730621862524\n",
      "train loss:0.009223037487588048\n",
      "train loss:0.029589630595330443\n",
      "train loss:0.007135055629984788\n",
      "train loss:0.020159492661259163\n",
      "train loss:0.016731112133442024\n",
      "train loss:0.018448449900350467\n",
      "train loss:0.04262247506419788\n",
      "train loss:0.055615740711589895\n",
      "train loss:0.0048928419393172\n",
      "train loss:0.010054585683893143\n",
      "train loss:0.015460855677606546\n",
      "train loss:0.017806414073058194\n",
      "train loss:0.11843458577704664\n",
      "train loss:0.036339987246403374\n",
      "train loss:0.09629922534227325\n",
      "train loss:0.0116810948507458\n",
      "train loss:0.0908780085763523\n",
      "train loss:0.041734414579567475\n",
      "train loss:0.027882838823762402\n",
      "train loss:0.02144356799882317\n",
      "train loss:0.059484477939074826\n",
      "train loss:0.05689044995240927\n",
      "train loss:0.006331556508068048\n",
      "train loss:0.049957217339272025\n",
      "train loss:0.0067361102790625986\n",
      "train loss:0.007743775679627699\n",
      "train loss:0.03477181362872686\n",
      "train loss:0.04370612626671003\n",
      "train loss:0.06444541203214253\n",
      "train loss:0.022144272879603764\n",
      "train loss:0.026881660402002107\n",
      "train loss:0.05117704022100569\n",
      "train loss:0.03236960566943682\n",
      "train loss:0.10602815681911607\n",
      "train loss:0.014324456294866193\n",
      "train loss:0.014912934011069719\n",
      "train loss:0.026320516734412457\n",
      "train loss:0.02486438431013795\n",
      "train loss:0.012862306145702431\n",
      "train loss:0.023178944181332928\n",
      "train loss:0.028677888263980305\n",
      "train loss:0.02363151185077244\n",
      "train loss:0.008890855134658187\n",
      "train loss:0.027963478025719194\n",
      "train loss:0.012086503412857184\n",
      "train loss:0.05488678256905557\n",
      "train loss:0.02213639866060656\n",
      "train loss:0.030954091873652844\n",
      "train loss:0.04350421421329417\n",
      "train loss:0.04432386452141886\n",
      "train loss:0.05498328690046998\n",
      "train loss:0.053671215001835214\n",
      "train loss:0.004628515689978605\n",
      "train loss:0.02224001702612442\n",
      "train loss:0.04110281779761511\n",
      "train loss:0.014142151426038186\n",
      "train loss:0.011191450420785337\n",
      "train loss:0.024814629992204167\n",
      "train loss:0.03879154690653124\n",
      "train loss:0.011696512999468549\n",
      "train loss:0.04880376497331969\n",
      "train loss:0.012263800072399968\n",
      "train loss:0.011329677897084455\n",
      "train loss:0.011326073860806656\n",
      "train loss:0.04332847963769994\n",
      "train loss:0.09053132931023193\n",
      "train loss:0.009999670845744525\n",
      "train loss:0.05830899111182025\n",
      "train loss:0.03973432370325125\n",
      "train loss:0.01621203090459562\n",
      "train loss:0.05554637357311769\n",
      "train loss:0.014036625388236714\n",
      "train loss:0.022070494598713436\n",
      "train loss:0.015171737145465276\n",
      "train loss:0.030337022915681317\n",
      "train loss:0.012960712731781857\n",
      "train loss:0.037222739655087655\n",
      "train loss:0.011019103364111858\n",
      "train loss:0.020302194238766953\n",
      "train loss:0.050804587834052874\n",
      "train loss:0.05092255973633022\n",
      "train loss:0.15911407327599048\n",
      "train loss:0.037053611295846944\n",
      "train loss:0.03222969896090087\n",
      "train loss:0.02589985213133921\n",
      "train loss:0.01743029766148338\n",
      "train loss:0.031265214467222274\n",
      "train loss:0.010898643151748788\n",
      "train loss:0.019141889624645237\n",
      "train loss:0.010551352749277192\n",
      "train loss:0.01804106724813738\n",
      "train loss:0.02935348983940168\n",
      "train loss:0.022451234881605064\n",
      "train loss:0.012955452606959041\n",
      "train loss:0.01347118580909486\n",
      "train loss:0.027513674717568746\n",
      "train loss:0.03574449453857104\n",
      "train loss:0.023424585954564398\n",
      "train loss:0.022891589799823964\n",
      "train loss:0.05786740457676629\n",
      "train loss:0.05489730625388943\n",
      "train loss:0.0108593166590196\n",
      "train loss:0.009658049757813864\n",
      "train loss:0.014863440217025016\n",
      "train loss:0.017159546144766166\n",
      "train loss:0.009370169468493969\n",
      "train loss:0.01083692532097135\n",
      "train loss:0.010399739675575741\n",
      "train loss:0.009643386889699028\n",
      "train loss:0.024314351252646405\n",
      "train loss:0.14674567150736936\n",
      "train loss:0.017951441671038692\n",
      "train loss:0.026188946350187033\n",
      "train loss:0.026009127560153073\n",
      "train loss:0.016571678367266703\n",
      "train loss:0.01929055588540765\n",
      "train loss:0.0105207572471962\n",
      "train loss:0.012355790627880576\n",
      "train loss:0.02043423243201026\n",
      "train loss:0.0075325711601348525\n",
      "train loss:0.013941893905797203\n",
      "train loss:0.01973844506454421\n",
      "train loss:0.10246737157973859\n",
      "train loss:0.044730242195601705\n",
      "train loss:0.030628841218526014\n",
      "train loss:0.0507928594070997\n",
      "train loss:0.025187393739994218\n",
      "train loss:0.00981533688649369\n",
      "train loss:0.006643281659281728\n",
      "train loss:0.021727293680635622\n",
      "=== epoch:6, train acc:0.983, test acc:0.984 ===\n",
      "train loss:0.011058729666735706\n",
      "train loss:0.013541337286124243\n",
      "train loss:0.017070118059286637\n",
      "train loss:0.009429688080231676\n",
      "train loss:0.019591146758502372\n",
      "train loss:0.00855657071532228\n",
      "train loss:0.015354642936168481\n",
      "train loss:0.027572129800478868\n",
      "train loss:0.0249815798486246\n",
      "train loss:0.0870675057575372\n",
      "train loss:0.02878935196252552\n",
      "train loss:0.021570776133714147\n",
      "train loss:0.033873147372058494\n",
      "train loss:0.03170639667084942\n",
      "train loss:0.05917893784606636\n",
      "train loss:0.04919967476200302\n",
      "train loss:0.05310368424385035\n",
      "train loss:0.09524550443581578\n",
      "train loss:0.009944948433625249\n",
      "train loss:0.027378178609739158\n",
      "train loss:0.004618839521781284\n",
      "train loss:0.02770817616713154\n",
      "train loss:0.058267477691953874\n",
      "train loss:0.0797599170086598\n",
      "train loss:0.007554800245967681\n",
      "train loss:0.02990422192963766\n",
      "train loss:0.030705655740858272\n",
      "train loss:0.014458095256160866\n",
      "train loss:0.01257987593752533\n",
      "train loss:0.029787596086156647\n",
      "train loss:0.019684367161428934\n",
      "train loss:0.0046366799620404285\n",
      "train loss:0.05414539090771967\n",
      "train loss:0.02131708213154724\n",
      "train loss:0.014147284871839593\n",
      "train loss:0.00802046087866362\n",
      "train loss:0.02872234553836855\n",
      "train loss:0.020115168092202245\n",
      "train loss:0.039684126628264906\n",
      "train loss:0.01250651864533302\n",
      "train loss:0.017530281770088675\n",
      "train loss:0.03351544895308236\n",
      "train loss:0.014134339035748265\n",
      "train loss:0.042304128845415324\n",
      "train loss:0.013454404974975803\n",
      "train loss:0.011751212831207019\n",
      "train loss:0.024838157103662998\n",
      "train loss:0.05873250506087729\n",
      "train loss:0.007331674336989522\n",
      "train loss:0.002466564416836259\n",
      "train loss:0.05057923147078944\n",
      "train loss:0.01323151590302028\n",
      "train loss:0.043116671321330687\n",
      "train loss:0.011939062297496862\n",
      "train loss:0.011755091250917931\n",
      "train loss:0.10669831551919282\n",
      "train loss:0.04674344956911725\n",
      "train loss:0.03607157000529314\n",
      "train loss:0.04438393285716471\n",
      "train loss:0.024348407159284068\n",
      "train loss:0.014874323898424626\n",
      "train loss:0.013235320426455565\n",
      "train loss:0.03335149616072526\n",
      "train loss:0.0072222682821659265\n",
      "train loss:0.04443486611947063\n",
      "train loss:0.0445255349496613\n",
      "train loss:0.01799192203198507\n",
      "train loss:0.024173944699004385\n",
      "train loss:0.02112764210628742\n",
      "train loss:0.047474888685837296\n",
      "train loss:0.030223093025127105\n",
      "train loss:0.03769630287844263\n",
      "train loss:0.015746421631936666\n",
      "train loss:0.027266543712577782\n",
      "train loss:0.01341743076755213\n",
      "train loss:0.013875354779876623\n",
      "train loss:0.019792503313750938\n",
      "train loss:0.0428583172416563\n",
      "train loss:0.033503820292791066\n",
      "train loss:0.11047959415844279\n",
      "train loss:0.029837726964911635\n",
      "train loss:0.019678051124970796\n",
      "train loss:0.07666986941055767\n",
      "train loss:0.018795466257411395\n",
      "train loss:0.0239642221326066\n",
      "train loss:0.032313664439989516\n",
      "train loss:0.008989069829785595\n",
      "train loss:0.020823600064440305\n",
      "train loss:0.01585723089637734\n",
      "train loss:0.017753801139569668\n",
      "train loss:0.01602636216714714\n",
      "train loss:0.01220341512843715\n",
      "train loss:0.013592209820033896\n",
      "train loss:0.028174528739863095\n",
      "train loss:0.007525948932057817\n",
      "train loss:0.03103437187090447\n",
      "train loss:0.010242218006038094\n",
      "train loss:0.020543156956495\n",
      "train loss:0.027792363072477334\n",
      "train loss:0.03705559249924477\n",
      "train loss:0.05343747119601857\n",
      "train loss:0.012609066060916631\n",
      "train loss:0.03836704999093268\n",
      "train loss:0.09195533132818108\n",
      "train loss:0.027843394318170307\n",
      "train loss:0.046755430555405555\n",
      "train loss:0.09384023320387433\n",
      "train loss:0.010002533941364284\n",
      "train loss:0.012849514056622246\n",
      "train loss:0.015073317706416322\n",
      "train loss:0.015369837149915265\n",
      "train loss:0.004894986247204535\n",
      "train loss:0.016133245162149503\n",
      "train loss:0.01674582486197626\n",
      "train loss:0.011209259573673991\n",
      "train loss:0.1447486757416029\n",
      "train loss:0.009366661051075087\n",
      "train loss:0.013821104108051756\n",
      "train loss:0.02033940366543805\n",
      "train loss:0.007657782860702464\n",
      "train loss:0.07771105450338447\n",
      "train loss:0.05088856751223499\n",
      "train loss:0.015581740365408367\n",
      "train loss:0.009610092159308983\n",
      "train loss:0.059922416623446904\n",
      "train loss:0.020679965129886943\n",
      "train loss:0.01665668828117572\n",
      "train loss:0.02338282528612701\n",
      "train loss:0.026995889295882293\n",
      "train loss:0.051960052039882576\n",
      "train loss:0.07041875386439095\n",
      "train loss:0.029794708260850858\n",
      "train loss:0.005544466340835527\n",
      "train loss:0.016998384216308605\n",
      "train loss:0.009566461217372526\n",
      "train loss:0.02059663986734263\n",
      "train loss:0.02740679498479538\n",
      "train loss:0.06575894440835169\n",
      "train loss:0.06277666337578534\n",
      "train loss:0.040769041383311985\n",
      "train loss:0.01949311119794347\n",
      "train loss:0.018060498811310798\n",
      "train loss:0.002722523185003195\n",
      "train loss:0.03221620805525023\n",
      "train loss:0.019430122078824028\n",
      "train loss:0.046414461820694614\n",
      "train loss:0.13094319023924336\n",
      "train loss:0.019399629921739367\n",
      "train loss:0.011085901980518214\n",
      "train loss:0.009459507062806363\n",
      "train loss:0.025278061651851206\n",
      "train loss:0.019177645988047637\n",
      "train loss:0.00793568958202455\n",
      "train loss:0.020269965804786745\n",
      "train loss:0.04902745201171167\n",
      "train loss:0.014403288238184953\n",
      "train loss:0.0743195186575091\n",
      "train loss:0.028548401020105377\n",
      "train loss:0.043943747564105344\n",
      "train loss:0.020926146065065706\n",
      "train loss:0.01110553624932681\n",
      "train loss:0.04518606698173098\n",
      "train loss:0.0067738357238122\n",
      "train loss:0.0191374347322366\n",
      "train loss:0.024383388357729515\n",
      "train loss:0.01868189785118481\n",
      "train loss:0.011498066409850816\n",
      "train loss:0.020744871499633045\n",
      "train loss:0.02323203897311611\n",
      "train loss:0.025227406405867688\n",
      "train loss:0.0037292880584979364\n",
      "train loss:0.012253520469203019\n",
      "train loss:0.03715732435662593\n",
      "train loss:0.04057126543963724\n",
      "train loss:0.036840577347066576\n",
      "train loss:0.022842951780880378\n",
      "train loss:0.010593690781191257\n",
      "train loss:0.005958812420721875\n",
      "train loss:0.02264909695868337\n",
      "train loss:0.016767155300385198\n",
      "train loss:0.06289362106030005\n",
      "train loss:0.008632415777973149\n",
      "train loss:0.02681069372805922\n",
      "train loss:0.007246815646775484\n",
      "train loss:0.022264088715436267\n",
      "train loss:0.08354638327940264\n",
      "train loss:0.02839214719678992\n",
      "train loss:0.034828219959663065\n",
      "train loss:0.019387409286345688\n",
      "train loss:0.012794719344663672\n",
      "train loss:0.00989555974578016\n",
      "train loss:0.006891107434533782\n",
      "train loss:0.014829824715920852\n",
      "train loss:0.007689601549413034\n",
      "train loss:0.04115853253794008\n",
      "train loss:0.05373774170100881\n",
      "train loss:0.01494563123360549\n",
      "train loss:0.008269511870276537\n",
      "train loss:0.008413769111527837\n",
      "train loss:0.015270497551892824\n",
      "train loss:0.0260833542803488\n",
      "train loss:0.01634123986407618\n",
      "train loss:0.0077599667544093285\n",
      "train loss:0.020527401734605096\n",
      "train loss:0.04366916253968042\n",
      "train loss:0.019408612649445506\n",
      "train loss:0.01949982215483192\n",
      "train loss:0.009440640250485433\n",
      "train loss:0.05002417210613786\n",
      "train loss:0.004548980967329117\n",
      "train loss:0.06952294445423851\n",
      "train loss:0.012811157321998936\n",
      "train loss:0.012017049152085665\n",
      "train loss:0.0036440723666174217\n",
      "train loss:0.016885365962586697\n",
      "train loss:0.007845186694311142\n",
      "train loss:0.01813046849308958\n",
      "train loss:0.0233073004109177\n",
      "train loss:0.06373411275318473\n",
      "train loss:0.013235743741411182\n",
      "train loss:0.0933512442511327\n",
      "train loss:0.06931994753684717\n",
      "train loss:0.018714566022188277\n",
      "train loss:0.016452358277314588\n",
      "train loss:0.08668965111437671\n",
      "train loss:0.01893033007536722\n",
      "train loss:0.02173940116230109\n",
      "train loss:0.031072266866614753\n",
      "train loss:0.03910028142816176\n",
      "train loss:0.003798898411012221\n",
      "train loss:0.0351330633425823\n",
      "train loss:0.059097186695131775\n",
      "train loss:0.015516965505721592\n",
      "train loss:0.00726839561058901\n",
      "train loss:0.01906918000568682\n",
      "train loss:0.005179057402996315\n",
      "train loss:0.004995200859068159\n",
      "train loss:0.0038853025627503517\n",
      "train loss:0.0028286082102922483\n",
      "train loss:0.051788532181985404\n",
      "train loss:0.006874533186839341\n",
      "train loss:0.016159113865401677\n",
      "train loss:0.0076293840981978825\n",
      "train loss:0.008143856418867813\n",
      "train loss:0.008289857646939281\n",
      "train loss:0.026376648595633632\n",
      "train loss:0.039344830341121836\n",
      "train loss:0.011564812640594613\n",
      "train loss:0.005397597056258703\n",
      "train loss:0.01746069233572679\n",
      "train loss:0.009993807202946261\n",
      "train loss:0.04035981307801831\n",
      "train loss:0.017627143367121713\n",
      "train loss:0.016997253586009734\n",
      "train loss:0.03469471511928222\n",
      "train loss:0.012447308617135196\n",
      "train loss:0.010362227763844356\n",
      "train loss:0.005501379902280962\n",
      "train loss:0.06624419528763233\n",
      "train loss:0.03434817265017592\n",
      "train loss:0.002455477775345501\n",
      "train loss:0.016706484874464966\n",
      "train loss:0.03226610159367202\n",
      "train loss:0.019013593551520037\n",
      "train loss:0.002295068870175058\n",
      "train loss:0.018626399874141383\n",
      "train loss:0.013460881539402957\n",
      "train loss:0.03804015908737147\n",
      "train loss:0.014877046125372734\n",
      "train loss:0.06630678456560175\n",
      "train loss:0.0230649470490795\n",
      "train loss:0.011414734570954344\n",
      "train loss:0.016480340494404014\n",
      "train loss:0.060815591837930894\n",
      "train loss:0.032505101930591994\n",
      "train loss:0.006102712116517115\n",
      "train loss:0.020558599323620988\n",
      "train loss:0.024218988176388283\n",
      "train loss:0.019633026287726053\n",
      "train loss:0.012310078926020802\n",
      "train loss:0.006140054192344795\n",
      "train loss:0.0043405491182375655\n",
      "train loss:0.04381675635756371\n",
      "train loss:0.013668686012877594\n",
      "train loss:0.016586137267587505\n",
      "train loss:0.007420699180614629\n",
      "train loss:0.007571791139834214\n",
      "train loss:0.015095671391952918\n",
      "train loss:0.008764381849374073\n",
      "train loss:0.006386129164118958\n",
      "train loss:0.006088657315646666\n",
      "train loss:0.007775141282237532\n",
      "train loss:0.022946567730628486\n",
      "train loss:0.02893381333875826\n",
      "train loss:0.01680309641414818\n",
      "train loss:0.01779258623090187\n",
      "train loss:0.007612438289828494\n",
      "train loss:0.0031554678883394887\n",
      "train loss:0.006514132223434502\n",
      "train loss:0.061899345700218274\n",
      "train loss:0.009052878333861022\n",
      "train loss:0.0182289463002127\n",
      "train loss:0.02913132260508281\n",
      "train loss:0.010100144799039402\n",
      "train loss:0.018217432916962775\n",
      "train loss:0.001683485306578028\n",
      "train loss:0.01644574095260578\n",
      "train loss:0.010934521135709642\n",
      "train loss:0.008802617594086999\n",
      "train loss:0.03910259157793371\n",
      "train loss:0.132231450457275\n",
      "train loss:0.008720053671808918\n",
      "train loss:0.020203072499187548\n",
      "train loss:0.04349786006340502\n",
      "train loss:0.036237551020841974\n",
      "train loss:0.015620378458922769\n",
      "train loss:0.002860242339219749\n",
      "train loss:0.008365886043737435\n",
      "train loss:0.012527597044286486\n",
      "train loss:0.028036953825680267\n",
      "train loss:0.013554419811622913\n",
      "train loss:0.03143277846911378\n",
      "train loss:0.013031839085766677\n",
      "train loss:0.06273630780402242\n",
      "train loss:0.013869177440124272\n",
      "train loss:0.003284867725922062\n",
      "train loss:0.0041741345462544535\n",
      "train loss:0.015708246461711078\n",
      "train loss:0.018682133639744865\n",
      "train loss:0.027703327188313517\n",
      "train loss:0.03929383616061882\n",
      "train loss:0.09419985146914661\n",
      "train loss:0.11334708750854952\n",
      "train loss:0.00994833997545726\n",
      "train loss:0.015874754606925244\n",
      "train loss:0.02803956939200951\n",
      "train loss:0.010746290094379279\n",
      "train loss:0.022445596017622037\n",
      "train loss:0.013306789007173808\n",
      "train loss:0.020386641104617954\n",
      "train loss:0.008038624018200852\n",
      "train loss:0.019888879556078244\n",
      "train loss:0.01379530523672397\n",
      "train loss:0.007646536583031241\n",
      "train loss:0.04608991505749775\n",
      "train loss:0.02476379303314094\n",
      "train loss:0.0268873897202206\n",
      "train loss:0.016843572612727335\n",
      "train loss:0.023046614425092572\n",
      "train loss:0.03393693858469494\n",
      "train loss:0.010808435208868355\n",
      "train loss:0.02959495301430588\n",
      "train loss:0.006789917241442661\n",
      "train loss:0.01766854325682929\n",
      "train loss:0.010040228425095221\n",
      "train loss:0.07125742369214073\n",
      "train loss:0.01281629902240839\n",
      "train loss:0.003872826229735867\n",
      "train loss:0.011675053743935586\n",
      "train loss:0.007633674523632061\n",
      "train loss:0.0023963529808880206\n",
      "train loss:0.002644756464373457\n",
      "train loss:0.022833253672154243\n",
      "train loss:0.05736460211516649\n",
      "train loss:0.03357004954881069\n",
      "train loss:0.026135411731095796\n",
      "train loss:0.045025781830953\n",
      "train loss:0.021409400735415415\n",
      "train loss:0.013095295380854117\n",
      "train loss:0.035207874853292326\n",
      "train loss:0.04890152486998074\n",
      "train loss:0.004324615700252012\n",
      "train loss:0.03220858817140659\n",
      "train loss:0.016821402359597216\n",
      "train loss:0.030538761309946243\n",
      "train loss:0.05722092290369996\n",
      "train loss:0.016102977651030918\n",
      "train loss:0.006174904958406906\n",
      "train loss:0.12865876007697127\n",
      "train loss:0.06204225492771379\n",
      "train loss:0.02876620818656331\n",
      "train loss:0.011799911341998705\n",
      "train loss:0.012250280452421665\n",
      "train loss:0.05244518162282993\n",
      "train loss:0.0072705454563730485\n",
      "train loss:0.01603892073522807\n",
      "train loss:0.016385241346369532\n",
      "train loss:0.0547285649071084\n",
      "train loss:0.013681407706830073\n",
      "train loss:0.01715676006083699\n",
      "train loss:0.023096347401061125\n",
      "train loss:0.012099601809127059\n",
      "train loss:0.008947163847729379\n",
      "train loss:0.011163053898688569\n",
      "train loss:0.01365805437082635\n",
      "train loss:0.042201705813846656\n",
      "train loss:0.014436781745887885\n",
      "train loss:0.032226004060896034\n",
      "train loss:0.03680829501147513\n",
      "train loss:0.016247828126009906\n",
      "train loss:0.00903914834019013\n",
      "train loss:0.025069956602431265\n",
      "train loss:0.022990054543238676\n",
      "train loss:0.0034204462003402394\n",
      "train loss:0.006054354443967308\n",
      "train loss:0.03951085638546338\n",
      "train loss:0.046155168432607085\n",
      "train loss:0.08423782867157206\n",
      "train loss:0.026919956057791596\n",
      "train loss:0.005777870268546105\n",
      "train loss:0.07172832777662307\n",
      "train loss:0.0389470301770814\n",
      "train loss:0.014007720493254551\n",
      "train loss:0.01762200772196765\n",
      "train loss:0.0225223833052854\n",
      "train loss:0.014133341351409987\n",
      "train loss:0.01741710871092034\n",
      "train loss:0.05632709305509692\n",
      "train loss:0.004560504195608008\n",
      "train loss:0.011953976294675244\n",
      "train loss:0.010541849242088891\n",
      "train loss:0.006814135939670234\n",
      "train loss:0.008218865777221642\n",
      "train loss:0.0015485875657463267\n",
      "train loss:0.03967728301428886\n",
      "train loss:0.009026897039247089\n",
      "train loss:0.04884766567359889\n",
      "train loss:0.024864480169884125\n",
      "train loss:0.0033254340630558842\n",
      "train loss:0.01741021061294609\n",
      "train loss:0.01975222862917588\n",
      "train loss:0.038533883388444004\n",
      "train loss:0.0520350864714246\n",
      "train loss:0.011725451612222795\n",
      "train loss:0.05375078739983063\n",
      "train loss:0.01031218014326518\n",
      "train loss:0.04125065542392209\n",
      "train loss:0.01210237382678896\n",
      "train loss:0.02999168833382321\n",
      "train loss:0.04569093826075937\n",
      "train loss:0.027882176151881745\n",
      "train loss:0.013760754477454864\n",
      "train loss:0.041346163161256395\n",
      "train loss:0.012685629831018447\n",
      "train loss:0.0166752396244589\n",
      "train loss:0.008428460091748134\n",
      "train loss:0.0044254108685409\n",
      "train loss:0.02271052344354889\n",
      "train loss:0.0026114894996292983\n",
      "train loss:0.034995183639416644\n",
      "train loss:0.06496513419839228\n",
      "train loss:0.0054130358692068585\n",
      "train loss:0.08171841326426048\n",
      "train loss:0.003100719269212336\n",
      "train loss:0.138529597578892\n",
      "train loss:0.014618543455018682\n",
      "train loss:0.006691075628152093\n",
      "train loss:0.036392558325445364\n",
      "train loss:0.021390861663682\n",
      "train loss:0.011735544815317848\n",
      "train loss:0.016553859024163457\n",
      "train loss:0.020755001377991338\n",
      "train loss:0.009506902194136455\n",
      "train loss:0.007638480696762898\n",
      "train loss:0.03251742916142991\n",
      "train loss:0.01820746890703352\n",
      "train loss:0.06859810712601712\n",
      "train loss:0.001879020677494878\n",
      "train loss:0.055408874908600324\n",
      "train loss:0.026591571737623495\n",
      "train loss:0.011203369374432367\n",
      "train loss:0.052529822857945246\n",
      "train loss:0.0184607645640888\n",
      "train loss:0.012470978247205071\n",
      "train loss:0.006222425595708301\n",
      "train loss:0.04701559716290928\n",
      "train loss:0.011824912379832592\n",
      "train loss:0.04332806665678475\n",
      "train loss:0.01504971245614268\n",
      "train loss:0.018168867746742912\n",
      "train loss:0.005893723390767737\n",
      "train loss:0.009440733294364576\n",
      "train loss:0.025164372180561317\n",
      "train loss:0.025273868555542187\n",
      "train loss:0.03589689401169689\n",
      "train loss:0.01728799602542576\n",
      "train loss:0.014382442098806387\n",
      "train loss:0.013116775738045993\n",
      "train loss:0.016597633615799745\n",
      "train loss:0.0468681250104504\n",
      "train loss:0.009861824308495649\n",
      "train loss:0.011992873882367154\n",
      "train loss:0.015828632057297773\n",
      "train loss:0.0018076977404228717\n",
      "train loss:0.028970984177564066\n",
      "train loss:0.013971268408372393\n",
      "train loss:0.004331328296544694\n",
      "train loss:0.007154780714613524\n",
      "train loss:0.03616217151398801\n",
      "train loss:0.020980722017549525\n",
      "train loss:0.006298081378444748\n",
      "train loss:0.0109098761686902\n",
      "train loss:0.0033827750164448916\n",
      "train loss:0.06214497484675578\n",
      "train loss:0.0036441051172830586\n",
      "train loss:0.0026089028049035763\n",
      "train loss:0.007871044762820533\n",
      "train loss:0.015178027918622541\n",
      "train loss:0.02267628883535029\n",
      "train loss:0.0024005349381969574\n",
      "train loss:0.0592332170707486\n",
      "train loss:0.054297258408376764\n",
      "train loss:0.024047815163282665\n",
      "train loss:0.007648223867994114\n",
      "train loss:0.0197686002453722\n",
      "train loss:0.0027563303129045013\n",
      "train loss:0.03324881939993232\n",
      "train loss:0.010643760348462762\n",
      "train loss:0.007739346836118967\n",
      "train loss:0.02859640774694465\n",
      "train loss:0.06391112013241113\n",
      "train loss:0.013859441622653538\n",
      "train loss:0.010029420469718836\n",
      "train loss:0.018124716566670057\n",
      "train loss:0.02031119074420359\n",
      "train loss:0.012291915702371203\n",
      "train loss:0.04424299679515142\n",
      "train loss:0.020096946881957196\n",
      "train loss:0.0015728369413536268\n",
      "train loss:0.004551650293196332\n",
      "train loss:0.04433471599073068\n",
      "train loss:0.048447243745335926\n",
      "train loss:0.024257703968950568\n",
      "train loss:0.027615687395965333\n",
      "train loss:0.01846247158700166\n",
      "train loss:0.004082870964111137\n",
      "train loss:0.02916332046650652\n",
      "train loss:0.02092873088413525\n",
      "train loss:0.008369530209964287\n",
      "train loss:0.014512082144623567\n",
      "train loss:0.013149271657886524\n",
      "train loss:0.004713594641300275\n",
      "train loss:0.027655683751306333\n",
      "train loss:0.003337685632928547\n",
      "train loss:0.014511319360764814\n",
      "train loss:0.0046724983990190545\n",
      "train loss:0.011851142467771159\n",
      "train loss:0.005513805231630805\n",
      "train loss:0.006339851576442239\n",
      "train loss:0.0038106110753182666\n",
      "train loss:0.031928723990845294\n",
      "train loss:0.01018911127188433\n",
      "train loss:0.004018496267186239\n",
      "train loss:0.017445922480842934\n",
      "train loss:0.06521837895844859\n",
      "train loss:0.010151539000848912\n",
      "train loss:0.023870147070147486\n",
      "train loss:0.02471282531695629\n",
      "train loss:0.015348379230835983\n",
      "train loss:0.008519897209578636\n",
      "train loss:0.01760277857870508\n",
      "train loss:0.007996960305999827\n",
      "train loss:0.009728550720545617\n",
      "train loss:0.02309213403302235\n",
      "train loss:0.01296312903152862\n",
      "train loss:0.0027995928510355884\n",
      "train loss:0.008003248939990831\n",
      "train loss:0.001339283685139683\n",
      "train loss:0.01060749933145026\n",
      "train loss:0.021061410378036632\n",
      "train loss:0.007316245165799725\n",
      "train loss:0.010471888086104214\n",
      "train loss:0.026092410020118507\n",
      "train loss:0.007237576958971964\n",
      "train loss:0.00832496071918696\n",
      "train loss:0.009658348624483263\n",
      "train loss:0.001323286264464568\n",
      "train loss:0.005292935623991816\n",
      "train loss:0.010807056402961741\n",
      "train loss:0.003670277775577279\n",
      "train loss:0.004396514351529986\n",
      "train loss:0.0026371831683378723\n",
      "train loss:0.011285910787738818\n",
      "train loss:0.006494084428769572\n",
      "train loss:0.026458492628796643\n",
      "train loss:0.008391186823650058\n",
      "train loss:0.021370555062297923\n",
      "train loss:0.015806376538897896\n",
      "train loss:0.009690635028913132\n",
      "train loss:0.0060760159636903295\n",
      "train loss:0.011562867550815653\n",
      "train loss:0.007802953402074117\n",
      "train loss:0.004452634968306832\n",
      "train loss:0.01746035616499205\n",
      "train loss:0.018736628636112602\n",
      "train loss:0.02493210308299373\n",
      "train loss:0.002610676927514677\n",
      "train loss:0.03863611839296785\n",
      "train loss:0.005638252227439372\n",
      "train loss:0.00279118779138769\n",
      "=== epoch:7, train acc:0.992, test acc:0.984 ===\n",
      "train loss:0.00555839048481465\n",
      "train loss:0.004737684758591644\n",
      "train loss:0.03713945792993191\n",
      "train loss:0.0074287493509732514\n",
      "train loss:0.011453230910979974\n",
      "train loss:0.00653948509724961\n",
      "train loss:0.0035222476182089073\n",
      "train loss:0.018998217251485604\n",
      "train loss:0.013181908495730022\n",
      "train loss:0.03756388769921392\n",
      "train loss:0.06996221691080798\n",
      "train loss:0.00723522315254236\n",
      "train loss:0.006086090343549158\n",
      "train loss:0.004698460874000657\n",
      "train loss:0.006777458363164969\n",
      "train loss:0.037972133577555696\n",
      "train loss:0.010694748618497743\n",
      "train loss:0.04199248914085588\n",
      "train loss:0.006577747436527945\n",
      "train loss:0.01969306889124498\n",
      "train loss:0.0020055252447039058\n",
      "train loss:0.008385724830087728\n",
      "train loss:0.03501193743205837\n",
      "train loss:0.02216991741294771\n",
      "train loss:0.004023731253816709\n",
      "train loss:0.01607287123715756\n",
      "train loss:0.005466951883404121\n",
      "train loss:0.013550408851051209\n",
      "train loss:0.004457596435851454\n",
      "train loss:0.013901439291207273\n",
      "train loss:0.012487969759896278\n",
      "train loss:0.022717661164428818\n",
      "train loss:0.00888680722246497\n",
      "train loss:0.04182066994550987\n",
      "train loss:0.011787539988530936\n",
      "train loss:0.023061352427407172\n",
      "train loss:0.013744745957719382\n",
      "train loss:0.039122589403510606\n",
      "train loss:0.02834792518479602\n",
      "train loss:0.01714187533618097\n",
      "train loss:0.017683323666539606\n",
      "train loss:0.018233330837225965\n",
      "train loss:0.029961421150734014\n",
      "train loss:0.017125717729192826\n",
      "train loss:0.014059728864068094\n",
      "train loss:0.030501458983551864\n",
      "train loss:0.007959104484013643\n",
      "train loss:0.03293229457373623\n",
      "train loss:0.032350835348867936\n",
      "train loss:0.024147493026109013\n",
      "train loss:0.009407708898250737\n",
      "train loss:0.004800652787691816\n",
      "train loss:0.008802908363289636\n",
      "train loss:0.018262539405306293\n",
      "train loss:0.009655873548107088\n",
      "train loss:0.01497898064977778\n",
      "train loss:0.026134091293816563\n",
      "train loss:0.05367086864479293\n",
      "train loss:0.0023688070836031887\n",
      "train loss:0.03561217451895983\n",
      "train loss:0.019213380107709975\n",
      "train loss:0.0033142400078900952\n",
      "train loss:0.007097311680649281\n",
      "train loss:0.015028868157463444\n",
      "train loss:0.015668374175898205\n",
      "train loss:0.05586115379374064\n",
      "train loss:0.004836364260252207\n",
      "train loss:0.0047725024829377944\n",
      "train loss:0.03286552946556957\n",
      "train loss:0.008693112831697977\n",
      "train loss:0.020532842530258204\n",
      "train loss:0.025800405916592706\n",
      "train loss:0.023110419550066635\n",
      "train loss:0.005990988520342444\n",
      "train loss:0.009223320240607619\n",
      "train loss:0.08249723605523819\n",
      "train loss:0.011274321193097864\n",
      "train loss:0.05249024575481277\n",
      "train loss:0.022062157246195403\n",
      "train loss:0.012461356722655366\n",
      "train loss:0.011864305055322455\n",
      "train loss:0.04953724060255112\n",
      "train loss:0.007688951506741113\n",
      "train loss:0.06396070786030499\n",
      "train loss:0.025468210673263974\n",
      "train loss:0.005139986116790349\n",
      "train loss:0.005625471499441851\n",
      "train loss:0.04681045905348705\n",
      "train loss:0.021626122430089323\n",
      "train loss:0.015662811185085918\n",
      "train loss:0.019107549144159974\n",
      "train loss:0.030160836762453607\n",
      "train loss:0.05953017914249675\n",
      "train loss:0.01937506095205764\n",
      "train loss:0.031001815713064138\n",
      "train loss:0.0237157193732565\n",
      "train loss:0.028829017652458867\n",
      "train loss:0.013568105103566567\n",
      "train loss:0.02685812480873454\n",
      "train loss:0.014327749368660775\n",
      "train loss:0.0030913531731720963\n",
      "train loss:0.01984590108821981\n",
      "train loss:0.046973603677258426\n",
      "train loss:0.0030981628605884774\n",
      "train loss:0.01406267471261421\n",
      "train loss:0.04024993157955538\n",
      "train loss:0.00866413204444014\n",
      "train loss:0.012510945824109117\n",
      "train loss:0.01048182636252257\n",
      "train loss:0.009427208612851977\n",
      "train loss:0.02071400809604451\n",
      "train loss:0.02517040033389946\n",
      "train loss:0.0070399090338431865\n",
      "train loss:0.03316802733137624\n",
      "train loss:0.029441023171428396\n",
      "train loss:0.05979028015224066\n",
      "train loss:0.005944138698529103\n",
      "train loss:0.0036080492178646715\n",
      "train loss:0.023056782471830264\n",
      "train loss:0.02865511910324842\n",
      "train loss:0.06231437835526205\n",
      "train loss:0.013601967380687743\n",
      "train loss:0.0120085080462087\n",
      "train loss:0.021234896975592533\n",
      "train loss:0.006248784639982666\n",
      "train loss:0.04948434331352618\n",
      "train loss:0.005061927339789667\n",
      "train loss:0.022575554442152375\n",
      "train loss:0.010457477892804072\n",
      "train loss:0.00926462302052235\n",
      "train loss:0.013033223480386302\n",
      "train loss:0.008671044615479606\n",
      "train loss:0.04652013921997708\n",
      "train loss:0.010488320768840287\n",
      "train loss:0.02126209121753416\n",
      "train loss:0.04297777582974808\n",
      "train loss:0.0077849993195006\n",
      "train loss:0.015963982769162558\n",
      "train loss:0.012144724907287255\n",
      "train loss:0.022004897701219887\n",
      "train loss:0.008004787145058732\n",
      "train loss:0.010119290039330651\n",
      "train loss:0.025456945118774582\n",
      "train loss:0.037294849912489714\n",
      "train loss:0.01491305573007578\n",
      "train loss:0.015397598138262934\n",
      "train loss:0.03485021298785137\n",
      "train loss:0.006675315097151725\n",
      "train loss:0.01265030882783587\n",
      "train loss:0.046795276122189276\n",
      "train loss:0.002830729442677814\n",
      "train loss:0.006571256531093754\n",
      "train loss:0.012905110197389885\n",
      "train loss:0.03417796759015504\n",
      "train loss:0.01813388950636805\n",
      "train loss:0.011353650334160598\n",
      "train loss:0.01074732856829405\n",
      "train loss:0.058011235853716155\n",
      "train loss:0.0061748215511734416\n",
      "train loss:0.003939246093536005\n",
      "train loss:0.008474875566040155\n",
      "train loss:0.018080524749678972\n",
      "train loss:0.007371378571147026\n",
      "train loss:0.003767553823872382\n",
      "train loss:0.024015815520655872\n",
      "train loss:0.021435263598639107\n",
      "train loss:0.02055791243646713\n",
      "train loss:0.01027240490764185\n",
      "train loss:0.007798441491544021\n",
      "train loss:0.007336650330481604\n",
      "train loss:0.0064210504697241565\n",
      "train loss:0.015722041342566103\n",
      "train loss:0.015177985650130921\n",
      "train loss:0.008264940723840219\n",
      "train loss:0.0293406511388671\n",
      "train loss:0.0027477185892648853\n",
      "train loss:0.012513486267164175\n",
      "train loss:0.006031282555297863\n",
      "train loss:0.011175816136790947\n",
      "train loss:0.010484481604434475\n",
      "train loss:0.004571952067224851\n",
      "train loss:0.0033291000846829466\n",
      "train loss:0.004095299602290709\n",
      "train loss:0.009300025386953984\n",
      "train loss:0.013708885519953917\n",
      "train loss:0.008395350371381099\n",
      "train loss:0.0020585786892918885\n",
      "train loss:0.00570614149696091\n",
      "train loss:0.027090365043244597\n",
      "train loss:0.0075674955443931664\n",
      "train loss:0.005429623848759625\n",
      "train loss:0.054041153530136526\n",
      "train loss:0.03631435372246635\n",
      "train loss:0.0037928122796614828\n",
      "train loss:0.009416668486697888\n",
      "train loss:0.015721439636208506\n",
      "train loss:0.019981520313675675\n",
      "train loss:0.020916424466584916\n",
      "train loss:0.008159107782972748\n",
      "train loss:0.008323769712069133\n",
      "train loss:0.05010580812716009\n",
      "train loss:0.001516350697744468\n",
      "train loss:0.003314090380906558\n",
      "train loss:0.0017923523092815826\n",
      "train loss:0.014353749073848088\n",
      "train loss:0.0183846019371991\n",
      "train loss:0.007135409369770906\n",
      "train loss:0.0073006338249176515\n",
      "train loss:0.009974664041426641\n",
      "train loss:0.002444755022472886\n",
      "train loss:0.011704733832628399\n",
      "train loss:0.032620549152444764\n",
      "train loss:0.01678180066539785\n",
      "train loss:0.004478065359818227\n",
      "train loss:0.007596451820306485\n",
      "train loss:0.005179239591990768\n",
      "train loss:0.061699257024045905\n",
      "train loss:0.0018354843706883017\n",
      "train loss:0.015310090834229451\n",
      "train loss:0.005806679786095483\n",
      "train loss:0.005937234052795143\n",
      "train loss:0.01215642030692596\n",
      "train loss:0.003532360175067615\n",
      "train loss:0.018857584503519688\n",
      "train loss:0.005123954556650915\n",
      "train loss:0.028958394330536805\n",
      "train loss:0.008155294964041167\n",
      "train loss:0.008356984251851893\n",
      "train loss:0.02039123476969257\n",
      "train loss:0.02215168544086961\n",
      "train loss:0.005301905248674073\n",
      "train loss:0.0019657417894361467\n",
      "train loss:0.007410602373877928\n",
      "train loss:0.01015935822133929\n",
      "train loss:0.013517273195497247\n",
      "train loss:0.005564779164508096\n",
      "train loss:0.026864385243309016\n",
      "train loss:0.04169010533095231\n",
      "train loss:0.010981700634988807\n",
      "train loss:0.00802339759168295\n",
      "train loss:0.010769108289632033\n",
      "train loss:0.011290878477965756\n",
      "train loss:0.004052579573613858\n",
      "train loss:0.0035952296400900852\n",
      "train loss:0.03220136856247162\n",
      "train loss:0.011657403677501444\n",
      "train loss:0.021133881003537747\n",
      "train loss:0.012841622002921573\n",
      "train loss:0.0031303300369051766\n",
      "train loss:0.010120803372064802\n",
      "train loss:0.004877047647432121\n",
      "train loss:0.015275758984938263\n",
      "train loss:0.021279218460719482\n",
      "train loss:0.024504179375012165\n",
      "train loss:0.021335839827802103\n",
      "train loss:0.04792611225027758\n",
      "train loss:0.07496449008516402\n",
      "train loss:0.023326165944604113\n",
      "train loss:0.031542014839964126\n",
      "train loss:0.011806150193115206\n",
      "train loss:0.003556224851280937\n",
      "train loss:0.05459483772978792\n",
      "train loss:0.033720123495145825\n",
      "train loss:0.053689809486917844\n",
      "train loss:0.013972359838761418\n",
      "train loss:0.02678573810046254\n",
      "train loss:0.008545411785734041\n",
      "train loss:0.007561339406521133\n",
      "train loss:0.008913801256121708\n",
      "train loss:0.01425121142256963\n",
      "train loss:0.026747918159890333\n",
      "train loss:0.009648053153335487\n",
      "train loss:0.03254315886896129\n",
      "train loss:0.0031360409815100617\n",
      "train loss:0.005591942275168495\n",
      "train loss:0.017633198648960586\n",
      "train loss:0.01682919407497924\n",
      "train loss:0.025447091783926477\n",
      "train loss:0.003916779885938381\n",
      "train loss:0.007614016771354754\n",
      "train loss:0.011842237158252358\n",
      "train loss:0.011922618904572501\n",
      "train loss:0.006377072583523816\n",
      "train loss:0.0051948834707019245\n",
      "train loss:0.007132005656263644\n",
      "train loss:0.008015969921164483\n",
      "train loss:0.0045919788328559735\n",
      "train loss:0.011630067785342984\n",
      "train loss:0.00734306828232937\n",
      "train loss:0.028768171896031022\n",
      "train loss:0.02080467631529471\n",
      "train loss:0.023837744946719176\n",
      "train loss:0.014107039420698252\n",
      "train loss:0.007406126582445612\n",
      "train loss:0.004780914944074772\n",
      "train loss:0.017053033994207868\n",
      "train loss:0.004179459067313726\n",
      "train loss:0.00937639492092908\n",
      "train loss:0.018178045996199595\n",
      "train loss:0.03437128249675279\n",
      "train loss:0.009307648448484019\n",
      "train loss:0.013077159134015073\n",
      "train loss:0.010279862264575824\n",
      "train loss:0.004763212762704857\n",
      "train loss:0.01073454664900939\n",
      "train loss:0.12493419983902668\n",
      "train loss:0.08662812302431105\n",
      "train loss:0.005736333234631342\n",
      "train loss:0.004700585290888607\n",
      "train loss:0.004069032104716702\n",
      "train loss:0.12471953304180947\n",
      "train loss:0.026326096867385466\n",
      "train loss:0.04141239857259112\n",
      "train loss:0.03049026368867451\n",
      "train loss:0.013726830822070445\n",
      "train loss:0.017847605256747175\n",
      "train loss:0.005716168874211646\n",
      "train loss:0.02348158080983346\n",
      "train loss:0.009685432283664072\n",
      "train loss:0.011423578453370681\n",
      "train loss:0.05821012392612383\n",
      "train loss:0.026423133936160234\n",
      "train loss:0.005439768102939466\n",
      "train loss:0.016612609784007415\n",
      "train loss:0.00943717611560157\n",
      "train loss:0.010470658036112307\n",
      "train loss:0.0177079451105445\n",
      "train loss:0.008370560313865901\n",
      "train loss:0.021901856202296333\n",
      "train loss:0.0033628599643886798\n",
      "train loss:0.020613141491742298\n",
      "train loss:0.004686126278719151\n",
      "train loss:0.013206966956312426\n",
      "train loss:0.08520468360341661\n",
      "train loss:0.005803729176253114\n",
      "train loss:0.01392420654556969\n",
      "train loss:0.02820386023354108\n",
      "train loss:0.025971004162891952\n",
      "train loss:0.023143853642514305\n",
      "train loss:0.01930720917802453\n",
      "train loss:0.07927121808499775\n",
      "train loss:0.10275317079679736\n",
      "train loss:0.00571587616848397\n",
      "train loss:0.009013567133763938\n",
      "train loss:0.0033259647746042022\n",
      "train loss:0.008951345019586087\n",
      "train loss:0.007928956512690221\n",
      "train loss:0.009063726479188721\n",
      "train loss:0.014454311800367816\n",
      "train loss:0.006236354634457245\n",
      "train loss:0.0180327851556025\n",
      "train loss:0.008857241742084156\n",
      "train loss:0.03369093505146881\n",
      "train loss:0.0082407369881817\n",
      "train loss:0.04184501352746895\n",
      "train loss:0.015993971391439238\n",
      "train loss:0.003942066879218541\n",
      "train loss:0.015595465292028814\n",
      "train loss:0.027591685791179356\n",
      "train loss:0.01373183191444097\n",
      "train loss:0.03333411590936958\n",
      "train loss:0.0064777987405593125\n",
      "train loss:0.015152721276127568\n",
      "train loss:0.013884307333013659\n",
      "train loss:0.01313722274640622\n",
      "train loss:0.0065827029909291635\n",
      "train loss:0.015130099482887339\n",
      "train loss:0.030576060507669495\n",
      "train loss:0.024042445041186033\n",
      "train loss:0.06005135359450198\n",
      "train loss:0.05320523953125075\n",
      "train loss:0.009654272855093054\n",
      "train loss:0.005756211474381823\n",
      "train loss:0.020299087654616136\n",
      "train loss:0.00804186625191429\n",
      "train loss:0.020533631519055833\n",
      "train loss:0.020965875394095716\n",
      "train loss:0.010439038402221077\n",
      "train loss:0.003759711424238943\n",
      "train loss:0.004196233070203406\n",
      "train loss:0.019479772265302068\n",
      "train loss:0.02219403285695562\n",
      "train loss:0.014725077622003604\n",
      "train loss:0.00728806678780174\n",
      "train loss:0.001616374567782231\n",
      "train loss:0.031728186293929046\n",
      "train loss:0.026157725777509057\n",
      "train loss:0.014162371996684782\n",
      "train loss:0.01821292075583609\n",
      "train loss:0.018821254927037383\n",
      "train loss:0.015487694496839555\n",
      "train loss:0.008125172931838539\n",
      "train loss:0.008510864138609119\n",
      "train loss:0.07214319915879988\n",
      "train loss:0.009920988356790023\n",
      "train loss:0.0059226669664762446\n",
      "train loss:0.015595268853054916\n",
      "train loss:0.012330996822523352\n",
      "train loss:0.01686592927808785\n",
      "train loss:0.005525489119448591\n",
      "train loss:0.020122736910928706\n",
      "train loss:0.00827714256340705\n",
      "train loss:0.009629100172055996\n",
      "train loss:0.010251346501967467\n",
      "train loss:0.00688279438914806\n",
      "train loss:0.011137911241745043\n",
      "train loss:0.0049666749750260945\n",
      "train loss:0.01083230110161598\n",
      "train loss:0.0046068737078624735\n",
      "train loss:0.018004360114641974\n",
      "train loss:0.01984292329974298\n",
      "train loss:0.003944044483428653\n",
      "train loss:0.008742166575336887\n",
      "train loss:0.014973810414467981\n",
      "train loss:0.033092228385066175\n",
      "train loss:0.03210647688673704\n",
      "train loss:0.012606437977771556\n",
      "train loss:0.008503671717243767\n",
      "train loss:0.011289487839276318\n",
      "train loss:0.005020467107746237\n",
      "train loss:0.005371090500296711\n",
      "train loss:0.025112761138703456\n",
      "train loss:0.018547224700163102\n",
      "train loss:0.006378631652025472\n",
      "train loss:0.003824387932340994\n",
      "train loss:0.014653400749442904\n",
      "train loss:0.013663977513459036\n",
      "train loss:0.05635501249375114\n",
      "train loss:0.00930402763835596\n",
      "train loss:0.009817729120395581\n",
      "train loss:0.11608510425569436\n",
      "train loss:0.02242801420698456\n",
      "train loss:0.039226363713714754\n",
      "train loss:0.05253735855285227\n",
      "train loss:0.013167205884056088\n",
      "train loss:0.05442051831108422\n",
      "train loss:0.023591641588990728\n",
      "train loss:0.009526425818274004\n",
      "train loss:0.0058722775570147325\n",
      "train loss:0.031653237297494044\n",
      "train loss:0.003064680565096521\n",
      "train loss:0.006137148183420578\n",
      "train loss:0.09156220049279284\n",
      "train loss:0.0070929160772538\n",
      "train loss:0.02590967933085685\n",
      "train loss:0.019348665555792437\n",
      "train loss:0.0048225669985451115\n",
      "train loss:0.019183682766395496\n",
      "train loss:0.020142899527752774\n",
      "train loss:0.018357547739086124\n",
      "train loss:0.003228971744930453\n",
      "train loss:0.006545178270132603\n",
      "train loss:0.014316472043851938\n",
      "train loss:0.0017493878807362318\n",
      "train loss:0.0034296684518868702\n",
      "train loss:0.09467204545087346\n",
      "train loss:0.012199715307222685\n",
      "train loss:0.0027770918178101054\n",
      "train loss:0.016368930490852397\n",
      "train loss:0.022648963245974433\n",
      "train loss:0.017227318284585947\n",
      "train loss:0.018030146972226033\n",
      "train loss:0.07681139621446653\n",
      "train loss:0.017636105574165655\n",
      "train loss:0.0124279502547753\n",
      "train loss:0.05339272524594664\n",
      "train loss:0.03320840243481473\n",
      "train loss:0.026738445286906068\n",
      "train loss:0.008917975448785228\n",
      "train loss:0.055107079080678585\n",
      "train loss:0.006435656816007037\n",
      "train loss:0.012075985662770183\n",
      "train loss:0.012509468463947156\n",
      "train loss:0.016513442542242147\n",
      "train loss:0.09066836200036615\n",
      "train loss:0.011964056771372125\n",
      "train loss:0.03704982963092895\n",
      "train loss:0.006603879363710127\n",
      "train loss:0.011433187085290508\n",
      "train loss:0.010341247068662168\n",
      "train loss:0.0028912914385746074\n",
      "train loss:0.0174308848823882\n",
      "train loss:0.006646492906958557\n",
      "train loss:0.019400637098349393\n",
      "train loss:0.008037356367531013\n",
      "train loss:0.004251700856669611\n",
      "train loss:0.010587956161702428\n",
      "train loss:0.003778909026927219\n",
      "train loss:0.02793242884599088\n",
      "train loss:0.0025519791554649064\n",
      "train loss:0.007899208418270692\n",
      "train loss:0.010271114474140374\n",
      "train loss:0.014862393532350176\n",
      "train loss:0.03601813827220289\n",
      "train loss:0.008954554502368085\n",
      "train loss:0.006735202980863792\n",
      "train loss:0.0030334888666219166\n",
      "train loss:0.029700243938942644\n",
      "train loss:0.010665734780276675\n",
      "train loss:0.021699028278446098\n",
      "train loss:0.028434423239391812\n",
      "train loss:0.01308590720474311\n",
      "train loss:0.009707563191550823\n",
      "train loss:0.024512165238811244\n",
      "train loss:0.030229981440413764\n",
      "train loss:0.012285148252797926\n",
      "train loss:0.018475181879318507\n",
      "train loss:0.01993012543893602\n",
      "train loss:0.01395615195146299\n",
      "train loss:0.011407872001778108\n",
      "train loss:0.026761775415575357\n",
      "train loss:0.06587971226919218\n",
      "train loss:0.008898490024106913\n",
      "train loss:0.005373117424460139\n",
      "train loss:0.004974470881560687\n",
      "train loss:0.0030515308016011928\n",
      "train loss:0.047499980806755965\n",
      "train loss:0.002889624461064335\n",
      "train loss:0.02136238379671963\n",
      "train loss:0.014063464945851988\n",
      "train loss:0.006617269878896828\n",
      "train loss:0.04695868683705972\n",
      "train loss:0.001798767433768875\n",
      "train loss:0.004152427690138413\n",
      "train loss:0.019883833477440983\n",
      "train loss:0.06470546068594779\n",
      "train loss:0.002421861916917521\n",
      "train loss:0.007004734931921888\n",
      "train loss:0.02594849546936676\n",
      "train loss:0.02831920207399725\n",
      "train loss:0.007308531345155158\n",
      "train loss:0.0031896484350302217\n",
      "train loss:0.005630352066602682\n",
      "train loss:0.010405240942610134\n",
      "train loss:0.07941649528350997\n",
      "train loss:0.011350481561941763\n",
      "train loss:0.0070330013736774\n",
      "train loss:0.0034509234686967666\n",
      "train loss:0.009325169026383787\n",
      "train loss:0.01647165664024411\n",
      "train loss:0.015964639405036438\n",
      "train loss:0.028689696595555016\n",
      "train loss:0.005328785022576188\n",
      "train loss:0.023017281806854598\n",
      "train loss:0.021872181625306273\n",
      "train loss:0.017735769958786087\n",
      "train loss:0.025919204471761898\n",
      "train loss:0.01749496207418507\n",
      "train loss:0.0255267507129764\n",
      "train loss:0.016691085146743553\n",
      "train loss:0.00973379013041592\n",
      "train loss:0.009009882105750875\n",
      "train loss:0.008411953701025522\n",
      "train loss:0.004945214209961684\n",
      "train loss:0.025382707743328323\n",
      "train loss:0.020336863560570673\n",
      "train loss:0.002869179858439618\n",
      "train loss:0.012172118799592962\n",
      "train loss:0.014131313051623202\n",
      "train loss:0.016607250348232124\n",
      "train loss:0.02554795044136046\n",
      "train loss:0.00887734304139597\n",
      "train loss:0.046304152772176865\n",
      "train loss:0.009556871560640919\n",
      "train loss:0.0049183264028278524\n",
      "train loss:0.037336997677919946\n",
      "train loss:0.05819908204168601\n",
      "train loss:0.029420739054515047\n",
      "train loss:0.009504640194135933\n",
      "train loss:0.02274774465314289\n",
      "train loss:0.04266228419271639\n",
      "train loss:0.02435970257615154\n",
      "train loss:0.017841228553407685\n",
      "train loss:0.009831222198400602\n",
      "train loss:0.06921840913609188\n",
      "train loss:0.005053567599325177\n",
      "train loss:0.03237887357709283\n",
      "train loss:0.011083789623866504\n",
      "train loss:0.0129768753451037\n",
      "train loss:0.0239453834848618\n",
      "train loss:0.02500447545845426\n",
      "train loss:0.009455212319680472\n",
      "train loss:0.12078476788408735\n",
      "train loss:0.0007789242693347784\n",
      "train loss:0.0024803576117690415\n",
      "train loss:0.01804721633499997\n",
      "train loss:0.004784191498539602\n",
      "train loss:0.029455332878058883\n",
      "train loss:0.01144399288442083\n",
      "train loss:0.011606413844485798\n",
      "train loss:0.00895393991650477\n",
      "train loss:0.0060952943441501825\n",
      "train loss:0.008683156212851316\n",
      "train loss:0.010481709995808988\n",
      "train loss:0.05242468116165799\n",
      "train loss:0.01350558943640649\n",
      "train loss:0.00927588086137764\n",
      "train loss:0.010981400926956096\n",
      "train loss:0.008649370561950814\n",
      "train loss:0.019738418359707036\n",
      "=== epoch:8, train acc:0.991, test acc:0.983 ===\n",
      "train loss:0.17972828459289872\n",
      "train loss:0.017799156884527722\n",
      "train loss:0.03658970138170912\n",
      "train loss:0.0014616779884980776\n",
      "train loss:0.003689269695625421\n",
      "train loss:0.0022331573778459003\n",
      "train loss:0.023224129522318976\n",
      "train loss:0.0037162544398478986\n",
      "train loss:0.0025378919546285273\n",
      "train loss:0.006388245233593226\n",
      "train loss:0.004585846289830683\n",
      "train loss:0.00443596829191949\n",
      "train loss:0.009089110120619717\n",
      "train loss:0.017761946164694162\n",
      "train loss:0.016288729690804665\n",
      "train loss:0.035994543303407095\n",
      "train loss:0.010856756373808962\n",
      "train loss:0.022974069472303786\n",
      "train loss:0.0044099324881010276\n",
      "train loss:0.01286905973686292\n",
      "train loss:0.007945800790678583\n",
      "train loss:0.012620923711416382\n",
      "train loss:0.026751795859628086\n",
      "train loss:0.033095501840363445\n",
      "train loss:0.06237818661309451\n",
      "train loss:0.00827326260333774\n",
      "train loss:0.05417079252711814\n",
      "train loss:0.09952235896192084\n",
      "train loss:0.022842137306847598\n",
      "train loss:0.004782127040686458\n",
      "train loss:0.0572418565694443\n",
      "train loss:0.005196224669215467\n",
      "train loss:0.020171781363124523\n",
      "train loss:0.006757783071549838\n",
      "train loss:0.027067698831937846\n",
      "train loss:0.05083625454683313\n",
      "train loss:0.025350601286421123\n",
      "train loss:0.008586684200739925\n",
      "train loss:0.008601915047482356\n",
      "train loss:0.005552318880225352\n",
      "train loss:0.006909100032178108\n",
      "train loss:0.026603365204206742\n",
      "train loss:0.004395799174764325\n",
      "train loss:0.01007780486722835\n",
      "train loss:0.028828591216715424\n",
      "train loss:0.022879162943996164\n",
      "train loss:0.007211525620701039\n",
      "train loss:0.023167615144699307\n",
      "train loss:0.014754028195079967\n",
      "train loss:0.007980992981228972\n",
      "train loss:0.011819782982799098\n",
      "train loss:0.018886576646875427\n",
      "train loss:0.014076638925527843\n",
      "train loss:0.008245356443204361\n",
      "train loss:0.008870940666604692\n",
      "train loss:0.012943234515037762\n",
      "train loss:0.0036362159836094226\n",
      "train loss:0.014943119376883201\n",
      "train loss:0.04553861802842822\n",
      "train loss:0.014637109485934547\n",
      "train loss:0.004960355031012839\n",
      "train loss:0.013898235557982929\n",
      "train loss:0.007441382053466864\n",
      "train loss:0.01652127721782306\n",
      "train loss:0.10266394930948093\n",
      "train loss:0.016742333896341083\n",
      "train loss:0.007808813119684533\n",
      "train loss:0.017607729580701795\n",
      "train loss:0.022996085467902567\n",
      "train loss:0.0016879717481145503\n",
      "train loss:0.11289120306439138\n",
      "train loss:0.003186617660368402\n",
      "train loss:0.00975313324576395\n",
      "train loss:0.0037483159232380636\n",
      "train loss:0.015626824037219666\n",
      "train loss:0.0013810330371198409\n",
      "train loss:0.011106944098443046\n",
      "train loss:0.018565380467576133\n",
      "train loss:0.004031867805507622\n",
      "train loss:0.019280419127593516\n",
      "train loss:0.006886180484722307\n",
      "train loss:0.004245804819503289\n",
      "train loss:0.02317140595589722\n",
      "train loss:0.02369242608381549\n",
      "train loss:0.03306492392866703\n",
      "train loss:0.0353728881530849\n",
      "train loss:0.003677817344943594\n",
      "train loss:0.028101664381070132\n",
      "train loss:0.0036246424791888878\n",
      "train loss:0.013427248361962216\n",
      "train loss:0.01261003797419989\n",
      "train loss:0.004786591270661627\n",
      "train loss:0.024456702145349375\n",
      "train loss:0.03013943274607469\n",
      "train loss:0.00789860302417212\n",
      "train loss:0.0318237593032916\n",
      "train loss:0.018190168520163363\n",
      "train loss:0.01103076473970159\n",
      "train loss:0.011474212897282607\n",
      "train loss:0.004864794749858048\n",
      "train loss:0.0179716268427097\n",
      "train loss:0.01747602966198619\n",
      "train loss:0.03391014123236341\n",
      "train loss:0.007689065449628193\n",
      "train loss:0.012376040726057302\n",
      "train loss:0.02557750962797117\n",
      "train loss:0.03205806173372996\n",
      "train loss:0.03675476235202593\n",
      "train loss:0.01578023257000958\n",
      "train loss:0.010291827276800648\n",
      "train loss:0.020430633072721846\n",
      "train loss:0.010391590706477277\n",
      "train loss:0.08757226574446271\n",
      "train loss:0.039902915715383284\n",
      "train loss:0.014639671812614607\n",
      "train loss:0.005723896676063489\n",
      "train loss:0.00295828257821321\n",
      "train loss:0.005185184650357456\n",
      "train loss:0.015754713603929816\n",
      "train loss:0.011399121324592199\n",
      "train loss:0.023189706171442406\n",
      "train loss:0.007269526999494397\n",
      "train loss:0.01931552893797916\n",
      "train loss:0.009965991509301811\n",
      "train loss:0.03185750428408621\n",
      "train loss:0.005857853645648522\n",
      "train loss:0.012513904976407773\n",
      "train loss:0.014985246808457597\n",
      "train loss:0.003338322436220211\n",
      "train loss:0.009239040370816113\n",
      "train loss:0.01536767968411976\n",
      "train loss:0.017027544105821017\n",
      "train loss:0.020821751885938652\n",
      "train loss:0.008632110981133508\n",
      "train loss:0.007957186301320278\n",
      "train loss:0.05029687735819068\n",
      "train loss:0.006969746269004257\n",
      "train loss:0.004591271927530875\n",
      "train loss:0.01326682636742132\n",
      "train loss:0.03802355122561612\n",
      "train loss:0.014025911866897816\n",
      "train loss:0.0049442194186888\n",
      "train loss:0.009163476147673015\n",
      "train loss:0.010765051813911282\n",
      "train loss:0.012402770531217713\n",
      "train loss:0.0040186100717114455\n",
      "train loss:0.018384211494926733\n",
      "train loss:0.009875402090883015\n",
      "train loss:0.012843270826585212\n",
      "train loss:0.011711851836085056\n",
      "train loss:0.012174348547170439\n",
      "train loss:0.012664436101427767\n",
      "train loss:0.003797769652703486\n",
      "train loss:0.0025996661025892696\n",
      "train loss:0.0034438522338253725\n",
      "train loss:0.007518418395040404\n",
      "train loss:0.0015685694300642827\n",
      "train loss:0.006852359154176545\n",
      "train loss:0.007542250500234915\n",
      "train loss:0.015161628329005972\n",
      "train loss:0.007286905004164997\n",
      "train loss:0.014488020070697502\n",
      "train loss:0.03781665968846311\n",
      "train loss:0.008732535726618088\n",
      "train loss:0.035662417643835646\n",
      "train loss:0.004768340427162743\n",
      "train loss:0.015773114460286893\n",
      "train loss:0.004106331176076562\n",
      "train loss:0.015616971695322637\n",
      "train loss:0.009776271650756356\n",
      "train loss:0.005926602916128689\n",
      "train loss:0.008447236469343\n",
      "train loss:0.005321713507415366\n",
      "train loss:0.016681895358446604\n",
      "train loss:0.006456151692642621\n",
      "train loss:0.008585331523576677\n",
      "train loss:0.004772174469107329\n",
      "train loss:0.008737079803335691\n",
      "train loss:0.00970995514468126\n",
      "train loss:0.013073916995536354\n",
      "train loss:0.008759349810415316\n",
      "train loss:0.03990956839081685\n",
      "train loss:0.0069812041576040726\n",
      "train loss:0.01018157676699184\n",
      "train loss:0.0029516547385545528\n",
      "train loss:0.0026920408404443553\n",
      "train loss:0.002213086351494883\n",
      "train loss:0.010545631500980885\n",
      "train loss:0.006547046520829088\n",
      "train loss:0.04453883757590783\n",
      "train loss:0.0015651190910552096\n",
      "train loss:0.0021591175393151445\n",
      "train loss:0.006887093505379875\n",
      "train loss:0.010250644476334654\n",
      "train loss:0.001722439472105583\n",
      "train loss:0.017936082063216566\n",
      "train loss:0.00862372865420609\n",
      "train loss:0.041013979008739564\n",
      "train loss:0.0036245621606780833\n",
      "train loss:0.003270977852939535\n",
      "train loss:0.03166678753332157\n",
      "train loss:0.018721503627148854\n",
      "train loss:0.017569702835871562\n",
      "train loss:0.003013869240757434\n",
      "train loss:0.002829126726077035\n",
      "train loss:0.02208715913570757\n",
      "train loss:0.008892461157132698\n",
      "train loss:0.009967964830345897\n",
      "train loss:0.028010274439619235\n",
      "train loss:0.03180184408103056\n",
      "train loss:0.026186709527025568\n",
      "train loss:0.006673530359744935\n",
      "train loss:0.020414262477655862\n",
      "train loss:0.004728346775972535\n",
      "train loss:0.018067245396735952\n",
      "train loss:0.0024430172514720676\n",
      "train loss:0.008433120328894171\n",
      "train loss:0.004873030469352057\n",
      "train loss:0.004354441837405335\n",
      "train loss:0.015880172290991187\n",
      "train loss:0.03812008335085617\n",
      "train loss:0.0028992298256580963\n",
      "train loss:0.002026138118900162\n",
      "train loss:0.01605617614262618\n",
      "train loss:0.009903917069650974\n",
      "train loss:0.010536967232873042\n",
      "train loss:0.010960177065643513\n",
      "train loss:0.017882981174361875\n",
      "train loss:0.003167434141073521\n",
      "train loss:0.005070863040798942\n",
      "train loss:0.005253069130347101\n",
      "train loss:0.0068467217681097495\n",
      "train loss:0.008308180545296036\n",
      "train loss:0.016401430427487165\n",
      "train loss:0.010573686623056992\n",
      "train loss:0.006739590101327798\n",
      "train loss:0.004189373915080061\n",
      "train loss:0.004160831852383687\n",
      "train loss:0.0536038320057697\n",
      "train loss:0.0028697690204810295\n",
      "train loss:0.024122813805369306\n",
      "train loss:0.005311084922587503\n",
      "train loss:0.0016920115435568423\n",
      "train loss:0.008918205495320578\n",
      "train loss:0.029313587379494455\n",
      "train loss:0.03787140568379559\n",
      "train loss:0.003918339740193861\n",
      "train loss:0.008782804831425052\n",
      "train loss:0.008741341271076545\n",
      "train loss:0.014013161444589483\n",
      "train loss:0.004315212699561399\n",
      "train loss:0.016373435302764555\n",
      "train loss:0.006683032553190113\n",
      "train loss:0.010904585123366884\n",
      "train loss:0.006827781500525348\n",
      "train loss:0.02996564394994111\n",
      "train loss:0.015870906709110965\n",
      "train loss:0.011473617394232296\n",
      "train loss:0.004062477490854971\n",
      "train loss:0.040463977116587696\n",
      "train loss:0.011622052797430192\n",
      "train loss:0.023135205413710773\n",
      "train loss:0.0029285444315361644\n",
      "train loss:0.01284403956195222\n",
      "train loss:0.016227781246816318\n",
      "train loss:0.01898344571922502\n",
      "train loss:0.018213367291326946\n",
      "train loss:0.014682705042958027\n",
      "train loss:0.10178631703888023\n",
      "train loss:0.01289057693433563\n",
      "train loss:0.0066076758711726465\n",
      "train loss:0.02867359766387252\n",
      "train loss:0.03419017880645716\n",
      "train loss:0.030876727246888086\n",
      "train loss:0.0047268775235900255\n",
      "train loss:0.0015394338738026958\n",
      "train loss:0.01439467392281552\n",
      "train loss:0.011273773068147162\n",
      "train loss:0.03279243944469411\n",
      "train loss:0.01647779876889567\n",
      "train loss:0.003994200590993689\n",
      "train loss:0.010258685748517555\n",
      "train loss:0.007719468366273686\n",
      "train loss:0.0051559958878485265\n",
      "train loss:0.0671338072688268\n",
      "train loss:0.008554246702743547\n",
      "train loss:0.07083306782082753\n",
      "train loss:0.0076825725480075616\n",
      "train loss:0.007261586677055096\n",
      "train loss:0.0060347659442115485\n",
      "train loss:0.006252885919453179\n",
      "train loss:0.026114875194892372\n",
      "train loss:0.011748602157300584\n",
      "train loss:0.13627175971951327\n",
      "train loss:0.007498725140088963\n",
      "train loss:0.017247711851865872\n",
      "train loss:0.08838101143358466\n",
      "train loss:0.01249533677571465\n",
      "train loss:0.03559417275294673\n",
      "train loss:0.016699438405186177\n",
      "train loss:0.00973629299682704\n",
      "train loss:0.002122864658626721\n",
      "train loss:0.02591070867555418\n",
      "train loss:0.013548351068565653\n",
      "train loss:0.006846620946988453\n",
      "train loss:0.03431999451838113\n",
      "train loss:0.01744699510553847\n",
      "train loss:0.004908044056462874\n",
      "train loss:0.0254159287839887\n",
      "train loss:0.006289074379561538\n",
      "train loss:0.008638937435892988\n",
      "train loss:0.006929704797204224\n",
      "train loss:0.00935872108326634\n",
      "train loss:0.019707514501600965\n",
      "train loss:0.03383773336820767\n",
      "train loss:0.009678103300457298\n",
      "train loss:0.00735682255647633\n",
      "train loss:0.002894109691396495\n",
      "train loss:0.03441760887952785\n",
      "train loss:0.012929101027580124\n",
      "train loss:0.010330287091167418\n",
      "train loss:0.024019371397441383\n",
      "train loss:0.006486188461786502\n",
      "train loss:0.007911297753087326\n",
      "train loss:0.007068434076887295\n",
      "train loss:0.14430386444814214\n",
      "train loss:0.007255341848438215\n",
      "train loss:0.009667111046197727\n",
      "train loss:0.020445630065686723\n",
      "train loss:0.002443322366555171\n",
      "train loss:0.007097950733268224\n",
      "train loss:0.006683534064844129\n",
      "train loss:0.0065943983800840445\n",
      "train loss:0.004150702762514764\n",
      "train loss:0.021159696641473734\n",
      "train loss:0.0113022551734861\n",
      "train loss:0.008543493792998515\n",
      "train loss:0.024383805925605344\n",
      "train loss:0.02734748998316107\n",
      "train loss:0.018618442361817734\n",
      "train loss:0.006725434338521865\n",
      "train loss:0.003720650118822735\n",
      "train loss:0.014129761328468668\n",
      "train loss:0.0075910761363640064\n",
      "train loss:0.0013933323942099806\n",
      "train loss:0.006129798490580495\n",
      "train loss:0.0037613235190653987\n",
      "train loss:0.019165955817057205\n",
      "train loss:0.013190566719294895\n",
      "train loss:0.0036138936093766056\n",
      "train loss:0.010430829125326706\n",
      "train loss:0.06526107036399593\n",
      "train loss:0.012039429850479136\n",
      "train loss:0.018534633964342694\n",
      "train loss:0.03895460087896903\n",
      "train loss:0.01761377402660994\n",
      "train loss:0.034621581273545594\n",
      "train loss:0.003430188637323385\n",
      "train loss:0.04329134509930637\n",
      "train loss:0.006060705896822211\n",
      "train loss:0.00622139239848141\n",
      "train loss:0.027801832112286536\n",
      "train loss:0.004021442090008955\n",
      "train loss:0.017845433307779553\n",
      "train loss:0.007439844731252765\n",
      "train loss:0.08262799116399357\n",
      "train loss:0.008536451919870128\n",
      "train loss:0.007617887863170046\n",
      "train loss:0.01297669573598511\n",
      "train loss:0.013642635322154668\n",
      "train loss:0.0046060123991812345\n",
      "train loss:0.010684283208394683\n",
      "train loss:0.005776363324768646\n",
      "train loss:0.005663282829910754\n",
      "train loss:0.11008761136340312\n",
      "train loss:0.013355275341486261\n",
      "train loss:0.004417527275145364\n",
      "train loss:0.015642812787709584\n",
      "train loss:0.018042094194381283\n",
      "train loss:0.06065774834502035\n",
      "train loss:0.015426588685518437\n",
      "train loss:0.01280358419796969\n",
      "train loss:0.025204308780698462\n",
      "train loss:0.01399992229120131\n",
      "train loss:0.010034530362826805\n",
      "train loss:0.005202033946888079\n",
      "train loss:0.021864017362748806\n",
      "train loss:0.005634421065530134\n",
      "train loss:0.006976796082752829\n",
      "train loss:0.011522348796979618\n",
      "train loss:0.003366493265967161\n",
      "train loss:0.009361831907799484\n",
      "train loss:0.012960138176460929\n",
      "train loss:0.005892237900233794\n",
      "train loss:0.005878482525537708\n",
      "train loss:0.029789714978255655\n",
      "train loss:0.048059567546116025\n",
      "train loss:0.022725930352447583\n",
      "train loss:0.014234237320992096\n",
      "train loss:0.005641062549487836\n",
      "train loss:0.002531869079539563\n",
      "train loss:0.004081051807358732\n",
      "train loss:0.013618001501659255\n",
      "train loss:0.057797330918603444\n",
      "train loss:0.013833908176200983\n",
      "train loss:0.004215922856625134\n",
      "train loss:0.024321608451665137\n",
      "train loss:0.010099445087862863\n",
      "train loss:0.002592057484452921\n",
      "train loss:0.008889972649450793\n",
      "train loss:0.0015533192091544792\n",
      "train loss:0.003965847379970731\n",
      "train loss:0.04695134607494103\n",
      "train loss:0.024887131147813792\n",
      "train loss:0.008315947914032857\n",
      "train loss:0.022673793836105762\n",
      "train loss:0.04436567299471074\n",
      "train loss:0.053715129514819215\n",
      "train loss:0.01660608762320274\n",
      "train loss:0.01712305453962092\n",
      "train loss:0.01725713036926919\n",
      "train loss:0.1073827738542228\n",
      "train loss:0.01856303001227515\n",
      "train loss:0.02520650995753299\n",
      "train loss:0.02108807390456886\n",
      "train loss:0.01660463972461641\n",
      "train loss:0.0055018943394899026\n",
      "train loss:0.012289268705481334\n",
      "train loss:0.010025049218109433\n",
      "train loss:0.013897772748186998\n",
      "train loss:0.030719883563422857\n",
      "train loss:0.006665884463516542\n",
      "train loss:0.10895728837709567\n",
      "train loss:0.024832471526974938\n",
      "train loss:0.010793092808815286\n",
      "train loss:0.010389104500761071\n",
      "train loss:0.007207754580273062\n",
      "train loss:0.008014263852349317\n",
      "train loss:0.00477261342404825\n",
      "train loss:0.029387394998513033\n",
      "train loss:0.00974938030396994\n",
      "train loss:0.009078668114962808\n",
      "train loss:0.016211028156501904\n",
      "train loss:0.047703601087626085\n",
      "train loss:0.022837495780418694\n",
      "train loss:0.005496476782087771\n",
      "train loss:0.017517432781920958\n",
      "train loss:0.00890024593032606\n",
      "train loss:0.017689602115504438\n",
      "train loss:0.006997220338738003\n",
      "train loss:0.0021939809014672445\n",
      "train loss:0.010876484573917733\n",
      "train loss:0.01292585143550682\n",
      "train loss:0.018848254288988685\n",
      "train loss:0.05042377342973456\n",
      "train loss:0.14955709490849808\n",
      "train loss:0.00401811932788498\n",
      "train loss:0.008281220133052332\n",
      "train loss:0.006566519577878028\n",
      "train loss:0.00972917224849647\n",
      "train loss:0.013854245416420618\n",
      "train loss:0.012536942290279423\n",
      "train loss:0.018208772803059922\n",
      "train loss:0.0021288964679503585\n",
      "train loss:0.02980712937628712\n",
      "train loss:0.009724457973942495\n",
      "train loss:0.0037032866267631753\n",
      "train loss:0.005356043895334105\n",
      "train loss:0.00892612658448366\n",
      "train loss:0.021331374025594364\n",
      "train loss:0.010835258141647063\n",
      "train loss:0.0070993850235480304\n",
      "train loss:0.006962561308963595\n",
      "train loss:0.016645657924423005\n",
      "train loss:0.007682450048213888\n",
      "train loss:0.040815251474212236\n",
      "train loss:0.01615567804820649\n",
      "train loss:0.021308395078478724\n",
      "train loss:0.03998033185414156\n",
      "train loss:0.0074844862177985945\n",
      "train loss:0.020671169673535945\n",
      "train loss:0.006931012297460234\n",
      "train loss:0.05335479728019634\n",
      "train loss:0.005451926250432576\n",
      "train loss:0.0021467348004332444\n",
      "train loss:0.02071846440850825\n",
      "train loss:0.004994677238870511\n",
      "train loss:0.0047658023096102085\n",
      "train loss:0.0012482210533547717\n",
      "train loss:0.03857100972751666\n",
      "train loss:0.011720490763458746\n",
      "train loss:0.012741839732042147\n",
      "train loss:0.008065012760859545\n",
      "train loss:0.0026309561473915623\n",
      "train loss:0.014662654460361966\n",
      "train loss:0.002547059732177177\n",
      "train loss:0.0037825863140054654\n",
      "train loss:0.00602403101175208\n",
      "train loss:0.04407232253015409\n",
      "train loss:0.002008285030502572\n",
      "train loss:0.026884173256866983\n",
      "train loss:0.011384214430580646\n",
      "train loss:0.02720858795362295\n",
      "train loss:0.023464550711349473\n",
      "train loss:0.0193278082537453\n",
      "train loss:0.002031562439232211\n",
      "train loss:0.008541852531534423\n",
      "train loss:0.0028585940009438447\n",
      "train loss:0.009625206844654873\n",
      "train loss:0.002818716346462193\n",
      "train loss:0.00528172873437064\n",
      "train loss:0.003951648710253161\n",
      "train loss:0.0034842262651350636\n",
      "train loss:0.023028981732328327\n",
      "train loss:0.004211612597523837\n",
      "train loss:0.01773063753946337\n",
      "train loss:0.011834519086278998\n",
      "train loss:0.05649222073947549\n",
      "train loss:0.01350192291816208\n",
      "train loss:0.01466334661056696\n",
      "train loss:0.013462098102081797\n",
      "train loss:0.005868593121734726\n",
      "train loss:0.008729979911276725\n",
      "train loss:0.006765346997715563\n",
      "train loss:0.018024771535117484\n",
      "train loss:0.005602184500879961\n",
      "train loss:0.005462559254080311\n",
      "train loss:0.009397387086201109\n",
      "train loss:0.03698021424452234\n",
      "train loss:0.003017320995760988\n",
      "train loss:0.011430831635050105\n",
      "train loss:0.0028888066681521875\n",
      "train loss:0.006450943605313523\n",
      "train loss:0.04375210502800005\n",
      "train loss:0.0036944664163742723\n",
      "train loss:0.0062464131027189385\n",
      "train loss:0.0036826370669441537\n",
      "train loss:0.004198347304404774\n",
      "train loss:0.0002915512033653892\n",
      "train loss:0.005233206532795393\n",
      "train loss:0.008075288384809347\n",
      "train loss:0.02090856130982601\n",
      "train loss:0.009124886297689984\n",
      "train loss:0.020964406317130924\n",
      "train loss:0.02196513301504396\n",
      "train loss:0.006096126578322101\n",
      "train loss:0.005373163241027158\n",
      "train loss:0.006411716928708855\n",
      "train loss:0.0042622687252392485\n",
      "train loss:0.007170349816667052\n",
      "train loss:0.003331423721974435\n",
      "train loss:0.019386360513395894\n",
      "train loss:0.0064606261292427325\n",
      "train loss:0.006468155301303128\n",
      "train loss:0.009885234416344533\n",
      "train loss:0.00240048151120452\n",
      "train loss:0.008303779547234656\n",
      "train loss:0.008173710095959113\n",
      "train loss:0.008291138878008393\n",
      "train loss:0.005547591242608092\n",
      "train loss:0.0009380388300320558\n",
      "train loss:0.0029745476974203087\n",
      "train loss:0.002002702533684605\n",
      "train loss:0.0015474172775396206\n",
      "train loss:0.024314604914528474\n",
      "train loss:0.006454994260501397\n",
      "train loss:0.029738099514886273\n",
      "train loss:0.017376030706881148\n",
      "train loss:0.010301679549004674\n",
      "train loss:0.0036901071322140103\n",
      "train loss:0.018721432896082576\n",
      "train loss:0.010882894336093393\n",
      "train loss:0.0013637247248617674\n",
      "train loss:0.012609848130480866\n",
      "train loss:0.001652417097661566\n",
      "train loss:0.015881215404840446\n",
      "train loss:0.012930732515852186\n",
      "train loss:0.017437766569851566\n",
      "train loss:0.01541276964129857\n",
      "train loss:0.005492050335197878\n",
      "train loss:0.0008571181043537543\n",
      "train loss:0.006597708573086019\n",
      "train loss:0.005933156519358603\n",
      "train loss:0.0017810648445387384\n",
      "train loss:0.009093959663094793\n",
      "train loss:0.0035806773549132516\n",
      "train loss:0.014395966549013667\n",
      "train loss:0.011266490196408492\n",
      "train loss:0.0005976309078862309\n",
      "train loss:0.010632049045285079\n",
      "train loss:0.006996458047937476\n",
      "train loss:0.007940283474631665\n",
      "train loss:0.014154097743632427\n",
      "train loss:0.00965099894647354\n",
      "train loss:0.0016568075395765492\n",
      "train loss:0.006729388147798173\n",
      "train loss:0.07898666715538452\n",
      "train loss:0.0012863175662500988\n",
      "train loss:0.007742262604079182\n",
      "train loss:0.0022151911473719667\n",
      "=== epoch:9, train acc:0.993, test acc:0.99 ===\n",
      "train loss:0.003564693288673237\n",
      "train loss:0.021371157862656184\n",
      "train loss:0.0021433903463342345\n",
      "train loss:0.004972718475581522\n",
      "train loss:0.003157070426584232\n",
      "train loss:0.005482313005472822\n",
      "train loss:0.005988780161543924\n",
      "train loss:0.004850193329038026\n",
      "train loss:0.009358696691088705\n",
      "train loss:0.013405105649576293\n",
      "train loss:0.02871206930541692\n",
      "train loss:0.006015432769232961\n",
      "train loss:0.04520226441548278\n",
      "train loss:0.007015053087272179\n",
      "train loss:0.007967070434539853\n",
      "train loss:0.004437106696576391\n",
      "train loss:0.014859367159761019\n",
      "train loss:0.0012844328631243756\n",
      "train loss:0.011999907536352987\n",
      "train loss:0.027674538939681127\n",
      "train loss:0.008446734623736156\n",
      "train loss:0.0036336061342815418\n",
      "train loss:0.024104339432730968\n",
      "train loss:0.0053423529882100414\n",
      "train loss:0.0034704455752521666\n",
      "train loss:0.044209605062004664\n",
      "train loss:0.007241377708769978\n",
      "train loss:0.006146695078708978\n",
      "train loss:0.009827880481717167\n",
      "train loss:0.015200167380044935\n",
      "train loss:0.005693231383616056\n",
      "train loss:0.010232958804628737\n",
      "train loss:0.008999869663734825\n",
      "train loss:0.00037318472135632915\n",
      "train loss:0.02249004875697501\n",
      "train loss:0.015464719282660806\n",
      "train loss:0.006737334060171446\n",
      "train loss:0.07303199202415318\n",
      "train loss:0.002341689728365579\n",
      "train loss:0.00819409279529449\n",
      "train loss:0.024012125272374035\n",
      "train loss:0.01539367892383761\n",
      "train loss:0.007417332278561622\n",
      "train loss:0.006871081116421592\n",
      "train loss:0.021903600521810295\n",
      "train loss:0.0734353951907121\n",
      "train loss:0.0024485154891312256\n",
      "train loss:0.02205235416564376\n",
      "train loss:0.01984565171685206\n",
      "train loss:0.009345869403068167\n",
      "train loss:0.007259304724558859\n",
      "train loss:0.008255019236454055\n",
      "train loss:0.0049599825492683955\n",
      "train loss:0.027705086409044476\n",
      "train loss:0.004883647173463205\n",
      "train loss:0.004327822323498782\n",
      "train loss:0.007525994707969829\n",
      "train loss:0.007750240630098782\n",
      "train loss:0.0037996149786604333\n",
      "train loss:0.061756388014444975\n",
      "train loss:0.013034866110591837\n",
      "train loss:0.005875810710572799\n",
      "train loss:0.007685945513287302\n",
      "train loss:0.03202865191966874\n",
      "train loss:0.008989363293052928\n",
      "train loss:0.007498901917958575\n",
      "train loss:0.027991011903292392\n",
      "train loss:0.006053871386666385\n",
      "train loss:0.02894285530064788\n",
      "train loss:0.006890216263563304\n",
      "train loss:0.04059378204059937\n",
      "train loss:0.021568806599419697\n",
      "train loss:0.007907747224499611\n",
      "train loss:0.021771718566241872\n",
      "train loss:0.004856490643582071\n",
      "train loss:0.0016653576893225694\n",
      "train loss:0.003483732442530458\n",
      "train loss:0.01084886760608834\n",
      "train loss:0.0010852459424151165\n",
      "train loss:0.001139195500040149\n",
      "train loss:0.04294385919397937\n",
      "train loss:0.015497190863879205\n",
      "train loss:0.013529158280432435\n",
      "train loss:0.0017342672449180887\n",
      "train loss:0.00898914640341524\n",
      "train loss:0.03377806084561721\n",
      "train loss:0.000809351730057028\n",
      "train loss:0.014792022263533702\n",
      "train loss:0.006347962165557026\n",
      "train loss:0.019731037251396407\n",
      "train loss:0.004004854649803462\n",
      "train loss:0.019385901618605747\n",
      "train loss:0.004236610869252514\n",
      "train loss:0.003062274053700877\n",
      "train loss:0.019261475175517864\n",
      "train loss:0.003563105859959167\n",
      "train loss:0.09692633588909558\n",
      "train loss:0.019865700777038694\n",
      "train loss:0.010298334699988435\n",
      "train loss:0.022504995505538195\n",
      "train loss:0.007506494483736502\n",
      "train loss:0.002772920958403216\n",
      "train loss:0.0208036619500123\n",
      "train loss:0.006680854977094011\n",
      "train loss:0.006984122943344329\n",
      "train loss:0.011279631037378392\n",
      "train loss:0.004569328205711648\n",
      "train loss:0.006834015701859899\n",
      "train loss:0.013456690203057686\n",
      "train loss:0.05768817686435566\n",
      "train loss:0.009254702389545913\n",
      "train loss:0.04237469444475235\n",
      "train loss:0.0034988657943883133\n",
      "train loss:0.002092232765996143\n",
      "train loss:0.0032998319325382415\n",
      "train loss:0.010203843372899006\n",
      "train loss:0.007902138655628548\n",
      "train loss:0.004343247333515861\n",
      "train loss:0.07544918749045085\n",
      "train loss:0.0032946021615661313\n",
      "train loss:0.04255886692804253\n",
      "train loss:0.010857994737040822\n",
      "train loss:0.009349292989335579\n",
      "train loss:0.010434581631337102\n",
      "train loss:0.004590507024561486\n",
      "train loss:0.027872968195342396\n",
      "train loss:0.008280865067404357\n",
      "train loss:0.03698465504300557\n",
      "train loss:0.03650450460291242\n",
      "train loss:0.053981521534057636\n",
      "train loss:0.025436364694385896\n",
      "train loss:0.0010116431433050631\n",
      "train loss:0.010872686028819618\n",
      "train loss:0.025128607175595872\n",
      "train loss:0.004886489658509028\n",
      "train loss:0.02292977895563878\n",
      "train loss:0.003959805352924005\n",
      "train loss:0.018514680025729934\n",
      "train loss:0.005524941718705378\n",
      "train loss:0.006432195557131954\n",
      "train loss:0.009816316360814875\n",
      "train loss:0.026708886756483353\n",
      "train loss:0.010937748212778526\n",
      "train loss:0.04104628477666439\n",
      "train loss:0.02416912761458678\n",
      "train loss:0.02015370324570418\n",
      "train loss:0.0037512001161528093\n",
      "train loss:0.015917567041272854\n",
      "train loss:0.014098103805486378\n",
      "train loss:0.05744909222924335\n",
      "train loss:0.01825897259900876\n",
      "train loss:0.015088432976305936\n",
      "train loss:0.005712467312631502\n",
      "train loss:0.042648507317747705\n",
      "train loss:0.022108477381094244\n",
      "train loss:0.014091191376868668\n",
      "train loss:0.009300461757345325\n",
      "train loss:0.007521645070672857\n",
      "train loss:0.026437347364068574\n",
      "train loss:0.008895739859770954\n",
      "train loss:0.007076735710872461\n",
      "train loss:0.012317798079258044\n",
      "train loss:0.0018235792052577807\n",
      "train loss:0.002324133231162046\n",
      "train loss:0.002991164338388466\n",
      "train loss:0.012100064264328398\n",
      "train loss:0.0009395345728828716\n",
      "train loss:0.010453318376505705\n",
      "train loss:0.0109479185087503\n",
      "train loss:0.006295218868764901\n",
      "train loss:0.0030788101529960915\n",
      "train loss:0.002309108238968568\n",
      "train loss:0.0003382336163029953\n",
      "train loss:0.005815445879642421\n",
      "train loss:0.006606407078238245\n",
      "train loss:0.0012640550044415594\n",
      "train loss:0.011753271471835221\n",
      "train loss:0.0026683891045030323\n",
      "train loss:0.01084228242502869\n",
      "train loss:0.014770435163737295\n",
      "train loss:0.04920757537963571\n",
      "train loss:0.013102001780550836\n",
      "train loss:0.058598325384792566\n",
      "train loss:0.008857647853274392\n",
      "train loss:0.0021966631132917308\n",
      "train loss:0.015923800705860292\n",
      "train loss:0.01745191134908928\n",
      "train loss:0.008149904479863815\n",
      "train loss:0.0554986876747105\n",
      "train loss:0.007839991747507406\n",
      "train loss:0.021636193729277605\n",
      "train loss:0.015415930859078301\n",
      "train loss:0.0032894074727880685\n",
      "train loss:0.008446726717890344\n",
      "train loss:0.0253294592397184\n",
      "train loss:0.004854416959463565\n",
      "train loss:0.02256615389034903\n",
      "train loss:0.010791963745624255\n",
      "train loss:0.023130184772151653\n",
      "train loss:0.06089600965411715\n",
      "train loss:0.0028263821194835516\n",
      "train loss:0.017430891442965165\n",
      "train loss:0.052412218587229054\n",
      "train loss:0.005181988163083121\n",
      "train loss:0.009305695031252975\n",
      "train loss:0.0038012314314270356\n",
      "train loss:0.005828161491143052\n",
      "train loss:0.016583408485391325\n",
      "train loss:0.007506611308602752\n",
      "train loss:0.006533823146700651\n",
      "train loss:0.006372409370988352\n",
      "train loss:0.03149150542003427\n",
      "train loss:0.0075173939881327005\n",
      "train loss:0.009075310589249952\n",
      "train loss:0.0055796841269174936\n",
      "train loss:0.005556013137391006\n",
      "train loss:0.013041284147686127\n",
      "train loss:0.007248074990995218\n",
      "train loss:0.0034628698762346425\n",
      "train loss:0.09582600478746256\n",
      "train loss:0.0045944979856508104\n",
      "train loss:0.0342353188442481\n",
      "train loss:0.0018594893065719679\n",
      "train loss:0.010366546287779086\n",
      "train loss:0.018357419372628317\n",
      "train loss:0.027007563767938753\n",
      "train loss:0.008850341443510644\n",
      "train loss:0.015671456435916668\n",
      "train loss:0.004129339047467546\n",
      "train loss:0.007737607248888002\n",
      "train loss:0.0038035087728209983\n",
      "train loss:0.003035209051987412\n",
      "train loss:0.008116715487698265\n",
      "train loss:0.012192840535521561\n",
      "train loss:0.015268848762415499\n",
      "train loss:0.013033960833727804\n",
      "train loss:0.0042464658542689555\n",
      "train loss:0.009815065916352306\n",
      "train loss:0.0025746420730855023\n",
      "train loss:0.003972513456005834\n",
      "train loss:0.0037669742562101215\n",
      "train loss:0.01040174157374094\n",
      "train loss:0.005589933122496295\n",
      "train loss:0.002888988897553679\n",
      "train loss:0.003923036464945148\n",
      "train loss:0.012681328194350522\n",
      "train loss:0.018879289147520822\n",
      "train loss:0.009960190570806899\n",
      "train loss:0.008079534554195439\n",
      "train loss:0.004513719334119425\n",
      "train loss:0.004564385808684258\n",
      "train loss:0.010502386314505096\n",
      "train loss:0.016945019282064523\n",
      "train loss:0.0009324481165152504\n",
      "train loss:0.001161374650815058\n",
      "train loss:0.0026833150451499098\n",
      "train loss:0.006636054624093149\n",
      "train loss:0.015232467255030548\n",
      "train loss:0.0014706001504431149\n",
      "train loss:0.002876901428292387\n",
      "train loss:0.004932215519609598\n",
      "train loss:0.01442173747335959\n",
      "train loss:0.006661920039620802\n",
      "train loss:0.026048644960610993\n",
      "train loss:0.006426651615558193\n",
      "train loss:0.004620381975537548\n",
      "train loss:0.00408989719626874\n",
      "train loss:0.0032620884932578\n",
      "train loss:0.014616963917603629\n",
      "train loss:0.0044426375882749385\n",
      "train loss:0.0033424604496231063\n",
      "train loss:0.004569889700513859\n",
      "train loss:0.008616241912050878\n",
      "train loss:0.04362943809673161\n",
      "train loss:0.044031477734324066\n",
      "train loss:0.006944564666152912\n",
      "train loss:0.030841072136926096\n",
      "train loss:0.010625296737937622\n",
      "train loss:0.009542580110330968\n",
      "train loss:0.014087621304352281\n",
      "train loss:0.00925165928958542\n",
      "train loss:0.023846446616754016\n",
      "train loss:0.010803825242145276\n",
      "train loss:0.0030677300966151914\n",
      "train loss:0.002155495411005024\n",
      "train loss:0.00035119508276411864\n",
      "train loss:0.013716797764490491\n",
      "train loss:0.01838706147093584\n",
      "train loss:0.029439512377259884\n",
      "train loss:0.002200248664761057\n",
      "train loss:0.009861002425079934\n",
      "train loss:0.0082332996717084\n",
      "train loss:0.013778256094921686\n",
      "train loss:0.0017761372775617554\n",
      "train loss:0.002752772765190056\n",
      "train loss:0.010202801626467235\n",
      "train loss:0.004791906300403482\n",
      "train loss:0.007067651918876012\n",
      "train loss:0.0014053262291875168\n",
      "train loss:0.0025532346093662906\n",
      "train loss:0.005959052486089157\n",
      "train loss:0.005859692666046215\n",
      "train loss:0.016140791829520912\n",
      "train loss:0.01574005830653775\n",
      "train loss:0.005100098831899882\n",
      "train loss:0.005013534537538618\n",
      "train loss:0.001509592615754725\n",
      "train loss:0.050457629598904076\n",
      "train loss:0.0012428049134279532\n",
      "train loss:0.007024256187256456\n",
      "train loss:0.0204313425836554\n",
      "train loss:0.009712738510685303\n",
      "train loss:0.0037514442048418445\n",
      "train loss:0.0035225204103754714\n",
      "train loss:0.019628545371331477\n",
      "train loss:0.030911036908280037\n",
      "train loss:0.015463355082359728\n",
      "train loss:0.0062228123345383565\n",
      "train loss:0.014019435960804114\n",
      "train loss:0.003581177512052308\n",
      "train loss:0.003969511434263778\n",
      "train loss:0.020774897942246694\n",
      "train loss:0.0036577627399421646\n",
      "train loss:0.008848130473486985\n",
      "train loss:0.002133678613423862\n",
      "train loss:0.002902896489749435\n",
      "train loss:0.007766232224683459\n",
      "train loss:0.012037212119810651\n",
      "train loss:0.011515520453074513\n",
      "train loss:0.0047632072237131055\n",
      "train loss:0.03182406170598862\n",
      "train loss:0.005958874192537218\n",
      "train loss:0.04020134319228083\n",
      "train loss:0.003860297701300338\n",
      "train loss:0.0031579648048571125\n",
      "train loss:0.00198448891412777\n",
      "train loss:0.01468930516065669\n",
      "train loss:0.0023246640157316635\n",
      "train loss:0.006830031129418351\n",
      "train loss:0.006535953252387785\n",
      "train loss:0.0024772674690760428\n",
      "train loss:0.0022054104163635054\n",
      "train loss:0.005273304609766418\n",
      "train loss:0.015644487857092697\n",
      "train loss:0.008955350786894925\n",
      "train loss:0.007350918905678867\n",
      "train loss:0.010742289091631005\n",
      "train loss:0.015149318134278968\n",
      "train loss:0.01939824767949847\n",
      "train loss:0.011624526970178586\n",
      "train loss:0.042239743690020655\n",
      "train loss:0.0033498430263951312\n",
      "train loss:0.054558165953648735\n",
      "train loss:0.005511021550456483\n",
      "train loss:0.005627362270043734\n",
      "train loss:0.017002580314705192\n",
      "train loss:0.030303826523883096\n",
      "train loss:0.014777362787735898\n",
      "train loss:0.007165239918636864\n",
      "train loss:0.007100447009776709\n",
      "train loss:0.0025469147997481817\n",
      "train loss:0.02302454829091869\n",
      "train loss:0.013653651218918537\n",
      "train loss:0.001957314206095793\n",
      "train loss:0.011350230572783919\n",
      "train loss:0.005429000435921614\n",
      "train loss:0.0041373495799532905\n",
      "train loss:0.005331715485340638\n",
      "train loss:0.0019325065104651303\n",
      "train loss:0.014865085140308907\n",
      "train loss:0.001471872586487207\n",
      "train loss:0.09131712787842453\n",
      "train loss:0.0019513495548467519\n",
      "train loss:0.017948967998445812\n",
      "train loss:0.004707043067599948\n",
      "train loss:0.029556449619602385\n",
      "train loss:0.009252261288648644\n",
      "train loss:0.014399776749430352\n",
      "train loss:0.003882219263276306\n",
      "train loss:0.005305647308547949\n",
      "train loss:0.018386517429532193\n",
      "train loss:0.02127460127913521\n",
      "train loss:0.006388258684042597\n",
      "train loss:0.011426941256536401\n",
      "train loss:0.026097997319025065\n",
      "train loss:0.010885111487243975\n",
      "train loss:0.021293473899109062\n",
      "train loss:0.001449870354276078\n",
      "train loss:0.02611762235809929\n",
      "train loss:0.014656396762065291\n",
      "train loss:0.004105919555396317\n",
      "train loss:0.003687663837649929\n",
      "train loss:0.05415463288593601\n",
      "train loss:0.01645721996631127\n",
      "train loss:0.014951387428692389\n",
      "train loss:0.041721541583110124\n",
      "train loss:0.07657064656695661\n",
      "train loss:0.002325006775794418\n",
      "train loss:0.014780019494867546\n",
      "train loss:0.00561175570277029\n",
      "train loss:0.003193308542437945\n",
      "train loss:0.03067829106236567\n",
      "train loss:0.027950704515773295\n",
      "train loss:0.0630427992088622\n",
      "train loss:0.025545583098444548\n",
      "train loss:0.0039425591674007235\n",
      "train loss:0.005212613997498195\n",
      "train loss:0.008568570418813325\n",
      "train loss:0.00992020360683917\n",
      "train loss:0.0032777995894709196\n",
      "train loss:0.005966385203009881\n",
      "train loss:0.01589488611316871\n",
      "train loss:0.0038000627732133136\n",
      "train loss:0.00993141680515858\n",
      "train loss:0.01352157086225788\n",
      "train loss:0.04871569885663343\n",
      "train loss:0.0034339024376484114\n",
      "train loss:0.029257108289885023\n",
      "train loss:0.021061338144628527\n",
      "train loss:0.006190889028518233\n",
      "train loss:0.005089811701696319\n",
      "train loss:0.009395988488826564\n",
      "train loss:0.0045002510528293505\n",
      "train loss:0.00901199655907271\n",
      "train loss:0.007640328442236939\n",
      "train loss:0.003724589593207061\n",
      "train loss:0.020850835689610436\n",
      "train loss:0.006291838668175978\n",
      "train loss:0.01960148118900326\n",
      "train loss:0.04135588443365161\n",
      "train loss:0.00887634296494625\n",
      "train loss:0.0015653704859467633\n",
      "train loss:0.00981182575976616\n",
      "train loss:0.003339056550246235\n",
      "train loss:0.0135821832970094\n",
      "train loss:0.006834469417849807\n",
      "train loss:0.0056255083044206376\n",
      "train loss:0.03597784232419412\n",
      "train loss:0.016442337522870457\n",
      "train loss:0.0033000583560184936\n",
      "train loss:0.015168846740772379\n",
      "train loss:0.010519187710617873\n",
      "train loss:0.004316284552363316\n",
      "train loss:0.007550202163885871\n",
      "train loss:0.04750966131652655\n",
      "train loss:0.009837723853612722\n",
      "train loss:0.0014764983043788122\n",
      "train loss:0.0023280010977862094\n",
      "train loss:0.00370308999251304\n",
      "train loss:0.0064950310039487\n",
      "train loss:0.018014019523777732\n",
      "train loss:0.005104752875788177\n",
      "train loss:0.02875741319085566\n",
      "train loss:0.005171187413698066\n",
      "train loss:0.0008171972202755773\n",
      "train loss:0.0033829088563113834\n",
      "train loss:0.012566121297565685\n",
      "train loss:0.014567238193291292\n",
      "train loss:0.05917641895767147\n",
      "train loss:0.04729021927627402\n",
      "train loss:0.0010631497835027852\n",
      "train loss:0.0029837368165362833\n",
      "train loss:0.010354694706881256\n",
      "train loss:0.0056988228918809815\n",
      "train loss:0.020760690219463765\n",
      "train loss:0.01107509330917177\n",
      "train loss:0.03162933382020507\n",
      "train loss:0.003243768123538548\n",
      "train loss:0.012153844149801148\n",
      "train loss:0.004553849955121162\n",
      "train loss:0.0059679091789316486\n",
      "train loss:0.009206479914348172\n",
      "train loss:0.007191010309236992\n",
      "train loss:0.006131145440277568\n",
      "train loss:0.016189909416774402\n",
      "train loss:0.023861028760573288\n",
      "train loss:0.0025974933215791164\n",
      "train loss:0.01943518924701972\n",
      "train loss:0.005317939412594481\n",
      "train loss:0.013034536593408778\n",
      "train loss:0.0077686237365431334\n",
      "train loss:0.010689833180375474\n",
      "train loss:0.002102727463951452\n",
      "train loss:0.0026792462777450554\n",
      "train loss:0.011167161286064313\n",
      "train loss:0.0046016924041686605\n",
      "train loss:0.01934523629301804\n",
      "train loss:0.005878220647691108\n",
      "train loss:0.004933024284372824\n",
      "train loss:0.00904491888019219\n",
      "train loss:0.006115627074571616\n",
      "train loss:0.002451077610897306\n",
      "train loss:0.010410667190947374\n",
      "train loss:0.03491491925563883\n",
      "train loss:0.006393649274106452\n",
      "train loss:0.04532521225922726\n",
      "train loss:0.010543675851370777\n",
      "train loss:0.004408833536582338\n",
      "train loss:0.003803233394975521\n",
      "train loss:0.004278163051963989\n",
      "train loss:0.023692566161979556\n",
      "train loss:0.009294079130489926\n",
      "train loss:0.007491906555402388\n",
      "train loss:0.021340112287135494\n",
      "train loss:0.011512292066083191\n",
      "train loss:0.016726587416811017\n",
      "train loss:0.004091974241735068\n",
      "train loss:0.0020968159174170687\n",
      "train loss:0.002409376923943439\n",
      "train loss:0.0046089347686458755\n",
      "train loss:0.010640372105797078\n",
      "train loss:0.0019151584670743643\n",
      "train loss:0.006870406505408666\n",
      "train loss:0.004662441992752538\n",
      "train loss:0.004791823325508005\n",
      "train loss:0.027643500685778512\n",
      "train loss:0.015934016490850397\n",
      "train loss:0.006798959832176202\n",
      "train loss:0.003938363242761403\n",
      "train loss:0.003973655561959702\n",
      "train loss:0.002549219638603441\n",
      "train loss:0.010735296074326045\n",
      "train loss:0.009212268366173473\n",
      "train loss:0.013824409962334744\n",
      "train loss:0.0037827399043238023\n",
      "train loss:0.0020861321176556796\n",
      "train loss:0.000749621856932035\n",
      "train loss:0.0021511773810675137\n",
      "train loss:0.022796356599665196\n",
      "train loss:0.005925812846644244\n",
      "train loss:0.0008172855272138537\n",
      "train loss:0.010020303034996552\n",
      "train loss:0.001947892275006082\n",
      "train loss:0.0009996332896445798\n",
      "train loss:0.0014672096611248883\n",
      "train loss:0.012045582539432373\n",
      "train loss:0.0031300391871941697\n",
      "train loss:0.0007108929058056509\n",
      "train loss:0.001590363853970776\n",
      "train loss:0.01285713398298552\n",
      "train loss:0.0003482641302928587\n",
      "train loss:0.020891261354486722\n",
      "train loss:0.017381088323387726\n",
      "train loss:0.004202370886341799\n",
      "train loss:0.0025014738430240535\n",
      "train loss:0.0014663024943962475\n",
      "train loss:0.005342540242068788\n",
      "train loss:0.003105488062281988\n",
      "train loss:0.0034915108489781744\n",
      "train loss:0.005248804054550123\n",
      "train loss:0.011593160515819713\n",
      "train loss:0.02942992056934814\n",
      "train loss:0.00254173663338293\n",
      "train loss:0.03871489815016617\n",
      "train loss:0.00650603488301605\n",
      "train loss:0.025199697010403536\n",
      "train loss:0.04190059001899093\n",
      "train loss:0.006858487099996531\n",
      "train loss:0.008589028093157227\n",
      "train loss:0.0016831304742717982\n",
      "train loss:0.005656154389345397\n",
      "train loss:0.007610611767070714\n",
      "train loss:0.0029703643195787355\n",
      "train loss:0.01281581657442366\n",
      "train loss:0.00680985116202765\n",
      "train loss:0.001067553703847561\n",
      "train loss:0.005151720971049103\n",
      "train loss:0.0060869237361966455\n",
      "train loss:0.0028841005231950143\n",
      "train loss:0.04919421833514157\n",
      "train loss:0.003104697346233097\n",
      "train loss:0.003140453949154367\n",
      "train loss:0.00353028761445115\n",
      "train loss:0.025116866566308297\n",
      "train loss:0.0018465378049771814\n",
      "train loss:0.01940140785484537\n",
      "train loss:0.008748321524735071\n",
      "train loss:0.0017420792215673679\n",
      "train loss:0.011778335837091501\n",
      "train loss:0.01323532338046613\n",
      "train loss:0.0012780468867531155\n",
      "train loss:0.004335506220244595\n",
      "train loss:0.0363192629925063\n",
      "train loss:0.00239060082689386\n",
      "train loss:0.0012804597338293582\n",
      "train loss:0.011456655095003708\n",
      "train loss:0.007729018957786711\n",
      "train loss:0.0069788831736751055\n",
      "train loss:0.00033959206682912627\n",
      "train loss:0.008112344371316282\n",
      "train loss:0.015299167618696895\n",
      "train loss:0.002198580941722665\n",
      "train loss:0.0033999344504793113\n",
      "train loss:0.0005283449042968305\n",
      "train loss:0.00501710906272714\n",
      "train loss:0.0015687178793706953\n",
      "train loss:0.040367129696756404\n",
      "train loss:0.0017524390089603003\n",
      "train loss:0.022105483904958066\n",
      "train loss:0.007132961146079609\n",
      "=== epoch:10, train acc:0.991, test acc:0.987 ===\n",
      "train loss:0.042476195930473484\n",
      "train loss:0.003901833639300104\n",
      "train loss:0.021825886789836938\n",
      "train loss:0.0024265802705840285\n",
      "train loss:0.016688564354652744\n",
      "train loss:0.0070955610881712735\n",
      "train loss:0.0031386704577785773\n",
      "train loss:0.01138243664352426\n",
      "train loss:0.0363604700891656\n",
      "train loss:0.0010864943599517081\n",
      "train loss:0.0028948519062774974\n",
      "train loss:0.007100954900365813\n",
      "train loss:0.0039373578178716305\n",
      "train loss:0.01502293797332847\n",
      "train loss:0.017452703010735003\n",
      "train loss:0.032769607198379534\n",
      "train loss:0.0011854454516523683\n",
      "train loss:0.015410078145428288\n",
      "train loss:0.012108635110596924\n",
      "train loss:0.005583557284310444\n",
      "train loss:0.024186235175552316\n",
      "train loss:0.0012929225597877122\n",
      "train loss:0.0020501234844665624\n",
      "train loss:0.011363386188131703\n",
      "train loss:0.010055202167014426\n",
      "train loss:0.004724682503642774\n",
      "train loss:0.007515247977422323\n",
      "train loss:0.009969745361213131\n",
      "train loss:0.004055913661565347\n",
      "train loss:0.013906493937710405\n",
      "train loss:0.017362262180135365\n",
      "train loss:0.0040192343608339435\n",
      "train loss:0.002778331707841691\n",
      "train loss:0.006882636391136933\n",
      "train loss:0.0016230642981332382\n",
      "train loss:0.04708321570780256\n",
      "train loss:0.009702493066565523\n",
      "train loss:0.004616162594441885\n",
      "train loss:0.0011916716893068857\n",
      "train loss:0.013290152785353011\n",
      "train loss:0.013690826861556754\n",
      "train loss:0.006124890940779872\n",
      "train loss:0.014941765341072404\n",
      "train loss:0.0037452096989121263\n",
      "train loss:0.00579332656568766\n",
      "train loss:0.02549237326264778\n",
      "train loss:0.0062896827631174065\n",
      "train loss:0.02669530027552049\n",
      "train loss:0.0018421078921685473\n",
      "train loss:0.009635478465054116\n",
      "train loss:0.002591201756201914\n",
      "train loss:0.02418198807410573\n",
      "train loss:0.005165608236147857\n",
      "train loss:0.0018558856050717987\n",
      "train loss:0.0033023766239840017\n",
      "train loss:0.007146810637332655\n",
      "train loss:0.0013026940315377803\n",
      "train loss:0.06195066886709836\n",
      "train loss:0.01875002496064698\n",
      "train loss:0.002913416127523648\n",
      "train loss:0.007769292889242131\n",
      "train loss:0.0032250647079135834\n",
      "train loss:0.008563453451942198\n",
      "train loss:0.0038658257133997883\n",
      "train loss:0.006128084082963791\n",
      "train loss:0.0021644486924935215\n",
      "train loss:0.018884792521357087\n",
      "train loss:0.02245800328235748\n",
      "train loss:0.011640567470721806\n",
      "train loss:0.002241244348434656\n",
      "train loss:0.006608436412415546\n",
      "train loss:0.008041369609806021\n",
      "train loss:0.014014345350973578\n",
      "train loss:0.0023735210006299587\n",
      "train loss:0.0070719613004845945\n",
      "train loss:0.002442260934304717\n",
      "train loss:0.016387796511497434\n",
      "train loss:0.0010808302860813655\n",
      "train loss:0.000733144056741144\n",
      "train loss:0.0040728918528171645\n",
      "train loss:0.0015674515532438976\n",
      "train loss:0.0058902825765675\n",
      "train loss:0.007257220766532524\n",
      "train loss:0.0041385272774103945\n",
      "train loss:0.0074155328185004695\n",
      "train loss:0.011935393100044966\n",
      "train loss:0.00157947338035697\n",
      "train loss:0.005232087241998787\n",
      "train loss:0.004492894657510685\n",
      "train loss:0.0038142382411616876\n",
      "train loss:0.007329728440060296\n",
      "train loss:0.010631603689134194\n",
      "train loss:0.013314830664411999\n",
      "train loss:0.040150665088003176\n",
      "train loss:0.003144331667945521\n",
      "train loss:0.013145654687792616\n",
      "train loss:0.003391935160663988\n",
      "train loss:0.004866489978471658\n",
      "train loss:0.005456884208386152\n",
      "train loss:0.005582653641601281\n",
      "train loss:0.0019930405001490196\n",
      "train loss:0.005028320172461132\n",
      "train loss:0.007733313597860314\n",
      "train loss:0.05801975762980453\n",
      "train loss:0.002801608819121542\n",
      "train loss:0.002542120983967504\n",
      "train loss:0.0013454723088307914\n",
      "train loss:0.017014319498089178\n",
      "train loss:0.015599480246064829\n",
      "train loss:0.0019689658552572834\n",
      "train loss:0.004738951547955599\n",
      "train loss:0.009056413470219935\n",
      "train loss:0.019460787964091255\n",
      "train loss:0.003106943214624682\n",
      "train loss:0.0017848813853005873\n",
      "train loss:0.02939078772487004\n",
      "train loss:0.017898591231375965\n",
      "train loss:0.0035348070876390094\n",
      "train loss:0.0020995530174815454\n",
      "train loss:0.017330036381582824\n",
      "train loss:0.0032943480604683234\n",
      "train loss:0.0037214885804607704\n",
      "train loss:0.014762872165489016\n",
      "train loss:0.0048984420309669836\n",
      "train loss:0.008996074868589712\n",
      "train loss:0.01677711944928893\n",
      "train loss:0.004803978064089893\n",
      "train loss:0.0014349267800405538\n",
      "train loss:0.00779511793044231\n",
      "train loss:0.016904817263047125\n",
      "train loss:0.008105499433281094\n",
      "train loss:0.0036503676288279123\n",
      "train loss:0.0024571443019574804\n",
      "train loss:0.005254694580270601\n",
      "train loss:0.005342537810656899\n",
      "train loss:0.0023803285443683305\n",
      "train loss:0.007746722051980165\n",
      "train loss:0.00660865787075403\n",
      "train loss:0.004467688475036533\n",
      "train loss:0.0005621846848996349\n",
      "train loss:0.001203177241209796\n",
      "train loss:0.010857729056493843\n",
      "train loss:0.010622230750245439\n",
      "train loss:0.0030841657838096507\n",
      "train loss:0.0032122116801830965\n",
      "train loss:0.018976422321391854\n",
      "train loss:0.0030961642831682933\n",
      "train loss:0.0036258028465519588\n",
      "train loss:0.0037040248023883977\n",
      "train loss:0.0031075511242558023\n",
      "train loss:0.00304318945256983\n",
      "train loss:0.004117880727828656\n",
      "train loss:0.0008413853649348489\n",
      "train loss:0.0026119190060267337\n",
      "train loss:0.0046800859599823545\n",
      "train loss:0.0018873418936794623\n",
      "train loss:0.0021094893418775436\n",
      "train loss:0.028700213415239217\n",
      "train loss:0.005374030061320394\n",
      "train loss:0.0025201163418877787\n",
      "train loss:0.0047573417340459724\n",
      "train loss:0.017865308314638638\n",
      "train loss:0.022151055797293585\n",
      "train loss:0.01573087183611203\n",
      "train loss:0.003484609052085776\n",
      "train loss:0.06410622502835216\n",
      "train loss:0.0001772305076377945\n",
      "train loss:0.017396087080823498\n",
      "train loss:0.007906449437064818\n",
      "train loss:0.025670681834342016\n",
      "train loss:0.005023595702716089\n",
      "train loss:0.00691920257097335\n",
      "train loss:0.001185609049267693\n",
      "train loss:0.013088758888146973\n",
      "train loss:0.0012270626689615757\n",
      "train loss:0.010892906004682845\n",
      "train loss:0.0020110577455242514\n",
      "train loss:0.010166106429974849\n",
      "train loss:0.0017244287609563265\n",
      "train loss:0.0009652284973754627\n",
      "train loss:0.00877874040383112\n",
      "train loss:0.008003138555731863\n",
      "train loss:0.005124822183715167\n",
      "train loss:0.07400584651203865\n",
      "train loss:0.00332216632052919\n",
      "train loss:0.10023742203126032\n",
      "train loss:0.00779186751069837\n",
      "train loss:0.0004449431793434815\n",
      "train loss:0.0020780717543620202\n",
      "train loss:0.008461855057260869\n",
      "train loss:0.0040265340984889245\n",
      "train loss:0.004093237755182822\n",
      "train loss:0.00900536593212491\n",
      "train loss:0.012287282936138823\n",
      "train loss:0.001079693831136436\n",
      "train loss:0.014501076614820464\n",
      "train loss:0.0027837003944066537\n",
      "train loss:0.01677502370496015\n",
      "train loss:0.009798290642051417\n",
      "train loss:0.018768185717916202\n",
      "train loss:0.004784173631654074\n",
      "train loss:0.005019838091787892\n",
      "train loss:0.010828601096646575\n",
      "train loss:0.010777722915901719\n",
      "train loss:0.007983239152717696\n",
      "train loss:0.006475249270002373\n",
      "train loss:0.0011641488027257505\n",
      "train loss:0.00887924019275344\n",
      "train loss:0.0020367849026623175\n",
      "train loss:0.010341514357411033\n",
      "train loss:0.0027546652375458475\n",
      "train loss:0.001017057860582942\n",
      "train loss:0.003791927216258953\n",
      "train loss:0.0033401352793451466\n",
      "train loss:0.002963007316482074\n",
      "train loss:0.01654162487535876\n",
      "train loss:0.00962982625755227\n",
      "train loss:0.017768275249566978\n",
      "train loss:0.009215616845451007\n",
      "train loss:0.007625816105627779\n",
      "train loss:0.0031449954065469075\n",
      "train loss:0.0038183705426914354\n",
      "train loss:0.00436039880080503\n",
      "train loss:0.06384721057926035\n",
      "train loss:0.00870390772201216\n",
      "train loss:0.015180929143800991\n",
      "train loss:0.0034291720573004247\n",
      "train loss:0.010859618219235303\n",
      "train loss:0.0036920590140033104\n",
      "train loss:0.013214622511696077\n",
      "train loss:0.0006835193710307609\n",
      "train loss:0.017560073696286933\n",
      "train loss:0.005686810889256269\n",
      "train loss:0.003169263458736332\n",
      "train loss:0.01067164647222319\n",
      "train loss:0.0022637125770964646\n",
      "train loss:0.003447274465924568\n",
      "train loss:0.013934701898185133\n",
      "train loss:0.008862085746893476\n",
      "train loss:0.002644571119573106\n",
      "train loss:0.005609502359890309\n",
      "train loss:0.059059560958647006\n",
      "train loss:0.0014553539272879978\n",
      "train loss:0.0034690309412491833\n",
      "train loss:0.005578369876125203\n",
      "train loss:0.019069604614491174\n",
      "train loss:0.012741007388193367\n",
      "train loss:0.001592720510149133\n",
      "train loss:0.004235763917314794\n",
      "train loss:0.011338166950289642\n",
      "train loss:0.0031316931417882843\n",
      "train loss:0.0013773036958390716\n",
      "train loss:0.0022454182089053885\n",
      "train loss:0.0008442926870268423\n",
      "train loss:0.0023359970484369895\n",
      "train loss:0.0127331685514249\n",
      "train loss:0.003230732316735574\n",
      "train loss:0.000352272292584489\n",
      "train loss:0.003718878787947986\n",
      "train loss:0.005764770580311673\n",
      "train loss:0.005598759793883786\n",
      "train loss:0.025080149212702952\n",
      "train loss:0.010231163811823284\n",
      "train loss:0.02930115644479035\n",
      "train loss:0.0043085296270415265\n",
      "train loss:0.008573811396956772\n",
      "train loss:0.0030548936471701312\n",
      "train loss:0.004293248604355229\n",
      "train loss:0.008089405534410416\n",
      "train loss:0.016412840640608627\n",
      "train loss:0.01905639143218302\n",
      "train loss:0.0011901233344116565\n",
      "train loss:0.0019276373316521834\n",
      "train loss:0.009154459237111006\n",
      "train loss:0.003197459348259565\n",
      "train loss:0.0027503942719259355\n",
      "train loss:0.006579366774186648\n",
      "train loss:0.004733460541371989\n",
      "train loss:0.016423189772550608\n",
      "train loss:0.0055847208015497255\n",
      "train loss:0.003250299661237036\n",
      "train loss:0.003428878346679083\n",
      "train loss:0.002925145906831495\n",
      "train loss:0.04263300160099145\n",
      "train loss:0.003390144253828174\n",
      "train loss:0.015446955629092223\n",
      "train loss:0.0042672756186039286\n",
      "train loss:0.012462167085877164\n",
      "train loss:0.007315703539608588\n",
      "train loss:0.0009965466272006777\n",
      "train loss:0.02722522706655863\n",
      "train loss:0.02362805234853245\n",
      "train loss:0.010685745156462041\n",
      "train loss:0.01821885978502078\n",
      "train loss:0.0936172811299801\n",
      "train loss:0.005895422623676171\n",
      "train loss:0.002417917902825148\n",
      "train loss:0.010507257803501766\n",
      "train loss:0.008321665016303721\n",
      "train loss:0.09065775912958733\n",
      "train loss:0.0009435841565242905\n",
      "train loss:0.01183230601682348\n",
      "train loss:0.006837797691626298\n",
      "train loss:0.027563111970695133\n",
      "train loss:0.0689722756352402\n",
      "train loss:0.00803573100669597\n",
      "train loss:0.01142391905757011\n",
      "train loss:0.009722002329533148\n",
      "train loss:0.005523806702321396\n",
      "train loss:0.02310168326901396\n",
      "train loss:0.004989801316375659\n",
      "train loss:0.007955659820528089\n",
      "train loss:0.0027102988289421197\n",
      "train loss:0.0029048929839524105\n",
      "train loss:0.01693590777428815\n",
      "train loss:0.010162005172626744\n",
      "train loss:0.002693524465143409\n",
      "train loss:0.007178738324532255\n",
      "train loss:0.005492588291560274\n",
      "train loss:0.003218853274993199\n",
      "train loss:0.006402199758696836\n",
      "train loss:0.022871193518282595\n",
      "train loss:0.007080837970744216\n",
      "train loss:0.0015627329810216997\n",
      "train loss:0.0020400417741288646\n",
      "train loss:0.004956170601640092\n",
      "train loss:0.002563245078790254\n",
      "train loss:0.012566755377349166\n",
      "train loss:0.004073563404916791\n",
      "train loss:0.007048927264857211\n",
      "train loss:0.0046681678762441605\n",
      "train loss:0.0029609519957031123\n",
      "train loss:0.008586764894592097\n",
      "train loss:0.000969978138943328\n",
      "train loss:0.0012907985444522271\n",
      "train loss:0.004131809677595331\n",
      "train loss:0.01016241373922248\n",
      "train loss:0.0017813887005606519\n",
      "train loss:0.004598730232384308\n",
      "train loss:0.0068068662014504665\n",
      "train loss:0.002847189285370168\n",
      "train loss:0.003396073520517255\n",
      "train loss:0.006852863202561796\n",
      "train loss:0.002857245619283878\n",
      "train loss:0.013203441066638582\n",
      "train loss:0.010964839101155399\n",
      "train loss:0.005772756255607371\n",
      "train loss:0.01846663772170797\n",
      "train loss:0.003380972687793071\n",
      "train loss:0.030421139138387617\n",
      "train loss:0.011866591416588025\n",
      "train loss:0.002367678311434127\n",
      "train loss:0.004170603828819498\n",
      "train loss:0.005016502392562263\n",
      "train loss:0.0014820919626739914\n",
      "train loss:0.020054202699456587\n",
      "train loss:0.0186180836250957\n",
      "train loss:0.010215479706102829\n",
      "train loss:0.006842857279356987\n",
      "train loss:0.01228718706508344\n",
      "train loss:0.018616938724525883\n",
      "train loss:0.008548942400017889\n",
      "train loss:0.0058955574737523265\n",
      "train loss:0.014412673725020359\n",
      "train loss:0.0006931033908868016\n",
      "train loss:0.006756221490863963\n",
      "train loss:0.006238926040918724\n",
      "train loss:0.011296841542776848\n",
      "train loss:0.0019012343383596616\n",
      "train loss:0.05912097087201237\n",
      "train loss:0.002370762714326243\n",
      "train loss:0.0064094804937617645\n",
      "train loss:0.003102288887281095\n",
      "train loss:0.007659873608764832\n",
      "train loss:0.019475131761370078\n",
      "train loss:0.031499460960421506\n",
      "train loss:0.0034511885380463033\n",
      "train loss:0.00701563202376642\n",
      "train loss:0.006976271744224248\n",
      "train loss:0.029014526603789635\n",
      "train loss:0.0016771730283415402\n",
      "train loss:0.010298408111707832\n",
      "train loss:0.0021597913898239447\n",
      "train loss:0.013566926082492348\n",
      "train loss:0.006805453722335711\n",
      "train loss:0.0004183495903489697\n",
      "train loss:0.003680958698064348\n",
      "train loss:0.08129954449243054\n",
      "train loss:0.013366133621576737\n",
      "train loss:0.0017651804511114291\n",
      "train loss:0.035687074584203476\n",
      "train loss:0.007130189676114617\n",
      "train loss:0.001994643074094792\n",
      "train loss:0.0031051535041798635\n",
      "train loss:0.005931498612466396\n",
      "train loss:0.009373183643072549\n",
      "train loss:0.0016376474725695522\n",
      "train loss:0.00938928221214373\n",
      "train loss:0.010736219104572866\n",
      "train loss:0.0029019455202347073\n",
      "train loss:0.0018796681199601181\n",
      "train loss:0.03931330480875711\n",
      "train loss:0.014503873983398615\n",
      "train loss:0.01988524521623628\n",
      "train loss:0.0026910843249880645\n",
      "train loss:0.02771558449639385\n",
      "train loss:0.0037782596357111608\n",
      "train loss:0.002679157279586588\n",
      "train loss:0.01943926298575804\n",
      "train loss:0.000839510279386237\n",
      "train loss:0.002987473733002692\n",
      "train loss:0.002928289479558528\n",
      "train loss:0.0018261809826732103\n",
      "train loss:0.004355384862632767\n",
      "train loss:0.003121101255668603\n",
      "train loss:0.0071033452936501255\n",
      "train loss:0.02037228526397946\n",
      "train loss:0.005098757528480216\n",
      "train loss:0.006758138751104883\n",
      "train loss:0.004944020846175499\n",
      "train loss:0.009144088123217207\n",
      "train loss:0.04413214498919919\n",
      "train loss:0.006749526286326314\n",
      "train loss:0.001965650846074943\n",
      "train loss:0.004424642302678507\n",
      "train loss:0.011729059985805947\n",
      "train loss:0.006393918877621185\n",
      "train loss:0.006885951793168628\n",
      "train loss:0.006541557770348938\n",
      "train loss:0.0061276120378616905\n",
      "train loss:0.011713006073584603\n",
      "train loss:0.005647258933931761\n",
      "train loss:0.012795685716243928\n",
      "train loss:0.07548230365897\n",
      "train loss:0.004111604854150514\n",
      "train loss:0.002318538600039154\n",
      "train loss:0.007809393231184305\n",
      "train loss:0.010823713690769107\n",
      "train loss:0.010881176712563414\n",
      "train loss:0.0028734608391203505\n",
      "train loss:0.006949733917781891\n",
      "train loss:0.005176736502157598\n",
      "train loss:0.003609580312139987\n",
      "train loss:0.015008840599257126\n",
      "train loss:0.0019829228787573453\n",
      "train loss:0.009732551324636405\n",
      "train loss:0.009721872864607899\n",
      "train loss:0.012710184935186155\n",
      "train loss:0.006272821291166892\n",
      "train loss:0.006138018900325869\n",
      "train loss:0.06609745761267123\n",
      "train loss:0.017185884334918574\n",
      "train loss:0.015004376754385264\n",
      "train loss:0.020778947824968242\n",
      "train loss:0.010627722463120328\n",
      "train loss:0.08104291758224358\n",
      "train loss:0.007558953760152349\n",
      "train loss:0.011458353337756888\n",
      "train loss:0.002331937579614384\n",
      "train loss:0.013147609435823835\n",
      "train loss:0.0024127015903147027\n",
      "train loss:0.026258574839478993\n",
      "train loss:0.007750582898588511\n",
      "train loss:0.0008166067344799734\n",
      "train loss:0.012736763813310802\n",
      "train loss:0.04335956173019156\n",
      "train loss:0.011850564286650071\n",
      "train loss:0.0072292729616528825\n",
      "train loss:0.01712507380557702\n",
      "train loss:0.005401298570697554\n",
      "train loss:0.0024937890205939885\n",
      "train loss:0.004586112903647963\n",
      "train loss:0.0037685052299547346\n",
      "train loss:0.01310103553444426\n",
      "train loss:0.0016782879633334227\n",
      "train loss:0.007864223902489378\n",
      "train loss:0.00987905133992524\n",
      "train loss:0.0294619551713263\n",
      "train loss:0.00546539272491581\n",
      "train loss:0.007425665322235242\n",
      "train loss:0.006310477580964806\n",
      "train loss:0.007195306089835573\n",
      "train loss:0.003365384830981631\n",
      "train loss:0.0036064793583921186\n",
      "train loss:0.031117833078287558\n",
      "train loss:0.007990233275575636\n",
      "train loss:0.004642207794245349\n",
      "train loss:0.00849052398083443\n",
      "train loss:0.04482361007053625\n",
      "train loss:0.005368416781040651\n",
      "train loss:0.004978066455004804\n",
      "train loss:0.009758355159556316\n",
      "train loss:0.01152083669253407\n",
      "train loss:0.009220110557774944\n",
      "train loss:0.0025340859680295087\n",
      "train loss:0.0034299464594297756\n",
      "train loss:0.015622603551036491\n",
      "train loss:0.020617985533657325\n",
      "train loss:0.005795330344430242\n",
      "train loss:0.018268597663124428\n",
      "train loss:0.005155164934984858\n",
      "train loss:0.05920511257271729\n",
      "train loss:0.0024628049712948383\n",
      "train loss:0.0050208301529051005\n",
      "train loss:0.007663238021852181\n",
      "train loss:0.002551835462032918\n",
      "train loss:0.016695546555095184\n",
      "train loss:0.03278251629462367\n",
      "train loss:0.009246417992379921\n",
      "train loss:0.004675717372852517\n",
      "train loss:0.003310814482369735\n",
      "train loss:0.0010407660416446609\n",
      "train loss:0.0022808781140878547\n",
      "train loss:0.007244399193137271\n",
      "train loss:0.002535436072210839\n",
      "train loss:0.00279871954362162\n",
      "train loss:0.003868779850275082\n",
      "train loss:0.025087681705469857\n",
      "train loss:0.0009023493559462092\n",
      "train loss:0.002169483839387542\n",
      "train loss:0.0058066017261094675\n",
      "train loss:0.020411415731049227\n",
      "train loss:0.0018599307592971342\n",
      "train loss:0.005916032361318393\n",
      "train loss:0.012782957339092101\n",
      "train loss:0.004698439496377107\n",
      "train loss:0.0038765088794790303\n",
      "train loss:0.005556104266224268\n",
      "train loss:0.0056462889287031345\n",
      "train loss:0.011641971503312925\n",
      "train loss:0.0035004563892888025\n",
      "train loss:0.002724383173550451\n",
      "train loss:0.0016829291446248352\n",
      "train loss:0.00174769728608284\n",
      "train loss:0.0016020888577982565\n",
      "train loss:0.005573583641683076\n",
      "train loss:0.005557121345500399\n",
      "train loss:0.012298795395512381\n",
      "train loss:0.004876939070861826\n",
      "train loss:0.007026835878875931\n",
      "train loss:0.0034948125416203084\n",
      "train loss:0.0016146131064950795\n",
      "train loss:0.007774294003309131\n",
      "train loss:0.011335680918674915\n",
      "train loss:0.0050924400713638065\n",
      "train loss:0.0025059763808492736\n",
      "train loss:0.012283221978713193\n",
      "train loss:0.001906110849454425\n",
      "train loss:0.04597934097854892\n",
      "train loss:0.003530341566660175\n",
      "train loss:0.006535020889330872\n",
      "train loss:0.002660591465026017\n",
      "train loss:0.004949261075243353\n",
      "train loss:0.002181885986823236\n",
      "train loss:0.011552099681551537\n",
      "train loss:0.0009103716341520418\n",
      "train loss:0.011255143477290324\n",
      "train loss:0.003751095577633522\n",
      "train loss:0.03162942371043357\n",
      "train loss:0.0008931135142708833\n",
      "train loss:0.003937607858661273\n",
      "train loss:0.02033500448803305\n",
      "train loss:0.039085024206164116\n",
      "train loss:0.022227763864907595\n",
      "train loss:0.005709185186396472\n",
      "train loss:0.001964280452951808\n",
      "train loss:0.014504291870329995\n",
      "train loss:0.005755716220365869\n",
      "train loss:0.006386457753849126\n",
      "train loss:0.0019429416608526414\n",
      "train loss:0.038752521183818285\n",
      "train loss:0.0026115824270890476\n",
      "train loss:0.004668882367651767\n",
      "train loss:0.004064413276558426\n",
      "train loss:0.002571149701821428\n",
      "train loss:0.0046330232459606555\n",
      "train loss:0.0066913671585619875\n",
      "train loss:0.006116375752951653\n",
      "train loss:0.0058764548665870405\n",
      "train loss:0.006157793486921881\n",
      "train loss:0.0066446044657469845\n",
      "train loss:0.012590082942980654\n",
      "train loss:0.014715963760081224\n",
      "train loss:0.0071134038806240415\n",
      "train loss:0.010127576566145009\n",
      "train loss:0.0010237815282115028\n",
      "train loss:0.056515147877468606\n",
      "train loss:0.01656992214166426\n",
      "train loss:0.0019407225015072268\n",
      "train loss:0.008005535697435666\n",
      "train loss:0.006275786482101626\n",
      "train loss:0.00904944992836199\n",
      "train loss:0.007140003308162823\n",
      "train loss:0.001081982636312481\n",
      "train loss:0.016443646465115994\n",
      "train loss:0.006645268788778799\n",
      "train loss:0.0017480233237584756\n",
      "train loss:0.0023241042296309926\n",
      "train loss:0.002091318857481184\n",
      "train loss:0.003097435080999849\n",
      "=== epoch:11, train acc:0.99, test acc:0.987 ===\n",
      "train loss:0.002177461260938841\n",
      "train loss:0.004544183664293643\n",
      "train loss:0.008017673594140424\n",
      "train loss:0.007242284772915607\n",
      "train loss:0.0024173578960346304\n",
      "train loss:0.002329130324570132\n",
      "train loss:0.0017944116614774263\n",
      "train loss:0.007068534480767659\n",
      "train loss:0.0026709349174750562\n",
      "train loss:0.008419608531493794\n",
      "train loss:0.008981409527545786\n",
      "train loss:0.0009180564326644883\n",
      "train loss:0.012331866051046464\n",
      "train loss:0.005732209050113384\n",
      "train loss:0.006696812345507298\n",
      "train loss:0.0009970340980532037\n",
      "train loss:0.013283839020246593\n",
      "train loss:0.0025910580525024527\n",
      "train loss:0.0005880958070752313\n",
      "train loss:0.003044868156903128\n",
      "train loss:0.002795721828082866\n",
      "train loss:0.0007730650466172978\n",
      "train loss:0.008570738932821542\n",
      "train loss:0.003648221594659381\n",
      "train loss:0.015107527776872022\n",
      "train loss:0.0031143128645811087\n",
      "train loss:0.03676980748693283\n",
      "train loss:0.00150279753617231\n",
      "train loss:0.002674673369307457\n",
      "train loss:0.00578699793895708\n",
      "train loss:0.001522528797085802\n",
      "train loss:0.008577720683404873\n",
      "train loss:0.009738006345078442\n",
      "train loss:0.0051171356196207\n",
      "train loss:0.010310951405850874\n",
      "train loss:0.010922669039840672\n",
      "train loss:0.005586615172739784\n",
      "train loss:0.026937517705067974\n",
      "train loss:0.008485787000049115\n",
      "train loss:0.0072574846387162715\n",
      "train loss:0.0034012380629933597\n",
      "train loss:0.0008297950959822555\n",
      "train loss:0.001894434750459798\n",
      "train loss:0.004061760720229191\n",
      "train loss:0.00486592232691064\n",
      "train loss:0.016401386395171576\n",
      "train loss:0.0015056385694718892\n",
      "train loss:0.0010451470475740415\n",
      "train loss:0.010690536086621304\n",
      "train loss:0.011980092908885487\n",
      "train loss:0.0007512565840463481\n",
      "train loss:0.023454751874404826\n",
      "train loss:0.012115620245603696\n",
      "train loss:0.005257652668862194\n",
      "train loss:0.0006503362004426647\n",
      "train loss:0.009344644919122815\n",
      "train loss:0.0031116735483360768\n",
      "train loss:0.020134733293676182\n",
      "train loss:0.013781349389327074\n",
      "train loss:0.0019312132660006698\n",
      "train loss:0.007434853911275785\n",
      "train loss:0.0013108183435739619\n",
      "train loss:0.001080911072326486\n",
      "train loss:0.017043410007677333\n",
      "train loss:0.001793704608904862\n",
      "train loss:0.005828973143856197\n",
      "train loss:0.006015333877988358\n",
      "train loss:0.007849999465823123\n",
      "train loss:0.011836071616292791\n",
      "train loss:0.0012030903585289342\n",
      "train loss:0.0012831683286341035\n",
      "train loss:0.006108691056021319\n",
      "train loss:0.005192725713990034\n",
      "train loss:0.0013122310532682083\n",
      "train loss:0.019145878258316856\n",
      "train loss:0.0009723935415017352\n",
      "train loss:0.01257097529254239\n",
      "train loss:0.0035837535813285125\n",
      "train loss:0.0013493282549618365\n",
      "train loss:0.030885810934337142\n",
      "train loss:0.06440392522059056\n",
      "train loss:0.007551668348713851\n",
      "train loss:0.015991679608622175\n",
      "train loss:0.0010252676708507656\n",
      "train loss:0.004625608250825013\n",
      "train loss:0.0015084890979194007\n",
      "train loss:0.0004922737782873263\n",
      "train loss:0.0057574065234709745\n",
      "train loss:0.0212752331300904\n",
      "train loss:0.004699888579492194\n",
      "train loss:0.0018864354231307872\n",
      "train loss:0.0018770637738095219\n",
      "train loss:0.0016846930833267948\n",
      "train loss:0.0021824314968105526\n",
      "train loss:0.0021443258644520615\n",
      "train loss:0.017244404430999446\n",
      "train loss:0.0046723809301624725\n",
      "train loss:0.009494508497268838\n",
      "train loss:0.027835658657352866\n",
      "train loss:0.0024003427719596505\n",
      "train loss:0.014820130287104468\n",
      "train loss:0.004923512442916855\n",
      "train loss:0.006377972143535741\n",
      "train loss:0.0009128800121382384\n",
      "train loss:0.003343192580847529\n",
      "train loss:0.004095650977800435\n",
      "train loss:0.00720086583601684\n",
      "train loss:0.0029995440458091276\n",
      "train loss:0.009967266701251755\n",
      "train loss:0.0036319744711088052\n",
      "train loss:0.010031492845269236\n",
      "train loss:0.015892325332332945\n",
      "train loss:0.0013009014943332054\n",
      "train loss:0.007145289106143422\n",
      "train loss:0.005419233315254691\n",
      "train loss:0.0044807660311079155\n",
      "train loss:0.00200495711928573\n",
      "train loss:0.00826802716525878\n",
      "train loss:0.00523072785177831\n",
      "train loss:0.0022944654962936033\n",
      "train loss:0.013879206650553526\n",
      "train loss:0.0039946813701739175\n",
      "train loss:0.0003443237914294215\n",
      "train loss:0.0035931844977331985\n",
      "train loss:0.0025131854666538976\n",
      "train loss:0.0011375465461081835\n",
      "train loss:0.0012698723800783915\n",
      "train loss:0.004016796039150829\n",
      "train loss:0.003639974067269924\n",
      "train loss:0.0007828866942804462\n",
      "train loss:0.030550364751889162\n",
      "train loss:0.0025458341529471275\n",
      "train loss:0.00173298131898844\n",
      "train loss:0.004442835255105792\n",
      "train loss:0.0007240662468438075\n",
      "train loss:0.0018211054054569828\n",
      "train loss:0.0007968695867382771\n",
      "train loss:0.003925678339565417\n",
      "train loss:0.0004429599355558956\n",
      "train loss:0.0048527973139466255\n",
      "train loss:0.0021583007410963216\n",
      "train loss:0.004300704397689822\n",
      "train loss:0.0013752895333559697\n",
      "train loss:0.008714091621469326\n",
      "train loss:0.006033455773649837\n",
      "train loss:0.00045112054944237387\n",
      "train loss:0.017337997976843118\n",
      "train loss:0.0033034099475705175\n",
      "train loss:0.007396871650083371\n",
      "train loss:0.006800637407315563\n",
      "train loss:0.00131552676495242\n",
      "train loss:0.022584397161985348\n",
      "train loss:0.0035567952572259517\n",
      "train loss:0.0029053457286628104\n",
      "train loss:0.0020509048972610854\n",
      "train loss:0.01740097474600806\n",
      "train loss:0.028346094227856652\n",
      "train loss:0.004488277162172326\n",
      "train loss:0.0018762895181216798\n",
      "train loss:0.005751571991855379\n",
      "train loss:0.0089857041986971\n",
      "train loss:0.013868811529212228\n",
      "train loss:0.004845080379787857\n",
      "train loss:0.005162350020874028\n",
      "train loss:0.003710725983558747\n",
      "train loss:0.029878566735804992\n",
      "train loss:0.0019189528299570838\n",
      "train loss:0.001035001562723897\n",
      "train loss:0.03365829408630041\n",
      "train loss:0.0009915245565167397\n",
      "train loss:0.0021015643492361823\n",
      "train loss:0.0029807323349690055\n",
      "train loss:0.0036556211546016843\n",
      "train loss:0.001724708786742802\n",
      "train loss:0.002442580201932745\n",
      "train loss:0.0012428119757325862\n",
      "train loss:0.006425507269565958\n",
      "train loss:0.002312628554278732\n",
      "train loss:0.018028327929037496\n",
      "train loss:0.005046285622892415\n",
      "train loss:0.037152497238561906\n",
      "train loss:0.0003975413199002705\n",
      "train loss:0.002226016295486976\n",
      "train loss:0.0007229727364731377\n",
      "train loss:0.0014943332500809532\n",
      "train loss:0.003449765681716803\n",
      "train loss:0.0033236491501869216\n",
      "train loss:0.024565232141643044\n",
      "train loss:0.009860567269966522\n",
      "train loss:0.009228705500930186\n",
      "train loss:0.007107468319200016\n",
      "train loss:0.014362262608529625\n",
      "train loss:0.0029641978940832896\n",
      "train loss:0.001436430436892169\n",
      "train loss:0.009276294383487477\n",
      "train loss:0.0009446186620445627\n",
      "train loss:0.001483030986386236\n",
      "train loss:0.013339741450424627\n",
      "train loss:0.0012984376064410833\n",
      "train loss:0.05529304386608991\n",
      "train loss:0.02595230751953984\n",
      "train loss:0.01814175312607239\n",
      "train loss:0.002023720984879691\n",
      "train loss:0.002428787049671902\n",
      "train loss:0.0014415043468497717\n",
      "train loss:0.004512816008956923\n",
      "train loss:0.005285146034727592\n",
      "train loss:0.0007630653495065791\n",
      "train loss:0.009324637279584746\n",
      "train loss:0.00921925716677677\n",
      "train loss:0.0178956838185689\n",
      "train loss:0.027419800391019548\n",
      "train loss:0.0016783725933601909\n",
      "train loss:0.003316750435150159\n",
      "train loss:0.00019356677320669365\n",
      "train loss:0.004664216511180704\n",
      "train loss:0.0023645275830703385\n",
      "train loss:0.04572196809560482\n",
      "train loss:0.00359921116353772\n",
      "train loss:0.0019311403529190462\n",
      "train loss:0.0026908536046795816\n",
      "train loss:0.0044074481119892725\n",
      "train loss:0.009177594463977423\n",
      "train loss:0.0015025127810459902\n",
      "train loss:0.0015108814206323592\n",
      "train loss:0.000866939905270974\n",
      "train loss:0.0014634804009585256\n",
      "train loss:0.013608463683809233\n",
      "train loss:0.003089993827856125\n",
      "train loss:0.0006337661718419678\n",
      "train loss:0.004103014707458579\n",
      "train loss:0.013288284475846783\n",
      "train loss:0.0029908828855367358\n",
      "train loss:0.01282434835353986\n",
      "train loss:0.0032177401972082955\n",
      "train loss:0.0036459041523873204\n",
      "train loss:0.00274835822220852\n",
      "train loss:0.001440360574788155\n",
      "train loss:0.003335313446363476\n",
      "train loss:0.09889141331585419\n",
      "train loss:0.016215961062249137\n",
      "train loss:0.000962913763561043\n",
      "train loss:0.002987158371003599\n",
      "train loss:0.005754693953443536\n",
      "train loss:0.00196300965253087\n",
      "train loss:0.009869807909999436\n",
      "train loss:0.005201731650775537\n",
      "train loss:0.004257283693695257\n",
      "train loss:0.007383835425180076\n",
      "train loss:0.0034912766995078347\n",
      "train loss:0.008968763404457198\n",
      "train loss:0.0047182813459453535\n",
      "train loss:0.0013282418813563696\n",
      "train loss:0.006063514487293817\n",
      "train loss:0.0021478584428874414\n",
      "train loss:0.006759205116813552\n",
      "train loss:0.0013040030391437793\n",
      "train loss:0.021074183588804054\n",
      "train loss:0.013188383036322528\n",
      "train loss:0.0012786716612846237\n",
      "train loss:0.005751420981817805\n",
      "train loss:0.0010997725348379872\n",
      "train loss:0.0004006584074107973\n",
      "train loss:0.017093664526317488\n",
      "train loss:0.019413709667106562\n",
      "train loss:0.014808124614518088\n",
      "train loss:0.00786744122637899\n",
      "train loss:0.009049618781296356\n",
      "train loss:0.0007015930421669292\n",
      "train loss:0.0011736397754232152\n",
      "train loss:0.0027172520014730915\n",
      "train loss:0.00471140645004292\n",
      "train loss:0.01715741380941471\n",
      "train loss:0.00879348838101619\n",
      "train loss:0.00566041063973026\n",
      "train loss:0.0019829432448992984\n",
      "train loss:0.005006220158870906\n",
      "train loss:0.0021412410125477926\n",
      "train loss:0.000258949451446135\n",
      "train loss:0.01681380146527065\n",
      "train loss:0.008299468693121924\n",
      "train loss:0.010046025128170101\n",
      "train loss:0.0015812722007633492\n",
      "train loss:0.0019606461321184957\n",
      "train loss:0.005006090953275399\n",
      "train loss:0.0102011401688481\n",
      "train loss:0.002216101627803752\n",
      "train loss:0.003639687185791135\n",
      "train loss:0.011858057678063454\n",
      "train loss:0.005360867522196154\n",
      "train loss:0.0057705782840789055\n",
      "train loss:0.009159091127454375\n",
      "train loss:0.0011230121168322434\n",
      "train loss:0.012176718410422581\n",
      "train loss:0.0034970399904454604\n",
      "train loss:0.02069537786611545\n",
      "train loss:0.0037366956578990286\n",
      "train loss:0.010464358994597094\n",
      "train loss:0.0035846852854806693\n",
      "train loss:0.002634173748922687\n",
      "train loss:0.0669872756170829\n",
      "train loss:0.014675527605633438\n",
      "train loss:0.005384124710266051\n",
      "train loss:0.0009889571813348132\n",
      "train loss:0.005711741677649238\n",
      "train loss:0.0009305120930893536\n",
      "train loss:0.009699793188545603\n",
      "train loss:0.011641948229268664\n",
      "train loss:0.0033487145734120453\n",
      "train loss:0.007366406541719585\n",
      "train loss:0.004835999256567467\n",
      "train loss:0.0049720121118084284\n",
      "train loss:0.0038243686093371487\n",
      "train loss:0.034207611656679966\n",
      "train loss:0.008501236031312642\n",
      "train loss:0.002635674676565177\n",
      "train loss:0.0009561853296001658\n",
      "train loss:0.0031317950205858418\n",
      "train loss:0.009240658709416075\n",
      "train loss:0.012787188693757159\n",
      "train loss:0.004070754341768523\n",
      "train loss:0.000804625642454409\n",
      "train loss:0.004133411115264735\n",
      "train loss:0.0062167679836887335\n",
      "train loss:0.001947674250566754\n",
      "train loss:0.004257435508106349\n",
      "train loss:0.0028694523485544065\n",
      "train loss:0.002719048460483227\n",
      "train loss:0.004295765919251778\n",
      "train loss:0.0032876008967340363\n",
      "train loss:0.005373747113243699\n",
      "train loss:0.0014086513917915219\n",
      "train loss:0.018621561125703047\n",
      "train loss:0.0044243652196219495\n",
      "train loss:0.0038930717153694977\n",
      "train loss:0.0061589218724022845\n",
      "train loss:0.0031701182614688704\n",
      "train loss:0.0005691945129061666\n",
      "train loss:0.006115245140318744\n",
      "train loss:0.001076419787633857\n",
      "train loss:0.0006129893553083831\n",
      "train loss:0.002321439685404164\n",
      "train loss:0.0037210300495327617\n",
      "train loss:0.009417397431492445\n",
      "train loss:0.0053248347657584676\n",
      "train loss:0.0065184844941617226\n",
      "train loss:0.009301690727133008\n",
      "train loss:0.003645687841697874\n",
      "train loss:0.007935977811719517\n",
      "train loss:0.00424886562714249\n",
      "train loss:0.0047924118124991165\n",
      "train loss:0.00519858881356815\n",
      "train loss:0.007445199645768491\n",
      "train loss:0.007472612352857046\n",
      "train loss:0.004315477848486054\n",
      "train loss:0.007951425481933831\n",
      "train loss:0.0009266413153514431\n",
      "train loss:0.02646105247628783\n",
      "train loss:0.002331781074725206\n",
      "train loss:0.0024824185127326247\n",
      "train loss:0.009949277545634547\n",
      "train loss:0.0035353607588534206\n",
      "train loss:0.017613664454013328\n",
      "train loss:0.002869847494752644\n",
      "train loss:0.0021679162091752923\n",
      "train loss:0.0013103974469924893\n",
      "train loss:0.0031124274547023995\n",
      "train loss:0.00752487533607795\n",
      "train loss:0.009370911638545193\n",
      "train loss:0.0011178699870485061\n",
      "train loss:0.005135797078389733\n",
      "train loss:0.00047627641255973033\n",
      "train loss:0.004663881225961142\n",
      "train loss:0.009097289969099448\n",
      "train loss:0.010368363507054935\n",
      "train loss:0.001734481755156501\n",
      "train loss:0.0072015838724184015\n",
      "train loss:0.002863751315826573\n",
      "train loss:0.005520174620345917\n",
      "train loss:0.01607667644009299\n",
      "train loss:0.0008960632369474284\n",
      "train loss:0.0016031307053261618\n",
      "train loss:0.0034861556852527004\n",
      "train loss:0.0012581209353457884\n",
      "train loss:0.0066057742738161165\n",
      "train loss:0.027459303928133328\n",
      "train loss:0.0015054702323490752\n",
      "train loss:0.02804204298865645\n",
      "train loss:0.0029411858943475407\n",
      "train loss:0.0029197895892415482\n",
      "train loss:0.002464032326893949\n",
      "train loss:0.009354177385781405\n",
      "train loss:0.001773426010345513\n",
      "train loss:0.002204539282014567\n",
      "train loss:0.0008738471775596851\n",
      "train loss:0.015702611881632834\n",
      "train loss:0.010899241275567895\n",
      "train loss:0.025657455137987627\n",
      "train loss:0.005300210664371543\n",
      "train loss:0.00043823446821703987\n",
      "train loss:0.0032001214379025213\n",
      "train loss:0.013772113664170351\n",
      "train loss:0.004164073042778243\n",
      "train loss:0.004162115148745541\n",
      "train loss:0.0035169775827651063\n",
      "train loss:0.0003434721125764106\n",
      "train loss:0.0013583873168818328\n",
      "train loss:0.008473771125007573\n",
      "train loss:0.0009319136596800106\n",
      "train loss:0.0013073987060945203\n",
      "train loss:0.0034109488687661693\n",
      "train loss:0.0008068035000401365\n",
      "train loss:0.0013333645645053629\n",
      "train loss:0.015814566953790576\n",
      "train loss:0.004520748192303465\n",
      "train loss:0.01050483600467601\n",
      "train loss:0.00979764242412155\n",
      "train loss:0.004555125020215759\n",
      "train loss:0.004345322354924997\n",
      "train loss:0.0036547076545318385\n",
      "train loss:0.01166998804460709\n",
      "train loss:0.01356362412549186\n",
      "train loss:0.0021367109902765856\n",
      "train loss:0.0003148257306719131\n",
      "train loss:0.0018168284913932609\n",
      "train loss:0.0011305691122815318\n",
      "train loss:0.0025791180938342013\n",
      "train loss:0.0012798596401821377\n",
      "train loss:0.009567250883705448\n",
      "train loss:0.0041038528601789435\n",
      "train loss:0.005905909035309106\n",
      "train loss:0.006587459756207328\n",
      "train loss:0.0022140857682797937\n",
      "train loss:0.00720439448170309\n",
      "train loss:0.0026151708948266034\n",
      "train loss:0.02076987966776395\n",
      "train loss:0.0024073355692808616\n",
      "train loss:0.006536457719408964\n",
      "train loss:0.01040947764350191\n",
      "train loss:0.024419372151071827\n",
      "train loss:0.01833330286938604\n",
      "train loss:0.007192172612449579\n",
      "train loss:0.0024963977861450384\n",
      "train loss:0.008063088049124055\n",
      "train loss:0.0007566535242079588\n",
      "train loss:0.014858215763660912\n",
      "train loss:0.009957846091833589\n",
      "train loss:0.008794081277803366\n",
      "train loss:0.003952905702106228\n",
      "train loss:0.0032702943703084766\n",
      "train loss:0.004138333729667597\n",
      "train loss:0.017272734321559405\n",
      "train loss:0.007477872172589103\n",
      "train loss:0.0017148720628144937\n",
      "train loss:0.03134478870190166\n",
      "train loss:0.003397131702714286\n",
      "train loss:0.000539846773703881\n",
      "train loss:0.013672297306408737\n",
      "train loss:0.011785994398679207\n",
      "train loss:0.004275200125802119\n",
      "train loss:0.001726503148876009\n",
      "train loss:0.005207304951529243\n",
      "train loss:0.0019079724414571364\n",
      "train loss:0.0006512600073507054\n",
      "train loss:0.00038169398346074075\n",
      "train loss:0.003482231034995611\n",
      "train loss:0.016945117750204262\n",
      "train loss:0.001987245231586851\n",
      "train loss:0.002822266111949384\n",
      "train loss:0.0019157133478616478\n",
      "train loss:0.0007640163856481172\n",
      "train loss:0.014760721253134837\n",
      "train loss:0.00034094403587504857\n",
      "train loss:0.004224466500053663\n",
      "train loss:0.027304039539220493\n",
      "train loss:0.00028545807319448036\n",
      "train loss:0.004391024962911646\n",
      "train loss:0.001206890336643165\n",
      "train loss:0.007891569306161871\n",
      "train loss:0.004372774716658888\n",
      "train loss:0.0035154636869100526\n",
      "train loss:0.005278109864422571\n",
      "train loss:0.006160998825252673\n",
      "train loss:0.0021024951723525222\n",
      "train loss:0.007431591769704088\n",
      "train loss:0.0014697393331493786\n",
      "train loss:0.04280353251569566\n",
      "train loss:0.001485183912808743\n",
      "train loss:0.003841115619154926\n",
      "train loss:0.0007552441145284112\n",
      "train loss:0.002801521124058039\n",
      "train loss:0.0061464772673065085\n",
      "train loss:0.007265456708583685\n",
      "train loss:0.01898302320112766\n",
      "train loss:0.021763070106244134\n",
      "train loss:0.02202590444867764\n",
      "train loss:0.016677574718108205\n",
      "train loss:0.0016607167968334384\n",
      "train loss:0.0023866346111107006\n",
      "train loss:0.005657137779647865\n",
      "train loss:0.0035444885625279827\n",
      "train loss:0.0059274720323891335\n",
      "train loss:0.004673085111887939\n",
      "train loss:0.0009236549891004071\n",
      "train loss:0.0036586590577379736\n",
      "train loss:0.004881386765491345\n",
      "train loss:0.0010654358518359874\n",
      "train loss:0.0009000173120720801\n",
      "train loss:0.003096481936551214\n",
      "train loss:0.0042714269170740496\n",
      "train loss:0.003930020585411078\n",
      "train loss:0.012462795478894707\n",
      "train loss:0.028073433323533976\n",
      "train loss:0.006882222292647681\n",
      "train loss:0.0029425673214705933\n",
      "train loss:0.007301164022465175\n",
      "train loss:0.001825839327908582\n",
      "train loss:0.007772291617165885\n",
      "train loss:0.001337140575066804\n",
      "train loss:0.014591956440874571\n",
      "train loss:0.003651319403880023\n",
      "train loss:0.003003886267834187\n",
      "train loss:0.0019596204804255596\n",
      "train loss:0.001968741347759741\n",
      "train loss:0.012940551717344049\n",
      "train loss:0.0034089707197046347\n",
      "train loss:0.0028118001505415403\n",
      "train loss:0.0391249515154709\n",
      "train loss:0.00341879113273969\n",
      "train loss:0.008871276242206278\n",
      "train loss:0.0024246926915677093\n",
      "train loss:0.003977451578559176\n",
      "train loss:0.01484165601351111\n",
      "train loss:0.0016039363812392904\n",
      "train loss:0.0012162980043031754\n",
      "train loss:0.0030758826236690438\n",
      "train loss:0.003671178969723519\n",
      "train loss:0.00020611184879175184\n",
      "train loss:0.0046422410569050415\n",
      "train loss:0.0027761523574088543\n",
      "train loss:0.009958922318083947\n",
      "train loss:0.0028920765013570287\n",
      "train loss:0.0010101575257112855\n",
      "train loss:0.006923649767628575\n",
      "train loss:0.004909878419597882\n",
      "train loss:0.013198775000852996\n",
      "train loss:0.002985674770390585\n",
      "train loss:0.007520049127464322\n",
      "train loss:0.0026610535503233707\n",
      "train loss:0.007497846433512128\n",
      "train loss:0.0016656758404531547\n",
      "train loss:0.00882987567504876\n",
      "train loss:0.00028979733379992244\n",
      "train loss:0.003970118217053047\n",
      "train loss:0.018291732398400557\n",
      "train loss:0.010091433660564697\n",
      "train loss:0.002929907867275093\n",
      "train loss:0.03029957766637719\n",
      "train loss:0.0018084185419176694\n",
      "train loss:0.0025916551229095194\n",
      "train loss:0.008108608220062168\n",
      "train loss:0.0006818317489971338\n",
      "train loss:0.00039538192383063297\n",
      "train loss:0.0026549767091063412\n",
      "train loss:0.0016820539719085781\n",
      "train loss:0.04500348420639029\n",
      "train loss:0.002798266697046495\n",
      "train loss:0.0013473783577185785\n",
      "train loss:0.004164992974716099\n",
      "train loss:0.0011063750164318157\n",
      "train loss:0.0031664861136025913\n",
      "train loss:0.0039983480393710165\n",
      "train loss:0.003399667735257229\n",
      "train loss:0.002651866557596387\n",
      "train loss:0.0004418182718436861\n",
      "train loss:0.006435828367852705\n",
      "train loss:0.010567594254389367\n",
      "train loss:0.0012819752208809013\n",
      "train loss:0.001072566635310381\n",
      "train loss:0.003210874533632541\n",
      "train loss:0.010954504732362196\n",
      "train loss:0.007734258664340014\n",
      "train loss:0.004615669241666154\n",
      "train loss:0.0025436659907557353\n",
      "train loss:0.009129563578027772\n",
      "train loss:0.0004997997411339787\n",
      "train loss:0.0025187579922191666\n",
      "train loss:0.001469375720563721\n",
      "train loss:0.004072169149695675\n",
      "train loss:0.005061596151420493\n",
      "train loss:0.00697755473948311\n",
      "train loss:0.0016450250279454507\n",
      "train loss:0.007245540978833812\n",
      "train loss:0.004549495570358746\n",
      "train loss:0.0006292597222362709\n",
      "train loss:0.008590734184656175\n",
      "train loss:0.0008874267162071051\n",
      "train loss:0.002399812411235772\n",
      "train loss:0.004639427777717146\n",
      "train loss:0.0075303290792119604\n",
      "=== epoch:12, train acc:0.996, test acc:0.984 ===\n",
      "train loss:0.0164990797006623\n",
      "train loss:0.002143466723137244\n",
      "train loss:0.0019915273903537097\n",
      "train loss:0.014122761508961483\n",
      "train loss:0.013203889242942888\n",
      "train loss:0.001310837919147647\n",
      "train loss:0.003327863761416988\n",
      "train loss:0.0018095284071664424\n",
      "train loss:0.0006821771465512116\n",
      "train loss:0.0010714604687148386\n",
      "train loss:0.0033736962803745975\n",
      "train loss:0.004291533918444722\n",
      "train loss:0.0016026221155522483\n",
      "train loss:0.003398696384690126\n",
      "train loss:0.004143159601297122\n",
      "train loss:0.004429394830989407\n",
      "train loss:0.007897380300671313\n",
      "train loss:0.005605219252966057\n",
      "train loss:0.0026427294158592567\n",
      "train loss:0.008288930641849428\n",
      "train loss:0.003918612900090142\n",
      "train loss:0.003660551910998987\n",
      "train loss:0.003839234064806369\n",
      "train loss:0.008195962720704088\n",
      "train loss:0.003386870632570579\n",
      "train loss:0.0021941943839995388\n",
      "train loss:0.006646353337171531\n",
      "train loss:0.006269688305250141\n",
      "train loss:0.0032332306638896678\n",
      "train loss:0.0007976761041983503\n",
      "train loss:0.003484709870084117\n",
      "train loss:0.0037121753392611277\n",
      "train loss:0.015437963818815171\n",
      "train loss:0.00876814840352372\n",
      "train loss:0.006548492140762037\n",
      "train loss:0.00351535335862034\n",
      "train loss:0.009437661781872067\n",
      "train loss:0.014315391844246494\n",
      "train loss:0.02402136321855848\n",
      "train loss:0.0057867842745944155\n",
      "train loss:0.002261721400243494\n",
      "train loss:0.0018759987639442419\n",
      "train loss:0.012896058659454947\n",
      "train loss:0.0006977155278092432\n",
      "train loss:0.0021834860892743224\n",
      "train loss:0.0024797386712836424\n",
      "train loss:0.002981859264419783\n",
      "train loss:0.0009907885805268304\n",
      "train loss:0.0016683958034505832\n",
      "train loss:0.006174681011729295\n",
      "train loss:0.0020173603035955018\n",
      "train loss:0.0019837122477521936\n",
      "train loss:0.015150500152408264\n",
      "train loss:0.004115677623720516\n",
      "train loss:0.0070487878336923035\n",
      "train loss:0.003976434912156563\n",
      "train loss:0.0038742316967503056\n",
      "train loss:0.0011761823926974072\n",
      "train loss:0.0022958324033486095\n",
      "train loss:0.0013345058607432056\n",
      "train loss:0.0017991055457388019\n",
      "train loss:0.00914637551591639\n",
      "train loss:0.006822445854688882\n",
      "train loss:0.006871216075293892\n",
      "train loss:0.022760912742687\n",
      "train loss:0.0011948082120771843\n",
      "train loss:0.005756015701828698\n",
      "train loss:0.007309643563810939\n",
      "train loss:0.0045938352186709365\n",
      "train loss:0.006287511921795482\n",
      "train loss:0.0025785358574549194\n",
      "train loss:0.006184865730625838\n",
      "train loss:0.007358503485072176\n",
      "train loss:0.00296378046742373\n",
      "train loss:0.0023797931651497427\n",
      "train loss:0.0005402995209816222\n",
      "train loss:0.003945629293837581\n",
      "train loss:0.01033341221762744\n",
      "train loss:0.07384779808162843\n",
      "train loss:0.002987774653125776\n",
      "train loss:0.0006849285734289814\n",
      "train loss:0.008909947314545263\n",
      "train loss:0.0023135496426629205\n",
      "train loss:0.002669907007977637\n",
      "train loss:0.0018323796024720116\n",
      "train loss:0.000686575078366781\n",
      "train loss:0.017569488290888117\n",
      "train loss:0.004526392344603331\n",
      "train loss:0.0009154906253982827\n",
      "train loss:0.006007608043559883\n",
      "train loss:0.011209943167080733\n",
      "train loss:0.00016696708216183193\n",
      "train loss:0.003140370479352523\n",
      "train loss:0.00466464286206551\n",
      "train loss:0.004133912341167738\n",
      "train loss:0.008366174436565847\n",
      "train loss:0.009969264544239022\n",
      "train loss:0.0023867740992168855\n",
      "train loss:0.0007923817892409659\n",
      "train loss:0.0017128441982218966\n",
      "train loss:0.0012597727988542808\n",
      "train loss:0.0005917863891424259\n",
      "train loss:0.00039315757382725724\n",
      "train loss:0.0042662678613142905\n",
      "train loss:0.012468712102526987\n",
      "train loss:0.0008774364695655901\n",
      "train loss:0.0047322654130578625\n",
      "train loss:0.014405479280871441\n",
      "train loss:0.017064820733189448\n",
      "train loss:0.013896683708993371\n",
      "train loss:0.0033487534296614547\n",
      "train loss:0.008335347511934514\n",
      "train loss:0.012899256482076769\n",
      "train loss:0.005000817957185231\n",
      "train loss:0.0036542676639740278\n",
      "train loss:0.0015823118201733237\n",
      "train loss:0.030239567312454075\n",
      "train loss:0.0007228849000916932\n",
      "train loss:0.001383966001477415\n",
      "train loss:0.005428626997372683\n",
      "train loss:0.0007084342262698102\n",
      "train loss:0.002951314126309517\n",
      "train loss:0.0007661326388345243\n",
      "train loss:0.005845025689478115\n",
      "train loss:0.0025570663511320863\n",
      "train loss:0.002486314313779072\n",
      "train loss:0.0384934766408673\n",
      "train loss:0.0017354930752103723\n",
      "train loss:0.005998920165735722\n",
      "train loss:0.0006474116468148429\n",
      "train loss:0.001538311837574424\n",
      "train loss:0.002821541842744839\n",
      "train loss:0.04225501886186657\n",
      "train loss:0.005466214460547156\n",
      "train loss:0.0024094799353907305\n",
      "train loss:0.0019492773023172829\n",
      "train loss:0.002603695594579866\n",
      "train loss:0.0051114939534484495\n",
      "train loss:0.0018844137286357393\n",
      "train loss:0.004012202810055336\n",
      "train loss:0.008053385689499745\n",
      "train loss:0.06546187191067791\n",
      "train loss:0.001726107452269774\n",
      "train loss:0.006798220605505563\n",
      "train loss:0.0027372045745202326\n",
      "train loss:0.04109784382716456\n",
      "train loss:0.005664483512033156\n",
      "train loss:0.0015237942985633782\n",
      "train loss:0.003727687890145568\n",
      "train loss:0.0024890790990715387\n",
      "train loss:0.0042230534777069175\n",
      "train loss:0.013360543598060007\n",
      "train loss:0.014650953374735085\n",
      "train loss:0.0006571586512247124\n",
      "train loss:0.03652236100914175\n",
      "train loss:0.0028818516138485973\n",
      "train loss:0.007062331939980988\n",
      "train loss:0.002271752260731121\n",
      "train loss:0.01089051712417653\n",
      "train loss:0.0060308650583128206\n",
      "train loss:0.003478470678025691\n",
      "train loss:0.0029249134843210905\n",
      "train loss:0.011381747744913502\n",
      "train loss:0.0014495624762797053\n",
      "train loss:0.02186291911758318\n",
      "train loss:0.029360856694511273\n",
      "train loss:0.005806758943632385\n",
      "train loss:0.0021769301826148986\n",
      "train loss:0.00135497023932101\n",
      "train loss:0.07195047336415607\n",
      "train loss:0.002568334746652317\n",
      "train loss:0.005445292050711823\n",
      "train loss:0.003064964764122746\n",
      "train loss:0.002622761733487827\n",
      "train loss:0.004161852409215666\n",
      "train loss:0.017969982875828502\n",
      "train loss:0.00383930889597321\n",
      "train loss:0.0030553229793097198\n",
      "train loss:0.007278735453276373\n",
      "train loss:0.003278010210467036\n",
      "train loss:0.0045887088071220475\n",
      "train loss:0.0007196542723404187\n",
      "train loss:0.0015510215673939726\n",
      "train loss:0.009039213633807037\n",
      "train loss:0.026342856333706904\n",
      "train loss:0.0036808458997040607\n",
      "train loss:0.0009366568555054488\n",
      "train loss:0.0010282120731492513\n",
      "train loss:0.01867965245155182\n",
      "train loss:0.004302448987498481\n",
      "train loss:0.0022433379708352193\n",
      "train loss:0.011576552779217191\n",
      "train loss:0.003116095532208534\n",
      "train loss:0.0009966751215147835\n",
      "train loss:0.002511582212495207\n",
      "train loss:0.004079267277405266\n",
      "train loss:0.006402374775676029\n",
      "train loss:0.0024601361811481077\n",
      "train loss:0.0037751002898523743\n",
      "train loss:0.010255307622029317\n",
      "train loss:0.012447885617226796\n",
      "train loss:0.001969215767186215\n",
      "train loss:0.001959230455535701\n",
      "train loss:0.0064015380030464615\n",
      "train loss:0.00044648829179975085\n",
      "train loss:0.006725171911364063\n",
      "train loss:0.0029493405659943234\n",
      "train loss:0.0006286371593185487\n",
      "train loss:0.002519991514797126\n",
      "train loss:0.0011486923667476303\n",
      "train loss:0.0033400231277151966\n",
      "train loss:0.00835587259028427\n",
      "train loss:0.0011140722285475709\n",
      "train loss:0.01544524491863552\n",
      "train loss:0.0038135580690088888\n",
      "train loss:0.006531448327761661\n",
      "train loss:0.004521763186676729\n",
      "train loss:0.002419190983659802\n",
      "train loss:0.040602599546371826\n",
      "train loss:0.017850936138158375\n",
      "train loss:0.002437627826633365\n",
      "train loss:0.004969449767955586\n",
      "train loss:0.0019055348354952847\n",
      "train loss:0.0029933669131991286\n",
      "train loss:0.0016616557696619242\n",
      "train loss:0.00036764010544091264\n",
      "train loss:0.0038539892786990486\n",
      "train loss:0.001642032403728268\n",
      "train loss:0.020547105599701427\n",
      "train loss:0.021249616628623316\n",
      "train loss:0.0061732462408503105\n",
      "train loss:0.0021976751412665792\n",
      "train loss:0.01612989651138895\n",
      "train loss:0.019354046672792814\n",
      "train loss:0.0028117878718160435\n",
      "train loss:0.0059675438312216935\n",
      "train loss:0.0008413430365278682\n",
      "train loss:0.0018530046831890018\n",
      "train loss:0.008486960093643884\n",
      "train loss:0.002620002610904482\n",
      "train loss:0.007765503364375892\n",
      "train loss:0.014111999267668407\n",
      "train loss:0.010343621905776172\n",
      "train loss:0.05574142234826768\n",
      "train loss:0.003679171427724548\n",
      "train loss:0.0024142560431738343\n",
      "train loss:0.0065120561981168255\n",
      "train loss:0.00011658345184301814\n",
      "train loss:0.0043663627423030085\n",
      "train loss:0.003922082954085755\n",
      "train loss:0.0007899746802438895\n",
      "train loss:0.0030809086454506585\n",
      "train loss:0.0006004737985800543\n",
      "train loss:0.008118778113151004\n",
      "train loss:0.012405304503749395\n",
      "train loss:0.019591508620974012\n",
      "train loss:0.004893569351972373\n",
      "train loss:0.011191188247207216\n",
      "train loss:0.0036807285192826454\n",
      "train loss:0.013093811421800959\n",
      "train loss:0.0013751226198663584\n",
      "train loss:0.00572503187647437\n",
      "train loss:0.004210655881091886\n",
      "train loss:0.008627840408135584\n",
      "train loss:0.006430986848825659\n",
      "train loss:0.0017490246399377086\n",
      "train loss:0.006511115104950104\n",
      "train loss:0.0016084157424341029\n",
      "train loss:0.0022479978803765263\n",
      "train loss:0.009489545828027588\n",
      "train loss:0.0030806643725207745\n",
      "train loss:0.002344817885819582\n",
      "train loss:0.002737615440568345\n",
      "train loss:0.0028125905143499153\n",
      "train loss:0.0011676820939503425\n",
      "train loss:0.0011127588478310382\n",
      "train loss:0.0033605718727158784\n",
      "train loss:0.0025293769050743825\n",
      "train loss:0.0033530738024819323\n",
      "train loss:0.01619981998520859\n",
      "train loss:0.009856337053418514\n",
      "train loss:0.005494640427054903\n",
      "train loss:0.002799637006870984\n",
      "train loss:0.00351222209466801\n",
      "train loss:0.014387173315431772\n",
      "train loss:0.0046519512047096334\n",
      "train loss:0.021841545830368247\n",
      "train loss:0.010082059226325286\n",
      "train loss:0.0024192988324344754\n",
      "train loss:0.005233949874740462\n",
      "train loss:0.0040053021606962875\n",
      "train loss:0.048052383464516284\n",
      "train loss:0.004724034575095728\n",
      "train loss:0.003128353992733836\n",
      "train loss:0.021120061001868157\n",
      "train loss:0.004177891632903601\n",
      "train loss:0.007703665911750887\n",
      "train loss:0.001500066491035496\n",
      "train loss:0.012050951579326626\n",
      "train loss:0.00253842806753445\n",
      "train loss:0.0014471010472982529\n",
      "train loss:0.0024074557360626446\n",
      "train loss:0.002410510927703031\n",
      "train loss:0.020698015588337077\n",
      "train loss:0.031577376375884286\n",
      "train loss:0.010415749061450628\n",
      "train loss:0.005231216514889415\n",
      "train loss:0.0058127034773750065\n",
      "train loss:0.014222835171338185\n",
      "train loss:0.026615920866335352\n",
      "train loss:0.04808115549055337\n",
      "train loss:0.02252597510966716\n",
      "train loss:0.014042431655441095\n",
      "train loss:0.0028069013130026573\n",
      "train loss:0.004112104046311184\n",
      "train loss:0.004236162558038401\n",
      "train loss:0.004885920177688879\n",
      "train loss:0.007185387003464221\n",
      "train loss:0.0036759613003491225\n",
      "train loss:0.0047937738209694845\n",
      "train loss:0.005286673950933594\n",
      "train loss:0.0016658122259177333\n",
      "train loss:0.012047634672607548\n",
      "train loss:0.0028917107201903557\n",
      "train loss:0.0012949812805729136\n",
      "train loss:0.010646866349352288\n",
      "train loss:0.006158737035694528\n",
      "train loss:0.0033029846855946393\n",
      "train loss:0.004867469380185481\n",
      "train loss:0.010189155958248\n",
      "train loss:0.006424991294147808\n",
      "train loss:0.0033188481821339187\n",
      "train loss:0.01130819867617962\n",
      "train loss:0.023760557979375298\n",
      "train loss:0.011251380205586753\n",
      "train loss:0.004510549759910642\n",
      "train loss:0.025376466655839373\n",
      "train loss:0.006489949605841474\n",
      "train loss:0.022304140198023573\n",
      "train loss:0.04559054776211931\n",
      "train loss:0.008132667225931067\n",
      "train loss:0.010968332911146454\n",
      "train loss:0.0028682585996232662\n",
      "train loss:0.0007393709367656343\n",
      "train loss:0.010190621338002472\n",
      "train loss:0.009487550688011869\n",
      "train loss:0.0031219373569630537\n",
      "train loss:0.008607526216917724\n",
      "train loss:0.006282286638092302\n",
      "train loss:0.003423302007878877\n",
      "train loss:0.013094759017333236\n",
      "train loss:0.0023143214789646317\n",
      "train loss:0.0005121994599366466\n",
      "train loss:0.027349531635944637\n",
      "train loss:0.0026294950245469083\n",
      "train loss:0.0019217934139939554\n",
      "train loss:0.005115380878473522\n",
      "train loss:0.0016618972968092196\n",
      "train loss:0.002697427363320926\n",
      "train loss:0.002937433716498196\n",
      "train loss:0.021396000210942467\n",
      "train loss:0.0017793091525940595\n",
      "train loss:0.0006905097189511115\n",
      "train loss:0.018464672597377437\n",
      "train loss:0.0036576205861120754\n",
      "train loss:0.012449510657331853\n",
      "train loss:0.0021140415066604403\n",
      "train loss:0.005863106717408417\n",
      "train loss:0.003617004977025326\n",
      "train loss:0.0002986112550043717\n",
      "train loss:0.018477924677128832\n",
      "train loss:0.00515587437702434\n",
      "train loss:0.0008335385997226615\n",
      "train loss:0.0017450948689149042\n",
      "train loss:0.0018235559933008128\n",
      "train loss:0.003508661525337251\n",
      "train loss:0.015039126120095704\n",
      "train loss:0.003870618137304218\n",
      "train loss:0.008432301553994664\n",
      "train loss:0.0017435409089096687\n",
      "train loss:0.015551180275335601\n",
      "train loss:0.014288623743128781\n",
      "train loss:0.0042056212911489\n",
      "train loss:0.004824294047508543\n",
      "train loss:0.0017576534182764442\n",
      "train loss:0.0009625117701329008\n",
      "train loss:0.01999586053233181\n",
      "train loss:0.0017857629661094587\n",
      "train loss:0.0024089503505305004\n",
      "train loss:0.0020060695808565986\n",
      "train loss:0.0011793319423966766\n",
      "train loss:0.0017429099244348912\n",
      "train loss:0.016248006566869096\n",
      "train loss:0.0011193521294700288\n",
      "train loss:0.01720659041283562\n",
      "train loss:0.001761933120666909\n",
      "train loss:0.022287057695003873\n",
      "train loss:0.009488624969984165\n",
      "train loss:0.0016855688943416317\n",
      "train loss:0.041139651452199846\n",
      "train loss:0.004109680776908935\n",
      "train loss:0.0035950531070994014\n",
      "train loss:0.011315471030315166\n",
      "train loss:0.0017095343127266063\n",
      "train loss:0.0029151125339693003\n",
      "train loss:0.008676862600438921\n",
      "train loss:0.0013652563506294899\n",
      "train loss:0.01861250686635461\n",
      "train loss:0.006221609809202782\n",
      "train loss:0.004711167547822452\n",
      "train loss:0.007462259234339011\n",
      "train loss:0.0024775893605259404\n",
      "train loss:0.011887348187335316\n",
      "train loss:0.0037698150244382363\n",
      "train loss:0.013628477531140125\n",
      "train loss:0.0008583619274842016\n",
      "train loss:0.005291072159794331\n",
      "train loss:0.013345016009866739\n",
      "train loss:0.026045270974961593\n",
      "train loss:0.0010473079867871372\n",
      "train loss:0.016564004751690963\n",
      "train loss:0.003943700434875952\n",
      "train loss:0.0025365893286278013\n",
      "train loss:0.0038829529787833437\n",
      "train loss:0.010341479305616894\n",
      "train loss:0.009973679768809973\n",
      "train loss:0.0008053500857541798\n",
      "train loss:0.004948221876625961\n",
      "train loss:0.013856518072649102\n",
      "train loss:0.01570969589553335\n",
      "train loss:0.0042351479374580355\n",
      "train loss:0.000814085395099024\n",
      "train loss:0.009985149936004696\n",
      "train loss:0.0018245459560493238\n",
      "train loss:0.005327412414831998\n",
      "train loss:0.003595548769086548\n",
      "train loss:0.0040518021932550614\n",
      "train loss:0.008931316358793918\n",
      "train loss:0.007583176800138846\n",
      "train loss:0.005590028214045341\n",
      "train loss:0.0030208440413559434\n",
      "train loss:0.00442145401333847\n",
      "train loss:0.0010044396256169612\n",
      "train loss:0.0013249828376101218\n",
      "train loss:0.0363192028135356\n",
      "train loss:0.009281266626871646\n",
      "train loss:0.001156294261019001\n",
      "train loss:0.005930103565092798\n",
      "train loss:0.005672040003948798\n",
      "train loss:0.006669423693176142\n",
      "train loss:0.00016378566651819302\n",
      "train loss:0.013794903768354665\n",
      "train loss:0.003706117053970988\n",
      "train loss:0.005769099362926648\n",
      "train loss:0.007071878020033581\n",
      "train loss:0.002049243626192861\n",
      "train loss:0.0009049526614540797\n",
      "train loss:0.008517871699730667\n",
      "train loss:0.004418688756932887\n",
      "train loss:0.030443792698391682\n",
      "train loss:0.012333906434460012\n",
      "train loss:0.010306332427896574\n",
      "train loss:0.005299108525399197\n",
      "train loss:0.0014550603575646324\n",
      "train loss:0.004202936062133533\n",
      "train loss:0.004863878530559996\n",
      "train loss:0.000488955878635096\n",
      "train loss:0.010477749598928134\n",
      "train loss:0.002310255606057349\n",
      "train loss:0.002612675474760918\n",
      "train loss:0.014585052875899077\n",
      "train loss:0.01011286055340282\n",
      "train loss:0.0006318261396337674\n",
      "train loss:0.007258249937089222\n",
      "train loss:0.002831229739541052\n",
      "train loss:0.01176696682705785\n",
      "train loss:0.0019211522509124377\n",
      "train loss:0.0016732467534045477\n",
      "train loss:0.007622151290948675\n",
      "train loss:0.004802477167264304\n",
      "train loss:0.0018246942869635469\n",
      "train loss:0.0038724108936085528\n",
      "train loss:0.0036557145740878133\n",
      "train loss:0.005425205129275021\n",
      "train loss:0.012883975130642484\n",
      "train loss:0.008152430190754414\n",
      "train loss:0.002532839802907739\n",
      "train loss:0.002075168688631306\n",
      "train loss:0.0026476704077747016\n",
      "train loss:0.002034319466872497\n",
      "train loss:0.014137617231571968\n",
      "train loss:0.0009675073043150997\n",
      "train loss:0.003454660570427003\n",
      "train loss:0.007255270009757284\n",
      "train loss:0.002066174133564207\n",
      "train loss:0.0024615053389434637\n",
      "train loss:0.00570469064453706\n",
      "train loss:0.0015727157510900657\n",
      "train loss:0.008677371679468403\n",
      "train loss:0.0033227969133745746\n",
      "train loss:0.004207411268089357\n",
      "train loss:0.017448506184858565\n",
      "train loss:0.003593275282647284\n",
      "train loss:0.0007303810221164496\n",
      "train loss:0.00259603656438472\n",
      "train loss:0.0051525276268379275\n",
      "train loss:0.0006088469279253225\n",
      "train loss:0.021569579954628496\n",
      "train loss:0.0007381206635951069\n",
      "train loss:0.0019996500558205144\n",
      "train loss:0.03919237395398212\n",
      "train loss:0.004187222656748022\n",
      "train loss:0.008441400146230694\n",
      "train loss:0.0014830359569661326\n",
      "train loss:0.0013493889577173724\n",
      "train loss:0.0005512442240601875\n",
      "train loss:0.0005042077720991824\n",
      "train loss:0.002806916163155065\n",
      "train loss:0.006847482475647979\n",
      "train loss:0.007578264048810096\n",
      "train loss:0.003154482434394449\n",
      "train loss:0.01092689272361991\n",
      "train loss:0.00044006588868057147\n",
      "train loss:0.0124037260676565\n",
      "train loss:0.002335784759430382\n",
      "train loss:0.0012579966064799318\n",
      "train loss:0.0008365524514299894\n",
      "train loss:0.011790630594291451\n",
      "train loss:0.0026388120015255396\n",
      "train loss:0.034116656358289\n",
      "train loss:0.015103980637989846\n",
      "train loss:0.0018713641749511232\n",
      "train loss:0.0010767020638302724\n",
      "train loss:0.002336671874600295\n",
      "train loss:0.0028533202481558916\n",
      "train loss:0.041613840709973385\n",
      "train loss:0.03784003652346031\n",
      "train loss:0.0021608808312880592\n",
      "train loss:0.01181187677966274\n",
      "train loss:0.0011285820631887027\n",
      "train loss:0.005382173674100096\n",
      "train loss:0.001537550274606584\n",
      "train loss:0.0013740880301723094\n",
      "train loss:0.003388592025846204\n",
      "train loss:0.019302134077303582\n",
      "train loss:0.003243173347449422\n",
      "train loss:0.0024641518396070912\n",
      "train loss:0.000994759872422259\n",
      "train loss:0.014633208106634482\n",
      "train loss:0.002637755489757459\n",
      "train loss:0.00784806372914508\n",
      "train loss:0.0018456847307145674\n",
      "train loss:0.0068568551647553\n",
      "train loss:0.007410745731358676\n",
      "train loss:0.0009949328023581543\n",
      "train loss:0.002559040561118732\n",
      "train loss:0.003514506195098813\n",
      "train loss:0.0010491031807342449\n",
      "train loss:0.0005490069884009713\n",
      "train loss:0.004009433710932601\n",
      "train loss:0.004657137495696437\n",
      "train loss:0.005527542072849652\n",
      "train loss:0.008461180342719555\n",
      "train loss:0.007986422485271993\n",
      "train loss:0.0009845117967354322\n",
      "train loss:0.0008763675849598236\n",
      "train loss:0.004523546086355425\n",
      "train loss:0.018669484490377388\n",
      "train loss:0.0006675615468031595\n",
      "train loss:0.0022981295086288104\n",
      "train loss:0.00570492354055509\n",
      "train loss:0.009327562567946394\n",
      "train loss:0.001625559433799367\n",
      "train loss:0.00036612984267552564\n",
      "train loss:0.00024562762574942667\n",
      "train loss:0.002692327948005099\n",
      "train loss:0.001938334257026285\n",
      "train loss:0.0016157833317734882\n",
      "train loss:0.0030317169376689436\n",
      "train loss:0.0009378635967133318\n",
      "train loss:0.0022919735649993777\n",
      "train loss:0.006976997791471861\n",
      "train loss:0.0014121361677123675\n",
      "train loss:0.0020389345974908464\n",
      "train loss:0.0010026911022033855\n",
      "train loss:0.0018152857160123048\n",
      "train loss:0.0059942232748206835\n",
      "train loss:0.005133679880268893\n",
      "train loss:0.006590911409485305\n",
      "train loss:0.0029632447792639887\n",
      "train loss:0.004942407532714451\n",
      "train loss:0.005597553196901483\n",
      "train loss:0.004071066083900915\n",
      "train loss:0.0027572352573880694\n",
      "train loss:0.002013225178319553\n",
      "train loss:0.0026896864165739383\n",
      "train loss:0.0019229867942539328\n",
      "train loss:0.0008351088692259558\n",
      "train loss:0.008711119188433031\n",
      "train loss:0.0006823705060478584\n",
      "=== epoch:13, train acc:0.998, test acc:0.987 ===\n",
      "train loss:0.0010119694544055043\n",
      "train loss:0.0011690112380984656\n",
      "train loss:0.003542025151183522\n",
      "train loss:0.00432004298223696\n",
      "train loss:0.0023031166684062735\n",
      "train loss:0.0016941731047783847\n",
      "train loss:0.000854615960355887\n",
      "train loss:0.01065192779410671\n",
      "train loss:0.001952189546432449\n",
      "train loss:0.021290214350911708\n",
      "train loss:0.0008758682388783381\n",
      "train loss:0.0007413621832931965\n",
      "train loss:0.022004684900099183\n",
      "train loss:0.017003333697389177\n",
      "train loss:0.00488424966701946\n",
      "train loss:0.003163586836133519\n",
      "train loss:0.005092397358512289\n",
      "train loss:0.00955319538698323\n",
      "train loss:0.003523823706862465\n",
      "train loss:0.007502479431282344\n",
      "train loss:0.0018537196965065532\n",
      "train loss:0.0038546466079608876\n",
      "train loss:0.004527937830473138\n",
      "train loss:0.0017773457679771114\n",
      "train loss:0.03031318085832427\n",
      "train loss:0.0035237475192772664\n",
      "train loss:0.004291583372492758\n",
      "train loss:0.018100093327937154\n",
      "train loss:0.0007031648805486856\n",
      "train loss:0.008773374327500057\n",
      "train loss:0.0007015517978895768\n",
      "train loss:0.005118718852293203\n",
      "train loss:0.0010186717114196477\n",
      "train loss:0.005394397702494515\n",
      "train loss:0.0022830351945412396\n",
      "train loss:0.0021444677955996193\n",
      "train loss:0.025183016245881484\n",
      "train loss:0.010846676205871493\n",
      "train loss:0.0016176160532584444\n",
      "train loss:0.0034173341988373933\n",
      "train loss:0.04464690662762147\n",
      "train loss:0.0006921552722418751\n",
      "train loss:0.0024256156981287964\n",
      "train loss:0.007075478692593\n",
      "train loss:0.007709504061122126\n",
      "train loss:0.003929252538006645\n",
      "train loss:0.011640176805044424\n",
      "train loss:0.037387641614888584\n",
      "train loss:0.010573907692280123\n",
      "train loss:0.0007496923707049804\n",
      "train loss:0.002150316035335977\n",
      "train loss:0.002089892560261787\n",
      "train loss:0.001147346578198395\n",
      "train loss:0.0006344082288887052\n",
      "train loss:0.0013995618245368463\n",
      "train loss:0.0115371828174743\n",
      "train loss:0.00121904769935213\n",
      "train loss:0.009070882211639833\n",
      "train loss:0.0008346976197823879\n",
      "train loss:0.0020809013408143893\n",
      "train loss:0.0012702309167299114\n",
      "train loss:0.009000483281683867\n",
      "train loss:0.018335195119440997\n",
      "train loss:0.011858389003872892\n",
      "train loss:0.00062483596420589\n",
      "train loss:0.008441073175037154\n",
      "train loss:0.037796401356337064\n",
      "train loss:0.03285446415426789\n",
      "train loss:0.01565791844163466\n",
      "train loss:0.005487494376910881\n",
      "train loss:0.0015130482064115885\n",
      "train loss:0.00727246118578928\n",
      "train loss:0.001346362352195133\n",
      "train loss:0.003980793206385139\n",
      "train loss:0.001635640523596963\n",
      "train loss:0.0026498573793363005\n",
      "train loss:0.008197562075529883\n",
      "train loss:0.0016959717220475505\n",
      "train loss:0.0008384100887452073\n",
      "train loss:0.0032352986870530466\n",
      "train loss:0.005849780312452912\n",
      "train loss:0.014237831114120962\n",
      "train loss:0.00835697485474541\n",
      "train loss:0.0022438055223231324\n",
      "train loss:0.0012507427788923146\n",
      "train loss:0.0040894121103576654\n",
      "train loss:0.0025506686291121485\n",
      "train loss:0.008226523218709234\n",
      "train loss:0.01920526541501904\n",
      "train loss:0.011391500101812457\n",
      "train loss:0.0036818892211276477\n",
      "train loss:0.00159711509758869\n",
      "train loss:0.0006981511663010849\n",
      "train loss:0.03518729961441879\n",
      "train loss:0.012007151743227371\n",
      "train loss:0.020487012925263032\n",
      "train loss:0.0017199088087009456\n",
      "train loss:0.0016572772405355385\n",
      "train loss:0.0012713548962604191\n",
      "train loss:0.0009349281906001651\n",
      "train loss:0.008675985044221603\n",
      "train loss:0.009888795361033263\n",
      "train loss:0.00582334714106776\n",
      "train loss:0.002374302391476886\n",
      "train loss:0.009009500805602646\n",
      "train loss:0.0050922961342695534\n",
      "train loss:0.001794775618091726\n",
      "train loss:0.004111450679033694\n",
      "train loss:0.02033774197217583\n",
      "train loss:0.058264515706835926\n",
      "train loss:0.0023817460122227637\n",
      "train loss:0.0035846948983162268\n",
      "train loss:0.003103880518915072\n",
      "train loss:0.001834352136479944\n",
      "train loss:0.0051116643334950685\n",
      "train loss:0.00626886499996288\n",
      "train loss:0.0024069271473369817\n",
      "train loss:0.00021411414114804104\n",
      "train loss:0.005245425795762379\n",
      "train loss:0.0015118262368982293\n",
      "train loss:0.00541274042675059\n",
      "train loss:0.0009990339131303286\n",
      "train loss:6.776515724427629e-05\n",
      "train loss:0.05499688102078579\n",
      "train loss:0.014554031796390376\n",
      "train loss:0.0016547082032442766\n",
      "train loss:0.0028089832913425266\n",
      "train loss:0.0018077980226956186\n",
      "train loss:0.0005111254721170772\n",
      "train loss:0.007177398734255198\n",
      "train loss:0.008588266381379684\n",
      "train loss:0.005114471503927424\n",
      "train loss:0.006294626672252476\n",
      "train loss:0.003136237690703776\n",
      "train loss:0.0033166387646815683\n",
      "train loss:0.044043257812522184\n",
      "train loss:0.0010540768593594275\n",
      "train loss:0.0399773536751469\n",
      "train loss:0.0011041311094792997\n",
      "train loss:0.0004641057348900005\n",
      "train loss:0.0004273301253940747\n",
      "train loss:0.013824611045348071\n",
      "train loss:0.0006124998729118067\n",
      "train loss:0.002202953095687526\n",
      "train loss:0.0010886045469657923\n",
      "train loss:0.0019373272540775966\n",
      "train loss:0.0016161607278053214\n",
      "train loss:0.0005954341627219215\n",
      "train loss:0.002731822429459744\n",
      "train loss:0.03210135423903295\n",
      "train loss:0.01615424853446624\n",
      "train loss:0.0019082939893929536\n",
      "train loss:0.005364235418686578\n",
      "train loss:0.0066233432293805565\n",
      "train loss:0.004158948857588462\n",
      "train loss:0.003043606149754398\n",
      "train loss:0.0020408795806629095\n",
      "train loss:0.000657462355236518\n",
      "train loss:0.003129542654171383\n",
      "train loss:0.028198468881732292\n",
      "train loss:0.0034519111360567945\n",
      "train loss:0.0025686230874289455\n",
      "train loss:0.006465100107840891\n",
      "train loss:0.003316838717205338\n",
      "train loss:0.0008795155902210333\n",
      "train loss:0.003229981805906\n",
      "train loss:0.015805678481261146\n",
      "train loss:0.0022745157609039652\n",
      "train loss:0.0047278325564541306\n",
      "train loss:0.011299219862304578\n",
      "train loss:0.0024313267417154063\n",
      "train loss:0.000290126730118266\n",
      "train loss:0.0014502234928692817\n",
      "train loss:0.003673538795175413\n",
      "train loss:0.000987167002258312\n",
      "train loss:0.00045918372280154973\n",
      "train loss:0.0013454873451605375\n",
      "train loss:0.0021917338860015577\n",
      "train loss:0.011663188863493318\n",
      "train loss:0.009870969952152859\n",
      "train loss:0.013256395754734494\n",
      "train loss:0.0032296556964773815\n",
      "train loss:0.0022314472400527443\n",
      "train loss:0.002780766922879686\n",
      "train loss:0.00029955312952180136\n",
      "train loss:0.0013271975286682396\n",
      "train loss:0.0026654202934721476\n",
      "train loss:0.002450458771478671\n",
      "train loss:0.01004152342072633\n",
      "train loss:0.008536200443954353\n",
      "train loss:0.00484970015021987\n",
      "train loss:0.0038216661024397715\n",
      "train loss:0.00028138115575350724\n",
      "train loss:0.0025629066691361295\n",
      "train loss:0.0029949595649571238\n",
      "train loss:0.028953034905939257\n",
      "train loss:0.004500935563014287\n",
      "train loss:0.0038973017702341527\n",
      "train loss:0.002788561846162904\n",
      "train loss:0.0017030592053215014\n",
      "train loss:0.0034327353542840727\n",
      "train loss:0.008934579306163107\n",
      "train loss:0.00032813536258524326\n",
      "train loss:0.001645906091351546\n",
      "train loss:0.0759582665898514\n",
      "train loss:0.0025900273015610513\n",
      "train loss:0.006750452774519073\n",
      "train loss:0.00326709383347685\n",
      "train loss:0.0018533495438195732\n",
      "train loss:0.00329874042327873\n",
      "train loss:0.002842162546854848\n",
      "train loss:0.0031244974763230604\n",
      "train loss:0.0016177266433028492\n",
      "train loss:0.0008793919295900424\n",
      "train loss:0.0032281574587184766\n",
      "train loss:0.014452647441615951\n",
      "train loss:0.0008102452061085828\n",
      "train loss:0.01878134370544703\n",
      "train loss:0.001533171528850483\n",
      "train loss:0.0006460171342481702\n",
      "train loss:0.0035026131839272835\n",
      "train loss:0.004648527444625393\n",
      "train loss:0.0007163484382368641\n",
      "train loss:0.0005571328353613858\n",
      "train loss:0.004119616370629993\n",
      "train loss:0.0006464122092022952\n",
      "train loss:0.002443151282724691\n",
      "train loss:0.005920350743284671\n",
      "train loss:0.0005714312042091697\n",
      "train loss:0.024339130269642087\n",
      "train loss:0.00230229192281737\n",
      "train loss:0.004016348226824771\n",
      "train loss:0.025918340113680428\n",
      "train loss:0.007431904565914159\n",
      "train loss:0.0011528655555653514\n",
      "train loss:0.004597857288148477\n",
      "train loss:0.00841647790924893\n",
      "train loss:0.0037564140132860537\n",
      "train loss:0.0007743268678698337\n",
      "train loss:0.0013016594908503126\n",
      "train loss:0.00781095441958646\n",
      "train loss:0.001065671025060273\n",
      "train loss:0.003037974374720172\n",
      "train loss:0.0009743779234587004\n",
      "train loss:0.00014024552417150812\n",
      "train loss:0.004658557523519756\n",
      "train loss:0.0011833562056620232\n",
      "train loss:0.0038780438311544294\n",
      "train loss:0.006880494738364198\n",
      "train loss:0.004424164977910121\n",
      "train loss:0.0032972673201053983\n",
      "train loss:0.0036820776082433183\n",
      "train loss:0.0008770960507106032\n",
      "train loss:0.0014014165614876727\n",
      "train loss:0.0021972726545329622\n",
      "train loss:0.00558607065231388\n",
      "train loss:0.0003684233001960168\n",
      "train loss:0.0012083583458449077\n",
      "train loss:0.004924539115080601\n",
      "train loss:0.00567327306132473\n",
      "train loss:0.004290226062755418\n",
      "train loss:0.0025140024465673755\n",
      "train loss:0.006876162528645821\n",
      "train loss:0.004619651898259365\n",
      "train loss:0.0003525400231836991\n",
      "train loss:0.00011135095652909472\n",
      "train loss:0.0007376558215321968\n",
      "train loss:0.004163790282599614\n",
      "train loss:0.0024904755093108025\n",
      "train loss:0.000646127542475079\n",
      "train loss:0.009722686058947461\n",
      "train loss:0.0008280149607960142\n",
      "train loss:0.0009210435976207926\n",
      "train loss:0.002150662242487703\n",
      "train loss:0.005100934448590376\n",
      "train loss:0.003077685262181155\n",
      "train loss:0.0030845070645246064\n",
      "train loss:0.002458110415247086\n",
      "train loss:0.008626676128669146\n",
      "train loss:0.001980882226224154\n",
      "train loss:0.0050497161489025345\n",
      "train loss:0.0011424278251551884\n",
      "train loss:0.007650271878957077\n",
      "train loss:0.0033205649478574486\n",
      "train loss:0.00644647909445874\n",
      "train loss:0.013791277008768747\n",
      "train loss:0.017353736295592028\n",
      "train loss:0.000511919537357096\n",
      "train loss:0.0016846563772626218\n",
      "train loss:0.002367544230455\n",
      "train loss:0.0036242224647708952\n",
      "train loss:0.0005733744446813743\n",
      "train loss:0.002032515596086546\n",
      "train loss:0.0005691302045134956\n",
      "train loss:0.006418642255002875\n",
      "train loss:0.002976749925813307\n",
      "train loss:0.0012351942482526483\n",
      "train loss:0.0008521677970656333\n",
      "train loss:0.0017871861943065167\n",
      "train loss:0.003046961054229209\n",
      "train loss:0.0029661467581806812\n",
      "train loss:0.013247014636042881\n",
      "train loss:0.0014366792598392091\n",
      "train loss:0.0006267385258286355\n",
      "train loss:0.016315144391297214\n",
      "train loss:0.002543938883126847\n",
      "train loss:0.001095242921930798\n",
      "train loss:0.013986483538435044\n",
      "train loss:0.003215371259309239\n",
      "train loss:0.002301615350553472\n",
      "train loss:0.00020060151600669637\n",
      "train loss:0.006744661116321864\n",
      "train loss:0.01124441301414747\n",
      "train loss:0.003809404342605214\n",
      "train loss:0.0019029051676055756\n",
      "train loss:0.0021082283867964696\n",
      "train loss:0.006470189498091317\n",
      "train loss:0.006136595327415245\n",
      "train loss:0.004464239944073337\n",
      "train loss:0.003210245343849898\n",
      "train loss:0.010033875333166551\n",
      "train loss:0.006130652042770044\n",
      "train loss:0.001112379441180298\n",
      "train loss:0.003414504472931133\n",
      "train loss:0.0012412501959165546\n",
      "train loss:0.0002508575218250767\n",
      "train loss:0.005529459985478761\n",
      "train loss:0.004324534216599739\n",
      "train loss:0.006896236914391113\n",
      "train loss:0.0013720244185452632\n",
      "train loss:0.004681772235683498\n",
      "train loss:0.001249161385918384\n",
      "train loss:0.0017218255211140189\n",
      "train loss:0.0021357839240284094\n",
      "train loss:0.0006538318827321348\n",
      "train loss:0.0033068004119337305\n",
      "train loss:0.0005359822218307201\n",
      "train loss:0.0016123550859031197\n",
      "train loss:0.0003601537815555662\n",
      "train loss:0.011252612488762345\n",
      "train loss:0.03748665156717596\n",
      "train loss:0.009617690032680771\n",
      "train loss:0.006294905490844485\n",
      "train loss:0.00179657229675453\n",
      "train loss:0.0038634806852619248\n",
      "train loss:0.006363963476772167\n",
      "train loss:0.0042749638085537445\n",
      "train loss:0.0020657639782197747\n",
      "train loss:0.0024763749804425582\n",
      "train loss:0.007475271524315167\n",
      "train loss:0.004978460344798093\n",
      "train loss:0.00018623848955328414\n",
      "train loss:0.0031487178921399002\n",
      "train loss:0.001555810356582856\n",
      "train loss:0.00021650760171612805\n",
      "train loss:0.005256166003880644\n",
      "train loss:0.003400926321604264\n",
      "train loss:0.03823530560709247\n",
      "train loss:0.0012132866676997814\n",
      "train loss:0.0075743449160181435\n",
      "train loss:0.003774699532059794\n",
      "train loss:0.004756222355967816\n",
      "train loss:0.00027791937499054237\n",
      "train loss:0.001817499352066306\n",
      "train loss:0.005825752194241234\n",
      "train loss:0.005108027763406536\n",
      "train loss:0.006488495150788578\n",
      "train loss:0.004740834721213823\n",
      "train loss:0.008735345916066211\n",
      "train loss:4.8422789301206966e-05\n",
      "train loss:0.014070629302906156\n",
      "train loss:0.004209011678548217\n",
      "train loss:0.001193073113851212\n",
      "train loss:0.0015241455813094376\n",
      "train loss:0.07203351383291735\n",
      "train loss:0.004066333233312183\n",
      "train loss:0.0022980781730100653\n",
      "train loss:0.00020016973044184656\n",
      "train loss:0.006861443892583331\n",
      "train loss:0.0067401925157504535\n",
      "train loss:0.0054213097599007075\n",
      "train loss:0.0007600971654951229\n",
      "train loss:0.0011535326606212546\n",
      "train loss:0.0026872013277200947\n",
      "train loss:0.003598341420484256\n",
      "train loss:0.008892175293945684\n",
      "train loss:0.006870005939937984\n",
      "train loss:0.005689758623855293\n",
      "train loss:0.0057011636513957745\n",
      "train loss:0.007200799383289996\n",
      "train loss:0.003224221994259163\n",
      "train loss:0.00023094233274573828\n",
      "train loss:0.00101528718139482\n",
      "train loss:0.001808656883726477\n",
      "train loss:0.000636600719164763\n",
      "train loss:0.001166993154676947\n",
      "train loss:0.00026005624686408304\n",
      "train loss:0.003643413684590668\n",
      "train loss:0.00027303611368380347\n",
      "train loss:0.0011991779481515413\n",
      "train loss:0.0004979165883931563\n",
      "train loss:0.005336633163495934\n",
      "train loss:0.003350217004032881\n",
      "train loss:0.00041401097700318466\n",
      "train loss:0.0006223931727119249\n",
      "train loss:0.0003886540025728107\n",
      "train loss:0.00043739370614289297\n",
      "train loss:0.0004385187224597359\n",
      "train loss:0.0009030682179484047\n",
      "train loss:0.0035356879825416193\n",
      "train loss:0.0030295099708496963\n",
      "train loss:0.002758222200323826\n",
      "train loss:0.004074998767832856\n",
      "train loss:0.000724889270714079\n",
      "train loss:0.00019125754637068715\n",
      "train loss:0.0011050237822462503\n",
      "train loss:0.0060520574888207924\n",
      "train loss:0.0008438955608383744\n",
      "train loss:0.001469778496826545\n",
      "train loss:0.0036611360110898384\n",
      "train loss:0.001085974302829997\n",
      "train loss:0.005722254015519162\n",
      "train loss:0.0009783300711812219\n",
      "train loss:0.00299315924837823\n",
      "train loss:0.0013275968318222497\n",
      "train loss:0.0036104057953720366\n",
      "train loss:0.0035442358153350132\n",
      "train loss:0.0014616831842290904\n",
      "train loss:0.0016416380665091788\n",
      "train loss:0.0007212281624288474\n",
      "train loss:0.008409740471284318\n",
      "train loss:0.0024907119279401805\n",
      "train loss:0.0010801416335823695\n",
      "train loss:0.002813410993819013\n",
      "train loss:0.0040023594999423475\n",
      "train loss:0.002225726830839943\n",
      "train loss:0.004719740491833785\n",
      "train loss:0.0004109880409174447\n",
      "train loss:0.008150292717896633\n",
      "train loss:0.00967813794978454\n",
      "train loss:0.0020489159307169815\n",
      "train loss:0.00043598834857278885\n",
      "train loss:0.0012645995779655963\n",
      "train loss:0.0008713341086949103\n",
      "train loss:0.0008080167395145178\n",
      "train loss:0.000558780260153444\n",
      "train loss:0.005590740477870632\n",
      "train loss:0.001708354999580962\n",
      "train loss:0.007007292453914798\n",
      "train loss:0.00031263031715142816\n",
      "train loss:0.005993538178631757\n",
      "train loss:0.004363317195797976\n",
      "train loss:0.0005870805076323817\n",
      "train loss:0.0014405923483057125\n",
      "train loss:0.0045830596844431745\n",
      "train loss:0.003397800261683431\n",
      "train loss:0.0033578396518742764\n",
      "train loss:0.0025917255678205814\n",
      "train loss:0.0025884048706619404\n",
      "train loss:0.007707933046946707\n",
      "train loss:0.0025494168514213133\n",
      "train loss:0.0014914674442167064\n",
      "train loss:0.006754911821929572\n",
      "train loss:0.0017395458691075128\n",
      "train loss:0.0009393786192955039\n",
      "train loss:0.005669925502818889\n",
      "train loss:0.002530932531348742\n",
      "train loss:0.0012632734258028072\n",
      "train loss:0.00392589354478391\n",
      "train loss:0.00047671692238744227\n",
      "train loss:0.00117720102538437\n",
      "train loss:0.0011058428456288457\n",
      "train loss:0.00568060693314982\n",
      "train loss:0.00033836373162452664\n",
      "train loss:0.00027805098003472103\n",
      "train loss:0.0023005073234165837\n",
      "train loss:0.004293457424587594\n",
      "train loss:0.009462004124955072\n",
      "train loss:0.005558123345775327\n",
      "train loss:0.0033617718175267576\n",
      "train loss:0.0008648502370701539\n",
      "train loss:0.0007847217747026601\n",
      "train loss:0.004074917448403263\n",
      "train loss:0.0028023821499721007\n",
      "train loss:0.0011783047071450973\n",
      "train loss:0.0011081229199275402\n",
      "train loss:0.0008476331900143817\n",
      "train loss:0.0022285423407038835\n",
      "train loss:0.0019107689363664292\n",
      "train loss:0.0004315814837538293\n",
      "train loss:0.019142287682629038\n",
      "train loss:0.0011577639011344214\n",
      "train loss:0.005111873270984671\n",
      "train loss:0.0017688237232640726\n",
      "train loss:0.005164305890986515\n",
      "train loss:0.0003424550441534838\n",
      "train loss:0.016426430492733284\n",
      "train loss:0.0032841613514314255\n",
      "train loss:0.002550761152882648\n",
      "train loss:0.0011245362182961795\n",
      "train loss:0.002358943553146442\n",
      "train loss:0.0011449102370666541\n",
      "train loss:0.0007505874853211463\n",
      "train loss:0.004984892092988343\n",
      "train loss:0.009674699883037194\n",
      "train loss:0.0014983664186293314\n",
      "train loss:0.0031234746726806063\n",
      "train loss:0.0015088363999211669\n",
      "train loss:0.0022339060720356573\n",
      "train loss:0.004396019974766159\n",
      "train loss:0.0038357375980186486\n",
      "train loss:0.004996097290144038\n",
      "train loss:0.0015821115314614256\n",
      "train loss:0.0008040981390404083\n",
      "train loss:0.0005025612829614829\n",
      "train loss:0.008287965430264624\n",
      "train loss:0.00641703148483574\n",
      "train loss:0.007643147920417969\n",
      "train loss:0.002309650683822463\n",
      "train loss:0.0029553913329155974\n",
      "train loss:0.001509131609561208\n",
      "train loss:0.006766467743035738\n",
      "train loss:0.003416080216259601\n",
      "train loss:0.0014602942225138676\n",
      "train loss:0.006801107210422447\n",
      "train loss:0.0005252774543278347\n",
      "train loss:0.004385857891913228\n",
      "train loss:0.0026383611703370722\n",
      "train loss:0.0036211204381583787\n",
      "train loss:0.008700239016377592\n",
      "train loss:0.0020063046519189906\n",
      "train loss:0.002459312349033304\n",
      "train loss:0.0026537512542386126\n",
      "train loss:0.00330405240351079\n",
      "train loss:0.0018751291761830494\n",
      "train loss:0.008462455935881156\n",
      "train loss:0.0019310970185532803\n",
      "train loss:0.006133869290865934\n",
      "train loss:0.01558766851019216\n",
      "train loss:0.0056984428311324066\n",
      "train loss:0.0014992394223368561\n",
      "train loss:0.0006341670847087558\n",
      "train loss:0.005156049050466556\n",
      "train loss:0.0003087169072841686\n",
      "train loss:0.002502468006406002\n",
      "train loss:0.002153847252271418\n",
      "train loss:0.0005280627634068506\n",
      "train loss:0.012053866585943918\n",
      "train loss:0.0006901704082896416\n",
      "train loss:0.00016706903818401346\n",
      "train loss:0.007429703598313063\n",
      "train loss:0.001252556094544867\n",
      "train loss:0.0009245771300160961\n",
      "train loss:0.00362558866552946\n",
      "train loss:0.005211479737033991\n",
      "train loss:0.0035933979247753257\n",
      "train loss:0.002935059056665717\n",
      "train loss:0.007666627226644291\n",
      "train loss:0.0035107378917128714\n",
      "train loss:0.0034116782623431273\n",
      "train loss:0.0015705566621141988\n",
      "train loss:0.002425961980727726\n",
      "train loss:0.0014992412217601165\n",
      "train loss:0.0169268118062442\n",
      "train loss:0.0001584290121279142\n",
      "train loss:0.0034168028950383816\n",
      "train loss:0.002206124351552457\n",
      "train loss:0.0037042081165174464\n",
      "train loss:0.0027429838312274446\n",
      "train loss:0.00037968937580128376\n",
      "train loss:0.016025316873715827\n",
      "train loss:0.003844616985325108\n",
      "train loss:0.0648214675372599\n",
      "train loss:0.00384778582104245\n",
      "train loss:0.002142122519148308\n",
      "train loss:0.006079241534485401\n",
      "train loss:0.02605509581685807\n",
      "train loss:0.004391730827351514\n",
      "train loss:0.0007186256319441663\n",
      "train loss:0.001805780752040336\n",
      "train loss:0.0053343868010251715\n",
      "train loss:0.008534442257509389\n",
      "train loss:0.0036490019520056182\n",
      "train loss:0.008167660876960211\n",
      "train loss:0.004432316171667455\n",
      "train loss:0.0035656108637350838\n",
      "train loss:0.003315760258889237\n",
      "train loss:0.005747794028623949\n",
      "train loss:0.0022598834164539363\n",
      "train loss:0.003809952720020822\n",
      "train loss:0.0037855124739258283\n",
      "train loss:0.007554436152875302\n",
      "train loss:0.0011618244788226704\n",
      "train loss:0.013771965278577427\n",
      "train loss:0.0021751308849955243\n",
      "train loss:0.0064741651394484324\n",
      "train loss:0.001490351524700646\n",
      "train loss:0.004580560033054656\n",
      "train loss:0.004221357360365701\n",
      "train loss:0.003880937518443511\n",
      "=== epoch:14, train acc:0.996, test acc:0.99 ===\n",
      "train loss:0.007281051026548365\n",
      "train loss:0.00031377773739887325\n",
      "train loss:0.00023177557044084724\n",
      "train loss:0.0032825496235351125\n",
      "train loss:0.002007720185328813\n",
      "train loss:0.005496450669568486\n",
      "train loss:0.015717488327958523\n",
      "train loss:0.011539927985768186\n",
      "train loss:0.0027372894551427767\n",
      "train loss:0.0018315692218343702\n",
      "train loss:0.0023266630488483616\n",
      "train loss:0.015227223244477277\n",
      "train loss:0.0029599297778351995\n",
      "train loss:0.0010915889669274425\n",
      "train loss:0.026619074959977104\n",
      "train loss:0.019730861831068713\n",
      "train loss:0.002197759601224384\n",
      "train loss:0.0064332242150315945\n",
      "train loss:0.010563629354250257\n",
      "train loss:0.009965232868359451\n",
      "train loss:0.0001939407812648546\n",
      "train loss:0.004002318092649947\n",
      "train loss:0.0006608762042025221\n",
      "train loss:0.0064979463695865845\n",
      "train loss:0.006843387261647685\n",
      "train loss:0.006932530575741777\n",
      "train loss:0.001745996186803583\n",
      "train loss:0.0015599371812946967\n",
      "train loss:0.0038372234362741725\n",
      "train loss:0.000515553205562875\n",
      "train loss:0.009042709274932222\n",
      "train loss:0.0010532293530172742\n",
      "train loss:0.004913837904645479\n",
      "train loss:0.004074812074940633\n",
      "train loss:0.01646526051152213\n",
      "train loss:0.001981707992199686\n",
      "train loss:0.002844024423908357\n",
      "train loss:0.001283476288799461\n",
      "train loss:0.0018350918304790684\n",
      "train loss:0.004030519861116605\n",
      "train loss:0.0026326122905782814\n",
      "train loss:0.015640566133833703\n",
      "train loss:0.0004059611801072404\n",
      "train loss:0.0007694088046700504\n",
      "train loss:0.0009838085508735853\n",
      "train loss:0.0008233706097639183\n",
      "train loss:0.0016962278759492736\n",
      "train loss:0.00045919376369600557\n",
      "train loss:0.0017820430755821563\n",
      "train loss:0.028159871671954405\n",
      "train loss:0.003653952913888695\n",
      "train loss:0.0024957772553379598\n",
      "train loss:0.003106160672644964\n",
      "train loss:0.0027296677704509408\n",
      "train loss:0.0006449017761721411\n",
      "train loss:0.010704013850014737\n",
      "train loss:0.012249109709417162\n",
      "train loss:0.001586329913089937\n",
      "train loss:0.0011591441422663356\n",
      "train loss:0.0003901469940168579\n",
      "train loss:0.00020339045263162087\n",
      "train loss:0.001296793375241948\n",
      "train loss:0.009144365980980238\n",
      "train loss:0.008744831810823939\n",
      "train loss:0.0013826325566087155\n",
      "train loss:0.001171180855532011\n",
      "train loss:0.002225003925162491\n",
      "train loss:0.005468567911444262\n",
      "train loss:0.006819938248053521\n",
      "train loss:0.0032259315083296718\n",
      "train loss:0.0033687435819403835\n",
      "train loss:3.548900868870299e-05\n",
      "train loss:0.0034770731311824492\n",
      "train loss:0.0005263819028944567\n",
      "train loss:0.020560909510492067\n",
      "train loss:0.0006973942031298506\n",
      "train loss:0.0009688633380515664\n",
      "train loss:0.0034067531739116\n",
      "train loss:0.06112702448005046\n",
      "train loss:0.004646007104206049\n",
      "train loss:0.0006229748626395929\n",
      "train loss:0.011517179277240672\n",
      "train loss:0.007882071879687562\n",
      "train loss:0.0036020766532798222\n",
      "train loss:0.0010950613192801481\n",
      "train loss:0.0016672209393097388\n",
      "train loss:0.006675448303470468\n",
      "train loss:0.01547121724787671\n",
      "train loss:0.008744374908275452\n",
      "train loss:0.005176834480984762\n",
      "train loss:0.0016209836117669332\n",
      "train loss:0.0034392261742596107\n",
      "train loss:0.0006703297028663542\n",
      "train loss:0.005640413285239479\n",
      "train loss:0.008158196460313521\n",
      "train loss:0.003674589677933332\n",
      "train loss:0.003687224721082497\n",
      "train loss:0.037123941856466856\n",
      "train loss:0.004717672333259741\n",
      "train loss:0.004813814430874187\n",
      "train loss:0.0013288918647708918\n",
      "train loss:0.005550155864278367\n",
      "train loss:0.00038708769958106516\n",
      "train loss:0.0082426458987538\n",
      "train loss:0.000807168569660653\n",
      "train loss:0.005037532819021406\n",
      "train loss:0.0021076525688684834\n",
      "train loss:0.0005579277827695801\n",
      "train loss:0.004150795390441106\n",
      "train loss:0.04863538545222717\n",
      "train loss:0.007007400580343869\n",
      "train loss:0.001032438298106028\n",
      "train loss:0.008357168669707017\n",
      "train loss:0.01593684618864132\n",
      "train loss:0.0037076129763720417\n",
      "train loss:0.004599800428415282\n",
      "train loss:0.004643253365524473\n",
      "train loss:0.0025985403776890587\n",
      "train loss:0.005560726308237975\n",
      "train loss:0.012432578543358455\n",
      "train loss:0.004277767599606084\n",
      "train loss:0.024139322822189575\n",
      "train loss:0.0070631274080918335\n",
      "train loss:0.007232224601588978\n",
      "train loss:0.00625486712233602\n",
      "train loss:0.013660275644842316\n",
      "train loss:0.0006718487684383914\n",
      "train loss:0.004053488844092207\n",
      "train loss:0.00096157859856533\n",
      "train loss:0.012629633108480294\n",
      "train loss:0.003718532618811203\n",
      "train loss:0.007849574732868526\n",
      "train loss:0.004136923384686887\n",
      "train loss:0.001760934963457967\n",
      "train loss:0.0018641201602796209\n",
      "train loss:0.004965634295496831\n",
      "train loss:0.0022092887313838027\n",
      "train loss:0.0037127338337862364\n",
      "train loss:0.002089160824040804\n",
      "train loss:0.0012960842644991288\n",
      "train loss:0.006063068713087284\n",
      "train loss:0.000775103168886987\n",
      "train loss:0.008889759502056416\n",
      "train loss:0.006494269891196308\n",
      "train loss:0.0012610605079736825\n",
      "train loss:0.00160540958073928\n",
      "train loss:0.0017227239501180454\n",
      "train loss:0.001335969156576385\n",
      "train loss:0.0024716697992463303\n",
      "train loss:0.006867944499729936\n",
      "train loss:0.003647373844833808\n",
      "train loss:0.018333232160838236\n",
      "train loss:0.0013971540638456825\n",
      "train loss:0.0028054566556091846\n",
      "train loss:0.004488911486608595\n",
      "train loss:0.008252125244030795\n",
      "train loss:0.004599305428481486\n",
      "train loss:0.0005866698526751067\n",
      "train loss:0.0028875733748096404\n",
      "train loss:0.0007986740051440466\n",
      "train loss:0.003682241948865986\n",
      "train loss:0.0017235282480413166\n",
      "train loss:0.0005248397373737026\n",
      "train loss:0.0037875340188557784\n",
      "train loss:0.000582962326940049\n",
      "train loss:0.006800598235694357\n",
      "train loss:0.0001014990439468783\n",
      "train loss:0.025047981402155684\n",
      "train loss:0.0004913697268488267\n",
      "train loss:0.001029643699366644\n",
      "train loss:0.0017628391235964935\n",
      "train loss:0.0003364939902477831\n",
      "train loss:0.0004535070273278129\n",
      "train loss:0.0012052589519110472\n",
      "train loss:0.007087118957890359\n",
      "train loss:0.004418040162740642\n",
      "train loss:0.0005839663199301383\n",
      "train loss:0.004769766294283804\n",
      "train loss:0.012282438987328427\n",
      "train loss:6.386607931858453e-05\n",
      "train loss:4.010092189505113e-05\n",
      "train loss:0.00449448746714111\n",
      "train loss:0.001314809088987385\n",
      "train loss:0.0013750967558123933\n",
      "train loss:0.003883466303793609\n",
      "train loss:0.0006333972323539316\n",
      "train loss:0.00047254668309665884\n",
      "train loss:0.007062081249107153\n",
      "train loss:0.004372422887044371\n",
      "train loss:0.0003455465767888279\n",
      "train loss:0.002019251293978189\n",
      "train loss:0.003036723533442809\n",
      "train loss:0.009207257067160286\n",
      "train loss:0.003085388965032957\n",
      "train loss:0.0008360567905907994\n",
      "train loss:0.002316876527763836\n",
      "train loss:0.00034672406551937955\n",
      "train loss:0.003734925193186965\n",
      "train loss:0.0031703486075341774\n",
      "train loss:0.0018323645055954613\n",
      "train loss:0.0005370080615418544\n",
      "train loss:0.00029631514699939883\n",
      "train loss:0.0006334392765788005\n",
      "train loss:0.0008329036989098852\n",
      "train loss:0.0031060069560989063\n",
      "train loss:0.004776081204486926\n",
      "train loss:0.0031674842487447253\n",
      "train loss:5.728259201183357e-05\n",
      "train loss:0.00032911220818821504\n",
      "train loss:0.005030276083249847\n",
      "train loss:0.00960666371811132\n",
      "train loss:0.0005191194753298558\n",
      "train loss:0.0015827022776071283\n",
      "train loss:0.0013954722918346238\n",
      "train loss:0.0005968664326178735\n",
      "train loss:0.001010868537268418\n",
      "train loss:0.00022053469590840348\n",
      "train loss:0.0026587035882355147\n",
      "train loss:0.00255676968268866\n",
      "train loss:0.0005343964528404329\n",
      "train loss:0.0022758083612707514\n",
      "train loss:0.001303308674063994\n",
      "train loss:0.017755907155318627\n",
      "train loss:0.004217547775560143\n",
      "train loss:0.0012505496536659583\n",
      "train loss:0.001060535014730149\n",
      "train loss:0.0012666553829501013\n",
      "train loss:0.004133464427319725\n",
      "train loss:0.0007356316145638388\n",
      "train loss:0.00021557781939479786\n",
      "train loss:0.0037900810703854052\n",
      "train loss:0.0025511876271048263\n",
      "train loss:0.0011583092538476794\n",
      "train loss:0.0005279636496128382\n",
      "train loss:0.002538772358287529\n",
      "train loss:0.001258238860778392\n",
      "train loss:0.019015883999651026\n",
      "train loss:0.0009669803119005219\n",
      "train loss:0.001937116338733135\n",
      "train loss:0.0005651755683071559\n",
      "train loss:8.905799370408585e-05\n",
      "train loss:0.010139498865046193\n",
      "train loss:0.0024481675462857773\n",
      "train loss:0.001806896900693181\n",
      "train loss:0.0041512355565045825\n",
      "train loss:0.0002172760898715606\n",
      "train loss:0.0003831634590913741\n",
      "train loss:0.00170814682156171\n",
      "train loss:0.0002822999550181889\n",
      "train loss:0.0006713879810452062\n",
      "train loss:0.001248819123607991\n",
      "train loss:0.0005559372371961923\n",
      "train loss:0.001187212968757941\n",
      "train loss:0.0007129131594474879\n",
      "train loss:0.0009077098444371293\n",
      "train loss:0.003940835616239381\n",
      "train loss:0.0013946495427498784\n",
      "train loss:0.013099029420777404\n",
      "train loss:6.808880343737117e-05\n",
      "train loss:0.0010158012456022607\n",
      "train loss:0.004027267460612573\n",
      "train loss:0.0003552664522139766\n",
      "train loss:0.003164155332267584\n",
      "train loss:0.0016935985822184487\n",
      "train loss:0.006327715901513483\n",
      "train loss:0.001569757545865552\n",
      "train loss:0.0018825015727713579\n",
      "train loss:0.00013681284229067665\n",
      "train loss:0.000811860259932863\n",
      "train loss:0.003122337253273296\n",
      "train loss:0.0014511476323211486\n",
      "train loss:0.00716271576683269\n",
      "train loss:0.0005276735226859104\n",
      "train loss:0.004622441419365245\n",
      "train loss:0.002927036442826702\n",
      "train loss:0.001122541210473678\n",
      "train loss:0.0007958278595175315\n",
      "train loss:0.0006867161373178895\n",
      "train loss:0.004135215506367393\n",
      "train loss:0.003020401680833354\n",
      "train loss:0.0023133326789389615\n",
      "train loss:0.0034318527956764796\n",
      "train loss:0.0029526951768424903\n",
      "train loss:0.0027434523031650638\n",
      "train loss:0.03372714380613881\n",
      "train loss:0.0010295734114258404\n",
      "train loss:0.0002439314032418638\n",
      "train loss:0.0011543428265368234\n",
      "train loss:0.013880980758894013\n",
      "train loss:0.0019386647223822542\n",
      "train loss:0.00043646008975347733\n",
      "train loss:0.0008921959677928462\n",
      "train loss:0.0028788317120745093\n",
      "train loss:0.004002970664369944\n",
      "train loss:0.0022480715830843633\n",
      "train loss:0.001462640962554123\n",
      "train loss:0.006998000062573621\n",
      "train loss:0.0013787361277230075\n",
      "train loss:0.006633846029556436\n",
      "train loss:0.005518627353888992\n",
      "train loss:0.0013737066375604575\n",
      "train loss:0.00029805668522438564\n",
      "train loss:0.0032079639646353532\n",
      "train loss:0.003710830914892124\n",
      "train loss:0.0022124525734506678\n",
      "train loss:0.020147550478318288\n",
      "train loss:0.0008409423290913396\n",
      "train loss:0.006719235789744694\n",
      "train loss:0.00013937196514498672\n",
      "train loss:0.0039603717756748185\n",
      "train loss:0.0009704307341784821\n",
      "train loss:0.002829387707148999\n",
      "train loss:0.010186942620511239\n",
      "train loss:0.0010589902809734616\n",
      "train loss:0.011515882140472953\n",
      "train loss:0.0001480357419772105\n",
      "train loss:0.00018725333003869482\n",
      "train loss:0.0025259621161210135\n",
      "train loss:0.0025270823897790913\n",
      "train loss:0.003330004429376937\n",
      "train loss:0.0013459473510013722\n",
      "train loss:0.0032141847184614\n",
      "train loss:0.0004955423726901332\n",
      "train loss:0.02260618132812807\n",
      "train loss:0.014679474297145665\n",
      "train loss:0.002497558042732993\n",
      "train loss:0.020105304261442778\n",
      "train loss:0.01849908191940579\n",
      "train loss:0.015465924076171025\n",
      "train loss:0.0038280525147410815\n",
      "train loss:0.009108335746978473\n",
      "train loss:0.02009761748015255\n",
      "train loss:0.009278590450080365\n",
      "train loss:0.00042750755448002877\n",
      "train loss:0.0008384716664983128\n",
      "train loss:0.00735563580075858\n",
      "train loss:0.0030227525688231453\n",
      "train loss:0.0015978684108666642\n",
      "train loss:0.0036612639159132663\n",
      "train loss:0.03791200595516429\n",
      "train loss:0.001229609371355255\n",
      "train loss:0.00047342426970316536\n",
      "train loss:0.0022190505117611584\n",
      "train loss:0.0002521858533312321\n",
      "train loss:0.0024575564257399815\n",
      "train loss:0.009104584344641304\n",
      "train loss:0.003914682834143298\n",
      "train loss:0.0006139339457987936\n",
      "train loss:0.00033216915133719624\n",
      "train loss:0.00022107464115438637\n",
      "train loss:0.004158469445749791\n",
      "train loss:0.0017030334828569303\n",
      "train loss:0.005520483488470099\n",
      "train loss:0.0015365217854425215\n",
      "train loss:0.0035643737746199684\n",
      "train loss:0.011743405855975175\n",
      "train loss:0.002792350505942309\n",
      "train loss:0.005779597676162295\n",
      "train loss:0.0016007143585818795\n",
      "train loss:0.0007300529296549873\n",
      "train loss:0.006868608199039776\n",
      "train loss:0.005241339571104345\n",
      "train loss:0.0016358163513167834\n",
      "train loss:0.002225037782590369\n",
      "train loss:0.00041811787411978737\n",
      "train loss:0.0009032747689196201\n",
      "train loss:0.0017395040050624145\n",
      "train loss:0.004746250063084869\n",
      "train loss:0.0012073765137451842\n",
      "train loss:0.006813059309853823\n",
      "train loss:0.003393179448110194\n",
      "train loss:0.001961725534994074\n",
      "train loss:0.0059269157735424485\n",
      "train loss:0.0011790108488619003\n",
      "train loss:0.004316473024972702\n",
      "train loss:0.002208543036381207\n",
      "train loss:0.03474836361376557\n",
      "train loss:0.005599699166080959\n",
      "train loss:0.004400040341509336\n",
      "train loss:0.002356298825656418\n",
      "train loss:0.0037386082201397042\n",
      "train loss:0.0017855423646966748\n",
      "train loss:0.03027970364193515\n",
      "train loss:0.021853089382265555\n",
      "train loss:0.0052950237391552355\n",
      "train loss:0.0005129691052543719\n",
      "train loss:0.0006912253888665471\n",
      "train loss:0.0006558099203751464\n",
      "train loss:0.0022624494120378\n",
      "train loss:0.0008678034784260014\n",
      "train loss:0.0009857354799954784\n",
      "train loss:0.004243471863108071\n",
      "train loss:0.0038579277894198404\n",
      "train loss:0.005809498228699274\n",
      "train loss:0.00047448980276121\n",
      "train loss:0.0016456508793724672\n",
      "train loss:0.008646583939375008\n",
      "train loss:0.006650072226494089\n",
      "train loss:0.004263306192438287\n",
      "train loss:0.003928358312669151\n",
      "train loss:0.0011859144927900945\n",
      "train loss:0.000520150365334003\n",
      "train loss:0.006708580155527726\n",
      "train loss:0.03624879805185275\n",
      "train loss:0.012022951762552919\n",
      "train loss:0.003192184808378023\n",
      "train loss:0.0030198522044588543\n",
      "train loss:0.0009109894850205163\n",
      "train loss:0.005602130872694463\n",
      "train loss:0.01618138574582206\n",
      "train loss:0.0009700283789558734\n",
      "train loss:0.00298701634334636\n",
      "train loss:0.0008652526024446835\n",
      "train loss:0.0006801702547682515\n",
      "train loss:0.004348725560081684\n",
      "train loss:0.004409040471913227\n",
      "train loss:0.002008002008681867\n",
      "train loss:0.0025590733623130817\n",
      "train loss:0.01215409356486471\n",
      "train loss:0.00962866866713745\n",
      "train loss:0.004439942204278105\n",
      "train loss:0.0020549507902039945\n",
      "train loss:0.011311399939514103\n",
      "train loss:0.0012373105674271883\n",
      "train loss:0.004518949423803411\n",
      "train loss:0.00022879409000860668\n",
      "train loss:0.0021107905973419745\n",
      "train loss:0.0016719522633662964\n",
      "train loss:0.001777386667172236\n",
      "train loss:0.029699728013288157\n",
      "train loss:0.0017492367701497904\n",
      "train loss:0.002482116414668602\n",
      "train loss:0.002755135300085863\n",
      "train loss:0.007875226827361841\n",
      "train loss:0.004961258482920517\n",
      "train loss:0.002845219335931241\n",
      "train loss:0.004896261592267795\n",
      "train loss:0.0009804688348056482\n",
      "train loss:0.002092776683007577\n",
      "train loss:0.005663666299325823\n",
      "train loss:0.00032265516876374184\n",
      "train loss:0.004826005604385272\n",
      "train loss:0.0010711609903860054\n",
      "train loss:0.004229154498707644\n",
      "train loss:0.010890658231548089\n",
      "train loss:0.003262925193835453\n",
      "train loss:0.0009186198526303816\n",
      "train loss:0.004851726035196238\n",
      "train loss:0.0006483078566005417\n",
      "train loss:0.0007980447087584921\n",
      "train loss:4.23540498540335e-05\n",
      "train loss:0.0011408964380763898\n",
      "train loss:0.0014763983020766758\n",
      "train loss:0.001042380911702684\n",
      "train loss:0.026816290532533104\n",
      "train loss:0.0005491748063153381\n",
      "train loss:0.0007284588504110737\n",
      "train loss:0.010815081431347273\n",
      "train loss:0.0007753501096620604\n",
      "train loss:0.0005270426242376433\n",
      "train loss:0.0005420932426207694\n",
      "train loss:0.006248854012798911\n",
      "train loss:0.011488648836045091\n",
      "train loss:0.012824659484545933\n",
      "train loss:0.0038768617511882246\n",
      "train loss:0.002953608578294639\n",
      "train loss:0.0018324865199399458\n",
      "train loss:0.0012156427614667816\n",
      "train loss:0.0007703043622239573\n",
      "train loss:0.027934607428901418\n",
      "train loss:0.0027368264353164655\n",
      "train loss:0.0008972728754092556\n",
      "train loss:0.0045878610218015965\n",
      "train loss:0.0025953005767199735\n",
      "train loss:0.001693617503165823\n",
      "train loss:0.036175138958842314\n",
      "train loss:0.0015614553563579874\n",
      "train loss:0.002848673718605261\n",
      "train loss:0.014461254229369922\n",
      "train loss:0.002534708880151017\n",
      "train loss:0.0005216291882864688\n",
      "train loss:0.0013023357411337633\n",
      "train loss:0.0009166811398964545\n",
      "train loss:0.003937156607306057\n",
      "train loss:0.00014112459792411307\n",
      "train loss:0.005203730843292171\n",
      "train loss:0.0006385750841717086\n",
      "train loss:0.0014819284469374044\n",
      "train loss:0.015433117032929915\n",
      "train loss:0.0023952100351537415\n",
      "train loss:0.0015303837405290259\n",
      "train loss:0.00514650649146572\n",
      "train loss:0.002513031266272353\n",
      "train loss:0.010119557833741917\n",
      "train loss:0.002225663248897494\n",
      "train loss:0.003678858367199282\n",
      "train loss:0.0018271471748969302\n",
      "train loss:0.0030128640362420108\n",
      "train loss:0.03242244446089321\n",
      "train loss:0.0005678088096609888\n",
      "train loss:0.014258506878362068\n",
      "train loss:0.001841904804835357\n",
      "train loss:0.0016328399739429424\n",
      "train loss:0.0031176659737303003\n",
      "train loss:0.0008745331728035741\n",
      "train loss:0.001554188673179165\n",
      "train loss:0.00016346563734270916\n",
      "train loss:0.003964454047305362\n",
      "train loss:0.004370292392792567\n",
      "train loss:0.0018642736398158067\n",
      "train loss:0.00171829723768642\n",
      "train loss:0.0003195326007743153\n",
      "train loss:0.0012890842580304965\n",
      "train loss:0.0013359942420879314\n",
      "train loss:0.011358292256470821\n",
      "train loss:0.0026613592487904946\n",
      "train loss:0.005072540003888186\n",
      "train loss:0.0013222832645929947\n",
      "train loss:0.008421823666300163\n",
      "train loss:0.00032889194279659935\n",
      "train loss:0.00043483947274308607\n",
      "train loss:0.00037512144987965096\n",
      "train loss:0.0017709757099649982\n",
      "train loss:0.0018227495364386223\n",
      "train loss:0.005397829819744552\n",
      "train loss:0.003794514645079397\n",
      "train loss:0.0019826910629160625\n",
      "train loss:0.0012104523600478235\n",
      "train loss:0.004614391317069671\n",
      "train loss:0.015316330576973259\n",
      "train loss:0.0021428689289184934\n",
      "train loss:0.002738613103794788\n",
      "train loss:0.0007762334020474993\n",
      "train loss:0.0015376361690110979\n",
      "train loss:0.001441864667800422\n",
      "train loss:0.0008266752450902854\n",
      "train loss:0.00015303189875771927\n",
      "train loss:0.009784646891664377\n",
      "train loss:0.0011069637577665794\n",
      "train loss:0.007790904132165405\n",
      "train loss:0.0011194077508704487\n",
      "train loss:0.00313582865701966\n",
      "train loss:0.0007924506876059871\n",
      "train loss:0.0034836443568618\n",
      "train loss:0.0005114086926851411\n",
      "train loss:0.0033419697049594157\n",
      "train loss:0.00210893914369922\n",
      "train loss:0.023037374126775617\n",
      "train loss:0.013233543693928228\n",
      "train loss:0.0034738045599822637\n",
      "train loss:0.0019959069497134897\n",
      "train loss:0.0002630564240744399\n",
      "train loss:0.001414100453476293\n",
      "train loss:0.001054198070814361\n",
      "train loss:0.0021415314669014623\n",
      "train loss:0.0006858281703326168\n",
      "train loss:0.0005717143654578635\n",
      "train loss:0.0009985627102784623\n",
      "train loss:0.006583071452921908\n",
      "train loss:0.004214941313364574\n",
      "train loss:0.001843001000259603\n",
      "train loss:0.005856953384961319\n",
      "train loss:0.0005567830808926999\n",
      "train loss:0.003753425023171589\n",
      "train loss:0.00950588571896941\n",
      "train loss:0.001205516767561618\n",
      "train loss:0.0005090912999275581\n",
      "train loss:0.00337642600076935\n",
      "train loss:0.0037876422387091626\n",
      "train loss:0.0007102676348008826\n",
      "train loss:0.0018985352727870209\n",
      "train loss:0.0007359983948093395\n",
      "train loss:0.001086694351355896\n",
      "train loss:0.003736083245091508\n",
      "train loss:0.00041673707529726574\n",
      "train loss:0.0018072173547297764\n",
      "train loss:0.01225371008244158\n",
      "train loss:0.004172622210014063\n",
      "train loss:0.0022918042500775864\n",
      "train loss:0.001297327151512566\n",
      "train loss:0.0016488089828565833\n",
      "train loss:0.00033879624849415335\n",
      "train loss:0.0028312586699754173\n",
      "train loss:0.017189729118300662\n",
      "train loss:0.0025527687815651845\n",
      "train loss:0.008123276566755582\n",
      "train loss:0.0009981618236989118\n",
      "train loss:0.0011850997490044969\n",
      "train loss:0.0026656083242804014\n",
      "train loss:0.0018068856415709947\n",
      "train loss:0.0005229453628665914\n",
      "train loss:0.002137955416847196\n",
      "train loss:0.007618460196795374\n",
      "train loss:0.0011705996491543653\n",
      "train loss:0.0015996807918710865\n",
      "train loss:0.001107528094261041\n",
      "train loss:0.0017625297825837561\n",
      "train loss:0.00034950211305190867\n",
      "train loss:0.007979461044429138\n",
      "train loss:0.0026960322211599407\n",
      "=== epoch:15, train acc:0.997, test acc:0.988 ===\n",
      "train loss:0.0011657981153005436\n",
      "train loss:0.0022666001516708405\n",
      "train loss:0.0015144670056172454\n",
      "train loss:0.00024561109479127337\n",
      "train loss:0.003915945686866146\n",
      "train loss:0.0008715860067266656\n",
      "train loss:0.002755816656938786\n",
      "train loss:0.001009269308755567\n",
      "train loss:0.007032272713993217\n",
      "train loss:0.0008030739390809242\n",
      "train loss:0.0017396671569397644\n",
      "train loss:0.0011554499639090004\n",
      "train loss:0.004096359151360743\n",
      "train loss:0.007487487202168757\n",
      "train loss:5.8841583883305516e-05\n",
      "train loss:0.0027431688079396664\n",
      "train loss:0.0025468194930457332\n",
      "train loss:0.0021708272650428693\n",
      "train loss:0.003827895173064569\n",
      "train loss:0.010738884107795072\n",
      "train loss:0.06349671086992484\n",
      "train loss:0.0006961582377131008\n",
      "train loss:0.0034725679717553097\n",
      "train loss:0.0005523314104104134\n",
      "train loss:0.0007784652851336216\n",
      "train loss:0.0015930273558757814\n",
      "train loss:0.004704269898392844\n",
      "train loss:0.0013209055872875743\n",
      "train loss:0.001171211884434108\n",
      "train loss:0.010950713357275958\n",
      "train loss:0.0011108836317289114\n",
      "train loss:0.0013314487960515728\n",
      "train loss:0.01329516683710089\n",
      "train loss:0.0012344207772933117\n",
      "train loss:0.027271789751353942\n",
      "train loss:0.0011353429226699148\n",
      "train loss:0.0013171051756513607\n",
      "train loss:0.0017752483008148228\n",
      "train loss:0.013255578801482738\n",
      "train loss:0.0014672583529150394\n",
      "train loss:0.0012366535807452335\n",
      "train loss:0.0023018867558873657\n",
      "train loss:0.010278931834211224\n",
      "train loss:0.004925580258671971\n",
      "train loss:0.0005836193361243011\n",
      "train loss:0.0018838293817976196\n",
      "train loss:0.005506440273886229\n",
      "train loss:0.002906772346780184\n",
      "train loss:0.0008504021032397947\n",
      "train loss:0.0016468958407363662\n",
      "train loss:0.004174092653945933\n",
      "train loss:0.002347603447169328\n",
      "train loss:0.0004933022227269233\n",
      "train loss:0.0014544330752069025\n",
      "train loss:0.0006784043802620941\n",
      "train loss:0.002546190220866194\n",
      "train loss:0.0006664027983718587\n",
      "train loss:0.007341469309928772\n",
      "train loss:0.0005176110570765881\n",
      "train loss:0.006514658744973023\n",
      "train loss:0.0018679927121796184\n",
      "train loss:0.00042686547365267764\n",
      "train loss:0.00338788347845339\n",
      "train loss:0.0007783402979648938\n",
      "train loss:0.0007442121103290125\n",
      "train loss:0.00033691780675198667\n",
      "train loss:0.0013819756806329327\n",
      "train loss:0.0023277411085782865\n",
      "train loss:0.0010151663006424019\n",
      "train loss:0.0018334908361316974\n",
      "train loss:0.00033657864029607146\n",
      "train loss:0.0024798833259934675\n",
      "train loss:0.0016736155140207527\n",
      "train loss:0.001202631280371462\n",
      "train loss:0.0001852370216443444\n",
      "train loss:0.0011824987741955771\n",
      "train loss:0.0008601352153837741\n",
      "train loss:0.000883190580389187\n",
      "train loss:0.0020024075548065938\n",
      "train loss:0.00398173069117967\n",
      "train loss:0.0008860900287433223\n",
      "train loss:0.004044668586687812\n",
      "train loss:0.008106921877435497\n",
      "train loss:0.0030727646427306326\n",
      "train loss:0.00016277417379970366\n",
      "train loss:0.0018517801852643084\n",
      "train loss:0.00022150472269878585\n",
      "train loss:0.0008359938442570896\n",
      "train loss:0.0008110689954216277\n",
      "train loss:0.003237814175695311\n",
      "train loss:0.0031169480024478375\n",
      "train loss:0.00040001094188825187\n",
      "train loss:0.003609107693964961\n",
      "train loss:0.0003866281990591493\n",
      "train loss:0.0012337500405012723\n",
      "train loss:0.00033008103202601576\n",
      "train loss:0.0012003612632021854\n",
      "train loss:0.00034645244212762506\n",
      "train loss:0.007243056195873823\n",
      "train loss:0.0011409089471475123\n",
      "train loss:0.0008011055585445504\n",
      "train loss:0.0030805116088083073\n",
      "train loss:0.0037669016537254076\n",
      "train loss:0.0003250208694631996\n",
      "train loss:0.0023243375168736386\n",
      "train loss:0.004090565157804375\n",
      "train loss:0.0008026911516412538\n",
      "train loss:0.0004666343334227853\n",
      "train loss:0.000243303278687604\n",
      "train loss:0.0031378274485588152\n",
      "train loss:0.0074492889584923195\n",
      "train loss:0.026141943156661965\n",
      "train loss:0.002849248263381543\n",
      "train loss:0.0013345095795566928\n",
      "train loss:0.0038512264134670728\n",
      "train loss:0.0006238196176976738\n",
      "train loss:0.0008846696313629998\n",
      "train loss:0.00044822885463433325\n",
      "train loss:0.00033913688658274285\n",
      "train loss:0.0009850091870029984\n",
      "train loss:0.001975090072478071\n",
      "train loss:0.00011812240097166511\n",
      "train loss:0.0005442424556346089\n",
      "train loss:0.0013779500339007014\n",
      "train loss:0.0035253773461796233\n",
      "train loss:0.003959288067958267\n",
      "train loss:0.008840433061014735\n",
      "train loss:0.0017922827445834408\n",
      "train loss:0.007543292071014416\n",
      "train loss:0.0025887741660030037\n",
      "train loss:0.0007636118375606493\n",
      "train loss:0.0006635240970520783\n",
      "train loss:0.0062680221517718345\n",
      "train loss:9.515438592389602e-05\n",
      "train loss:0.00115956785028217\n",
      "train loss:0.0015724540211924517\n",
      "train loss:0.005055528576664722\n",
      "train loss:0.00167553484280337\n",
      "train loss:0.0011950090894546172\n",
      "train loss:0.002751448267998809\n",
      "train loss:0.004226698642184517\n",
      "train loss:0.0033421398987340677\n",
      "train loss:0.0007889073797005998\n",
      "train loss:0.012083757644813236\n",
      "train loss:0.0008760168228321607\n",
      "train loss:0.0431859946810152\n",
      "train loss:0.020606815552318105\n",
      "train loss:0.0019118547356122351\n",
      "train loss:0.002483771209040475\n",
      "train loss:0.014399215020165772\n",
      "train loss:0.0009049740459987191\n",
      "train loss:0.009325841914842831\n",
      "train loss:0.0004711286445124055\n",
      "train loss:0.0033118735354369195\n",
      "train loss:0.00017578630566644692\n",
      "train loss:0.003922320761713791\n",
      "train loss:0.005179359234758367\n",
      "train loss:0.003316114232644861\n",
      "train loss:0.0008825542874472581\n",
      "train loss:0.005568209484139581\n",
      "train loss:0.002145888930446514\n",
      "train loss:0.005168251545278516\n",
      "train loss:0.0005486239451787952\n",
      "train loss:0.005619761582820654\n",
      "train loss:0.0017078092395376747\n",
      "train loss:0.002801165958691006\n",
      "train loss:0.001745447515502309\n",
      "train loss:0.0027095593259573877\n",
      "train loss:0.0034991882051791856\n",
      "train loss:0.0010189196278224911\n",
      "train loss:0.003467518891998755\n",
      "train loss:0.0037978079757507843\n",
      "train loss:6.563643511641277e-05\n",
      "train loss:0.0017882177350725058\n",
      "train loss:0.00022208564001819142\n",
      "train loss:0.0015092551676932945\n",
      "train loss:0.008295383864901352\n",
      "train loss:0.0037961274233207893\n",
      "train loss:0.011681098316132996\n",
      "train loss:0.0035424292590882796\n",
      "train loss:0.002307354478439261\n",
      "train loss:0.004091585377223952\n",
      "train loss:0.004504307195214918\n",
      "train loss:0.0007054980146376088\n",
      "train loss:0.00015694479508482297\n",
      "train loss:0.000913118835940042\n",
      "train loss:0.000575399590883242\n",
      "train loss:0.001356864486710028\n",
      "train loss:0.0024487286942560535\n",
      "train loss:0.007253820926881357\n",
      "train loss:0.0007477380827440888\n",
      "train loss:0.007249433738004931\n",
      "train loss:0.00035627241800057966\n",
      "train loss:0.0011095622453055351\n",
      "train loss:0.0058135334177951085\n",
      "train loss:0.0008817026659924534\n",
      "train loss:0.00043343578733237646\n",
      "train loss:0.00020248949769504135\n",
      "train loss:0.0213022663215817\n",
      "train loss:0.0014389937097163009\n",
      "train loss:0.00463301811328324\n",
      "train loss:0.0011548454669579968\n",
      "train loss:0.0030536825750064173\n",
      "train loss:0.002839873698316804\n",
      "train loss:0.0005199456384144738\n",
      "train loss:0.011746295733620632\n",
      "train loss:0.003765314145751239\n",
      "train loss:0.03286373580649731\n",
      "train loss:0.0026053887422338895\n",
      "train loss:0.0002801963190254052\n",
      "train loss:0.004674368099398613\n",
      "train loss:0.00045126491622345187\n",
      "train loss:0.0022135953575639473\n",
      "train loss:0.010755415184430774\n",
      "train loss:0.012896908586219358\n",
      "train loss:0.0038217542675582157\n",
      "train loss:0.0041813550509587575\n",
      "train loss:0.008228915175133964\n",
      "train loss:0.004149698145833632\n",
      "train loss:0.006800771066785683\n",
      "train loss:0.0006510834074312953\n",
      "train loss:0.005582613576967519\n",
      "train loss:0.007854794703219155\n",
      "train loss:0.005909659562063826\n",
      "train loss:0.006471979233006931\n",
      "train loss:0.013647325734835396\n",
      "train loss:0.004541875406887123\n",
      "train loss:0.015561100754757829\n",
      "train loss:0.002339046905087485\n",
      "train loss:0.0013932127783456698\n",
      "train loss:0.008507556417436708\n",
      "train loss:0.004644526236241487\n",
      "train loss:0.002539606366573382\n",
      "train loss:0.018523966270782087\n",
      "train loss:0.015214775627296673\n",
      "train loss:0.0003273328276097443\n",
      "train loss:0.00027282709874436464\n",
      "train loss:0.0007624068399233835\n",
      "train loss:0.0038228686234879463\n",
      "train loss:0.0053657963296354924\n",
      "train loss:0.004387368711832713\n",
      "train loss:0.005402196893271539\n",
      "train loss:0.0041499239318161085\n",
      "train loss:0.0018355185808805095\n",
      "train loss:0.008936521421822363\n",
      "train loss:0.005942799503747309\n",
      "train loss:0.001997661803055307\n",
      "train loss:0.0011122393290445916\n",
      "train loss:0.0038196530518096084\n",
      "train loss:0.0019389347319308413\n",
      "train loss:0.002446972106341079\n",
      "train loss:0.0009096652942646068\n",
      "train loss:0.005898527915251944\n",
      "train loss:0.00050645960881952\n",
      "train loss:0.0005375665451860643\n",
      "train loss:0.012972127249258232\n",
      "train loss:0.0036512825071307008\n",
      "train loss:0.0006843714575202095\n",
      "train loss:0.0046706176882285915\n",
      "train loss:0.0020806224738798944\n",
      "train loss:0.001801916383219581\n",
      "train loss:0.0033671727902165067\n",
      "train loss:0.004090452505560746\n",
      "train loss:0.0017715854737198322\n",
      "train loss:0.0019855510673577144\n",
      "train loss:0.0006617245856901064\n",
      "train loss:0.0005835802609495896\n",
      "train loss:0.00023644727993137732\n",
      "train loss:0.00039617245972909765\n",
      "train loss:0.0005479302417687271\n",
      "train loss:0.012748031983981287\n",
      "train loss:0.02097578854957552\n",
      "train loss:0.0017904470358729874\n",
      "train loss:0.0015307281013971297\n",
      "train loss:0.0026146909463966657\n",
      "train loss:0.006770006863240477\n",
      "train loss:0.002641232339411262\n",
      "train loss:0.0014934253178277867\n",
      "train loss:0.0023801552832876816\n",
      "train loss:0.004825943032739535\n",
      "train loss:5.1342217709006094e-05\n",
      "train loss:0.004227668445306872\n",
      "train loss:0.0016432991337004947\n",
      "train loss:0.002469736434982925\n",
      "train loss:0.002256871477702577\n",
      "train loss:0.0003613247042108414\n",
      "train loss:0.0016019227109416662\n",
      "train loss:0.007345183175340299\n",
      "train loss:0.0028535220354002915\n",
      "train loss:0.0007863051876547949\n",
      "train loss:0.0003577145358807065\n",
      "train loss:0.004863394862956668\n",
      "train loss:0.002081366910140348\n",
      "train loss:0.0004736243214420454\n",
      "train loss:0.000692899048815946\n",
      "train loss:0.0001773312294910978\n",
      "train loss:0.0006814161984188692\n",
      "train loss:0.0012727024840697293\n",
      "train loss:0.0019053904429013517\n",
      "train loss:0.002253317864774664\n",
      "train loss:0.0010965405759240804\n",
      "train loss:0.0004417582312871962\n",
      "train loss:0.0002242923297002626\n",
      "train loss:4.989659917761871e-05\n",
      "train loss:0.0008665701135890162\n",
      "train loss:0.000856691670635409\n",
      "train loss:0.002022892314779893\n",
      "train loss:0.005213846015753972\n",
      "train loss:0.009743902767419882\n",
      "train loss:0.00021053372627095212\n",
      "train loss:6.857367437628384e-05\n",
      "train loss:0.0005701863458264819\n",
      "train loss:0.0064054252609822004\n",
      "train loss:0.0006262788167786289\n",
      "train loss:0.0013183701933933434\n",
      "train loss:0.00021035649647512412\n",
      "train loss:0.0018869662814752883\n",
      "train loss:0.0007164456425068098\n",
      "train loss:0.0017318633734962454\n",
      "train loss:0.0002591831870721609\n",
      "train loss:0.0015918069988175023\n",
      "train loss:0.0098836978617995\n",
      "train loss:0.0047237261115266336\n",
      "train loss:0.006257820112597784\n",
      "train loss:0.00019394017973862346\n",
      "train loss:0.0013686093677803479\n",
      "train loss:0.0037393789706669208\n",
      "train loss:0.002100117681113429\n",
      "train loss:0.0039163901171976045\n",
      "train loss:0.004193585785031144\n",
      "train loss:0.0010925361260793588\n",
      "train loss:0.0002731723061415688\n",
      "train loss:0.0011174242785841608\n",
      "train loss:0.0007875328076113904\n",
      "train loss:8.548150113030051e-05\n",
      "train loss:0.009760123287662592\n",
      "train loss:0.00032807529546661265\n",
      "train loss:0.003426592049507498\n",
      "train loss:0.0044913986195697165\n",
      "train loss:0.0014292477765576314\n",
      "train loss:0.0041928495248625556\n",
      "train loss:0.0006432188426551883\n",
      "train loss:0.0027252785491230914\n",
      "train loss:0.0006033363097915292\n",
      "train loss:0.0020660153669239383\n",
      "train loss:0.0004130116055114642\n",
      "train loss:0.0019330117284005457\n",
      "train loss:0.00981621975235476\n",
      "train loss:0.002205370333441556\n",
      "train loss:0.004821867545980491\n",
      "train loss:0.002100547018079202\n",
      "train loss:0.0011943252399103192\n",
      "train loss:0.0006256345662374482\n",
      "train loss:0.001921679442708957\n",
      "train loss:0.0010034638878193376\n",
      "train loss:0.0016466010530701816\n",
      "train loss:0.01304824338803005\n",
      "train loss:0.00515094677787791\n",
      "train loss:0.002387948234125061\n",
      "train loss:0.0035059525259956946\n",
      "train loss:0.0017852269901480011\n",
      "train loss:0.002312461149414513\n",
      "train loss:0.001711870464076313\n",
      "train loss:0.00030471175964634994\n",
      "train loss:0.002158764435354335\n",
      "train loss:0.0009062095556549179\n",
      "train loss:0.0004005912200602362\n",
      "train loss:0.0009000598962994798\n",
      "train loss:0.001479040127080175\n",
      "train loss:6.123205625688934e-05\n",
      "train loss:0.0016620229116799357\n",
      "train loss:0.00391201960268943\n",
      "train loss:0.011233978799111368\n",
      "train loss:0.00014425512518652638\n",
      "train loss:0.0003576732837841022\n",
      "train loss:0.009914670198978726\n",
      "train loss:0.004959736368799049\n",
      "train loss:0.0015263632430147786\n",
      "train loss:0.00037905149047762286\n",
      "train loss:0.0012131389812616484\n",
      "train loss:0.0011535747912507503\n",
      "train loss:0.001318397857969041\n",
      "train loss:0.0058342154613064585\n",
      "train loss:0.013969590244065345\n",
      "train loss:0.004092208207866017\n",
      "train loss:0.0053811566341490135\n",
      "train loss:0.007678286326648969\n",
      "train loss:0.00985206169972237\n",
      "train loss:0.0036984360658465307\n",
      "train loss:0.001123024011391824\n",
      "train loss:0.0007579242172374103\n",
      "train loss:0.0007865471960520356\n",
      "train loss:0.010603853604721582\n",
      "train loss:0.002230005240811138\n",
      "train loss:0.0049306844922662125\n",
      "train loss:0.002726047745057108\n",
      "train loss:0.0039560192740916555\n",
      "train loss:0.0017398189124008814\n",
      "train loss:0.0034395121855245814\n",
      "train loss:0.026577763104726714\n",
      "train loss:0.006918191652905217\n",
      "train loss:5.4430164098669703e-05\n",
      "train loss:0.0039027081308574342\n",
      "train loss:0.0007745212809181222\n",
      "train loss:0.004143943488589367\n",
      "train loss:0.001473413633152345\n",
      "train loss:0.003196571934495544\n",
      "train loss:0.028143265752654415\n",
      "train loss:0.005923121231143413\n",
      "train loss:0.004972239407185558\n",
      "train loss:0.0005120404266961047\n",
      "train loss:0.009895988423861041\n",
      "train loss:0.0015446708526652723\n",
      "train loss:0.003385203770798337\n",
      "train loss:0.0007873845752056341\n",
      "train loss:0.001660510945240721\n",
      "train loss:0.0012422499221688712\n",
      "train loss:0.016415456130399294\n",
      "train loss:0.0007319040973344581\n",
      "train loss:0.0019284389139709627\n",
      "train loss:0.0015949755812311134\n",
      "train loss:0.001500573720012277\n",
      "train loss:0.009538968633316908\n",
      "train loss:0.006227688552457738\n",
      "train loss:0.005170716015603985\n",
      "train loss:0.0022474048322845964\n",
      "train loss:0.00044660097370594835\n",
      "train loss:0.002340001958699438\n",
      "train loss:0.0021556060492361135\n",
      "train loss:0.0033181514375406405\n",
      "train loss:0.0027797703265970215\n",
      "train loss:0.002721291224760741\n",
      "train loss:0.002216784829670796\n",
      "train loss:0.0003312915980043989\n",
      "train loss:0.0033386835406255984\n",
      "train loss:0.0024248368234764625\n",
      "train loss:0.0009274859677931311\n",
      "train loss:0.00010034157384857548\n",
      "train loss:0.0015187673753867088\n",
      "train loss:0.00011209271553969565\n",
      "train loss:0.0008050012544136097\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-activation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
